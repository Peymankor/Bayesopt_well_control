
# Problem Statement

In general, an optimization task can be defined as a search process for the maximum output value of a "well behaved" ^[In this context, it means the function is defined everywhere inside the input domain, It is single-valued and continuous.] objective function $\mathbf{J}$. Can be defined as $\mathbf{J}: \chi \rightarrow \mathbb{R}$ where acceptable solutions $\chi$ have a dimension of $D$, $\chi \subseteq \mathbb{R}^D$:


```{=tex}
\begin{equation}
\begin{aligned}
& \underset{\mathbf{u}}{\text{maximize}}
& & \mathbf{J}(\mathbf{u}) \\
& \text{subject to}
& & \mathbf{u} \subseteq \chi
\end{aligned}
\label{eq:globalopt}
\end{equation}
```


In the examples of this paper, the goal is to maximize the Net-Present-Value (NPV) in USD. Thus, the primary objective function is referred to as simply NPV in the rest of this paper. This objective function has been widely used in both well-control and field development optimization studies. In a deterministic setting, the uncertainty in the geological parameters is disregarded, and the optimization is performed based on a single geological model. Therefore, in the case of deterministic optimization, the objective function can be defined as:

```{=tex}
\begin{equation}
\mathbf{J}(\mathbf{u, G})= \sum_{k=1}^{K} \Bigg [\sum_{j=1}^{N_p}p_oq_{o,j,k}(\mathbf{u, G}) 
- \sum_{j=1}^{N_p}p_{wp}q_{wp,j,k}(\mathbf{u, G}) - 
\sum_{j=1}^{N_{wi}}p_{wi}q_{wi,j,k}(\mathbf{u, G}) \Bigg]\frac{\Delta t_k}{(1+b)^{\frac{t_k}{D}}}
\label{eq:npvdet}
\end{equation}
```

The first term in the double summation corresponds to the oil revenue; the second term is water-production cost, and the third term corresponds to the water injection cost. The Equation \@ref(eq:npvdet) is considered as the objective function for the deterministic setting since only a single geological model is considered. The $\mathbf{G}$ in Equation \@ref(eq:npvdet) is "the geological model". The additional parameters in the Equation are as follows: $K$ is the total number of timesteps; $N_p$ is the total number of production wells subject to optimization; $N_{wi}$ is the total number of water-injection wells subject to optimization; $k$ is the timestep index; $j$ is the well-number index; $p_o$ is the revenue from oil production per unit volume (in USD/bbl); $p_{wp}$ is the water-production cost per unit volume (in USD/bbl); $p_{wi}$ is the water-injection cost per unit volume (in USD/bbl); $q_o$ is the oil-production rate (in B/D); $q_{wp}$ is the water-production rate (in B/D); $q_{wi}$ is the water-injection rate (in B/D); $\Delta t_k$ is the time interval for timestep $k$ (in days); $b$ is the discount rate (dimensionless); $t_k$ is the cumulative time for discounting; and D is the reference time for discounting ($D = 365$ days, if b is expressed as a fraction per year and the cash flow, is discounted daily). $\mathbf{u}$ in Equation \@ref(eq:npvdet) is the control vector (i.e., a vector of control variables) defined as $\mathbf{u} = [u_1, u_2, \cdots, u_N]^D$, $D$ is the number of control variables (dimension of optimization problem).

As mentioned above, Equation \@ref(eq:npvdet) lacks to capture the uncertainty in the geological model. In contrast, in a Robust Optimization (RO) setting, the objective is to optimize the expected value over all geological realizations (assumption here is decision-maker is risk-neutral). Then, the goal is to optimize the $\mathbb{E}_{\mathbf{G}}[\mathbf{J}(\mathbf{u},\mathbf{G})]$, can be defined as:


```{=tex}
\begin{equation}
\mathbb{E}_{\mathbf{G}}[\mathbf{J}(\mathbf{u},\mathbf{G})]=\int_{\mathcal{Z}}\mathbf{J}(\mathbf{u, G})p(\mathbf{G})dG
\label{eq:npvopt-exact}
\end{equation}
```


Where $p(\mathbf{G})$ is probability density function (PDF) of the random variable, $\mathbf{G}$, and $\mathcal{Z}$ is the domain of the values $\mathbf{G}$ can take^[Let us say permeability is the uncertain variable, then it only takes $z \in \mathcal{Z},z>0$]  . However, throughout , we assume that the uncertainty in $\mathbf{G}$ can be represented by sampling its PDF ($p(\mathbf{G})$) to obtain an ensemble of $n_e$ realization, $\mathbf{G}_{re}$, $re=1,2,\cdots,n_e$. Therefore, approximation of $\mathbb{E}_{\mathbf{G}}[\mathbf{J}(\mathbf{u},\mathbf{G})]$ can be written as:

```{=tex}
\begin{equation}
\mathbb{E}_{\mathbf{G}}[\mathbf{J}(\mathbf{u},\mathbf{G})]\approx\overline{\mathbf{J}}(\mathbf{u})=\frac{\sum_{re=1}^{n_e} \mathbf{J}(\mathbf{u,G_{re}})}{n_e}
\label{eq:npvopt}
\end{equation}
```

Where in Equation \@ref(eq:npvopt) contrary to Equation \@ref(eq:npvdet), there is not one, rather $n_e$ geological realizations, each of them written as $\mathbf{G_{re}}$. Also, note that we dropped the dependency of $\overline{\mathbf{J}}$ on $\mathbf{G}$ and wrote the objective function as  $\overline{\mathbf{J}}(\mathbf{u})$. This is because the $n_e$ number of $\mathbf{G_{re}}$ is fixed at the start, and in all optimization process, we use the same $\mathbf{G_{re}}$. In this work, the objective is to optimize $\overline{\mathbf{J}}(\mathbf{u})$ in Equation \@ref(eq:npvopt), where it is simply an approximation of the expected value of NPV defined in \@ref(eq:npvdet) over all realizations.^[In the rest of the paper, we use "Expected NPV" or $\overline{\mathbf{J}}(\mathbf{u})$ interchangeably, but we note that they are the same.] 

However, we would like to elaborate that optimization of $\overline{\mathbf{J}}(\mathbf{u})$ needs special treatment due to three main difficulties. Therefore, the optimization method should be able to handle them, to manage the optimization of Equation \@ref(eq:npvopt). The three difficulties are: 

-   Analytic expression of $\overline{\mathbf{J}}(\mathbf{u})$ is explicitly unknown. In order to compute, $\overline{\mathbf{J}}(\mathbf{u})$, we need to find $\mathbf{J}(\mathbf{u, G})$ in Equation \@ref(eq:npvdet). Here, inside Equation \@ref(eq:npvdet), dependency of $q_{o,j,k}(\mathbf{u, G}),q_{wp,j,k}(\mathbf{u, G}),q_{wi,j,k}(\mathbf{u, G})$ on $(\mathbf{u, G})$ is explicit. In other words, we do not have access^[There is indeed a function $f$, but in flow simulation, due to iterative solving of large PDE equations (mainly inside the commercial simulators), we can not track and write down the analytical expression of $f$. To put it simply, there is a $f$ available, but we do not have access to that.] to an analytical function $f$ so that we can write $q_{wi,j,k}(\mathbf{u, G})=f(\mathbf{u, G})$. The main implication of lack of access to the analytical expression of $f$ is that the objective function prohibit us from being able to use gradient-based (as we need $f$, in order calculate $\frac{\partial f}{\partial \mathbf{u}}$) methods. Alternatively, someone can resort to an approximation of $\frac{\partial f}{\partial \mathbf{u}}$ or $\frac{\partial \overline{\mathbf{J}}(\mathbf{u})}{\partial \mathbf{u}}$ in general, but that requires careful and consistent attention on how to approximate.   
-   The surface of $\overline{\mathbf{J}}(\mathbf{u})$ is multi-modal. Meaning $\overline{\mathbf{J}}(\mathbf{u})$ is non-convex in the domain of $\chi$ , and the optimization algorithm must visit all local optima to find the "global" one.^[Someone may argue that in well-control optimization, although non-convex, the difference between local optima and global optima is low. Therefore even reaching local optima is enough. That may be true in some special cases, but from the theoretical point of view, the $\overline{\mathbf{J}}(\mathbf{u})$ does not meet Jensen's inequality ($\overline{\mathbf{J}}[\lambda \mathbf{\mathbf{u_1}}+(1-\lambda)\mathbf{u_2}]\leq \lambda\overline{\mathbf{J}}(\mathbf{\mathbf{u_1}}) + (1-\lambda)\overline{\mathbf{J}}(\mathbf{\mathbf{u_2}})$ for any $\mathbf{u_1}$,$\mathbf{u_2}$ and any $\lambda$ where $0<\lambda<1$). Therefore, the optimization is classified as non-convex optimization.]
-   Most notably, forward evaluation of $\overline{\mathbf{J}}(\mathbf{u})$ is computationally expensive. This point will be discussed more in detail below.

It is well defined in the literature that optimizing $\overline{\mathbf{J}}(\mathbf{u})$ is computationally prohibitive [@debrito2021; @nwachukwu2018; @hong2017]. Let us assume a simple case to illustrate the computational burden of this optimization problem. Assume that an E&P enterprise is in the process of finding the injection rate of five injection wells and bottom hole pressure (BHP) of five other production wells($D=10$) for the next five years. It means we have to make a decision, where the decision alternatives have a dimension of ten, and each dimension is in continuous space. The geology team of the enterprise came up with 100 geological realizations of the model.($n_e=100$). Now, if we suppose that the reservoir model is 3D, a rich grid-based, it is not hard to imagine that flow-simulation of the reservoir model will take \~1hr, to compute $q_{o,j,k}(\mathbf{u, G}),q_{wp,j,k}(\mathbf{u, G}),q_{wi,j,k}(\mathbf{u, G})$. Then, simply having 100 realizations means that each forward computation of $\overline{\mathbf{J}}(\mathbf{u})$ takes around \~100 hr. Considering that the enterprise has to decide in a six-month period (in the best case, it can be interpreted as six months CPU running time), the total number of the available computational resource for running the forward model $\frac{6 \times 30 \times 24 }{100}= 43.2 \approx 50$ is around 50. Having of the only $50$ forward model evaluations in ten-dimensional, non-linear, and non-convex optimization problem is relatively low. To put this in simple terms, if we say that each dimension of the control variable $\mathbf{u}$ could be discretized into ten possible cases, then the total available decision alternatives (solutions) for this optimization problem will be: $\text {Number of all possible alternatives} = 10^{10}$. As it is clear, finding the best solution from a pool of ten billion possible solutions with only 50 shots is a pretty much hard undertaking.\

In the rest of this paper, we will be discussing that the Bayesian Optimization workflow presented here is well suited to deal with the three difficulties described above. 

<!-- It is well defined in the literature that optimizing Equation \@ref(eq:npvopt) is computationally prohibitive [@debrito2021; @nwachukwu2018; @hong2017]. Not only because thousand(s) of PDE have to be solved simultaneously in the flow-simulation in order to compute the $q_o, q_{wp}, q_{wi}$; the flow simulation must be enumerated over all realizations $n_e$ to compute $\overline{J}(u)$. Let us assume a simple case to illustrate the computational burden of this optimization problem. Assume that an E&P enterprise is in the process of finding the injection rate of five injection wells and bottom hole pressure (BHP) of other five production wells, $D=10$. The geology team of the enterprise comes up with 100 geological realizations of the model.($n_e=100$). Now, if we suppose that the reservoir model is 3D with a moderate number of grid cells, it is not hard to imagine that flow-simulation of a fine grid model will take \~1hr. Then, simply having 100 realizations means that each forward computation of $\overline{J}(u)$ takes around \~100 hr. Considering that the enterprise has to decide in six month period (in the best case, it can be interpreted as six months CPU running time), which means that the total number of the available budget for running the forward model is$\frac{6 \times 30 \times 24 }{100}= 43.2 \approx 50$ is around 50. The budget of the only $50$ forward model in ten-dimensional, non-linear, and non-convex optimization problem is relatively low. To put this in simple terms, if we say that each dimension of the control variable $\mathbf{u}$, could be discretized into ten possible cases, then total available decision alternatives (solutions) for this optimization problem will be $\text {Number of all possible alternatives} = 10^{10}$. As it is clear, finding the best solution from a pool of ten billion possible solutions with only 50 shots is a pretty much hard undertaking.\ -->

<!-- In the rest of this paper, we will be discussing that the Bayesian Optimization workflow is well suited to deal with the three difficulties described at the beginning of the section.  -->





<!-- In Figure \@ref(fig:optglobal) we can see some examples where the surface of $\mathbf{J}$ could be challenging to be optimized. The surfaces on the left side need careful attention to avoid getting stuck in local optima. Figures on the right side show presence of saddle area, where the gradient of function $\mathbf{J}$ is zero, in some cases in only one direction, possibly all directions. In this work, the focus is on the type of objective function $\mathbf{J}$, which is challenging to optimize because of the following three difficulties: -->

<!-- -   Analytic expression of $\mathbf{J}$ is explicitly unknown. This is a typical case in reservoir optimization problems where the Net Present Value (NPV) or Recovery Factor (RF) is computed through solving a vast number of partial differential equations through flow simulation. Thus, a precise analytical expression for the objective function is not available, avoiding the applicability of techniques that exploit the analytical expression of the objective function. -->
<!-- -   The surface of $\mathbf{J}$ is multi-modal. Meaning that $\mathbf{J}$ is non-convex in the domain of $\chi$ , and the optimization algorithm must visit all local optima to find the "global" one. -->
<!-- -   Most importantly, forward evaluation of $\mathbf{J}$ is computationally expensive. This point will be discussed more in detail below. -->



<!-- ```{r optglobal, echo=FALSE, fig.cap="This plot may change, it does not show what exactly I want to say...", out.width="70%", fig.align='center'} -->
<!-- knitr::include_graphics("img/globalopt.jpg") -->
<!-- ``` -->

<!-- In the examples of this paper, the goal is to maximize the Net-Present-Value (NPV), in USD. Thus, the primary objective function referred to as simply NPV in the rest of this paper. This objective function has been widely used in both well control and field development optimization studies. In a deterministic setting, the uncertainty in the geological parameters is disregarded and the optimization is performed based on a single geological model. Therefore, in the case of deterministic optimization, the objective function can be defined as: -->

<!-- ```{=tex} -->
<!-- \begin{equation} -->
<!-- \mathbf{J}(\mathbf{u, G})= \sum_{k=1}^{K} \Bigg [\sum_{j=1}^{N_p}p_oq_{o,j,k}(\mathbf{u, G})  -->
<!-- - \sum_{j=1}^{N_p}p_{wp}q_{wp,j,k}(\mathbf{u, G}) -  -->
<!-- \sum_{j=1}^{N_{wi}}p_{wi}q_{wi,j,k}(\mathbf{u, G}) \Bigg]\frac{\Delta t_k}{(1+b)^{\frac{t_k}{D}}} -->
<!-- \label{eq:npvdet} -->
<!-- \end{equation} -->
<!-- ``` -->

<!-- Where the first term in the double summation corresponds to the oil revenue; the second term is water-production cost and third term corresponds to the water-injection cost. Equation \@ref(eq:npvdet) is considered as objective function in the deterministic setting since only a single geological model is considered. The $G$ in the Equation \@ref(eq:npvdet) is "the geological model". The additional parameters in the Equation are as follows: $K$ is the total number of timesteps; $N_p$ is the total number of production wells subject to optimization; $N_{wi}$ is the total number of water-injection wells subject to optimization; $k$ is the timestep index; $j$ is the well-number index; $p_o$ is the revenue from oil production per unit volume (in USD/bbl); $p_{wp}$ is the water-production cost per unit volume (in USD/bbl); $p_{wi}$ is the water-injection cost per unit volume (in USD/bbl); $q_o$ is the oil-production rate (in B/D); $q_{wp}$ is the water-production rate (in B/D); $q_{wi}$ is the water-injection rate (in B/D); $\Delta t_k$ is the time interval for timestep $k$ (in days); $b$ is the discount rate (dimensionless); $t_k$ is the cumulative time for discounting; and D is the reference time for discounting ($D = 365$ days if b is expressed as a fraction per year and the cash flow is discounted daily). $\mathbf{u}$ in Equation \@ref(eq:npvdet) is the control vector (i.e., a vector of control variables) defined as $\mathbf{u} = [u_1, u_2, \cdots, u_N]^D$, where $D$ is the number of control variables (dimension of optimization problem). -->

<!-- As mentioned above, Equation \@ref(eq:npvdet) lacks to capture the uncertainty in the geological model. In contrast, in a Robust Optimization (RO) setting, the objective is to optimize the expected value over all geological realizations (assumption here is decision maker is risk-neutral). Then, the gaol is to optimize the $\mathbb{E}_{\mathbf{G}}[\mathbf{J}(\mathbf{u},\mathbf{G})]$, can be defined as: -->


<!-- ```{=tex} -->
<!-- \begin{equation} -->
<!-- \mathbb{E}_{\mathbf{G}}[\mathbf{J}(\mathbf{u},\mathbf{G})]=\int_{-\infty}^{+\infty}\mathbf{J}(\mathbf{u, G})p(\mathbf{G})dG -->
<!-- \label{eq:npvopt-exact} -->
<!-- \end{equation} -->
<!-- ``` -->


<!-- Where $p(\mathbf{G})$ is probability density function (PDF) of random variable, $\mathbf{G}$. However, thoroughout , we assume that the uncertainity in $\mathbf{G}$ can be represented by sampling its PDF ($p(\mathbf{G})$) to obtain an ensemble of $n_e$ realization, $\mathbf{G}_{re}$, $re=1,2,\cdots,n_e$. Therefore, approximation of $\mathbb{E}_{\mathbf{G}}[\mathbf{J}(\mathbf{u},\mathbf{G})]$ can be written as: -->

<!-- ```{=tex} -->
<!-- \begin{equation} -->
<!-- \mathbb{E}_{\mathbf{G}}[\mathbf{J}(\mathbf{u},\mathbf{G})]\approx\overline{J}(\mathbf{u})=\frac{\sum_{re=1}^{n_e} J(\mathbf{u,G_{re}})}{n_e} -->
<!-- \label{eq:npvopt} -->
<!-- \end{equation} -->
<!-- ``` -->

<!-- Where in Equation \@ref(eq:npvopt) contrary to Equation \@ref(eq:npvdet), there is not one, rather $n_e$ geological realizations, each of them written as $G_{re}$. In this work, the objective is to optimize the Equation \@ref(eq:npvopt), where it is simply approximation of expected value of NPV defined in \@ref(eq:npvdet) over all realizations. -->

<!-- It is well defined in the literature that optimizing Equation \@ref(eq:npvopt) is computationally prohibitive [@debrito2021; @nwachukwu2018; @hong2017]. Not only because thousand(s) of PDE have to be solved simultaneously in the flow-simulation in order to compute the $q_o, q_{wp}, q_{wi}$; the flow simulation must be enumerated over all realizations $n_e$ to compute $\overline{J}(u)$. Let us assume a simple case to illustrate the computational burden of this optimization problem. Assume that an E&P enterprise is in the process of finding the injection rate of five injection wells and bottom hole pressure (BHP) of other five production wells, $D=10$. The geology team of the enterprise comes up with 100 geological realizations of the model.($n_e=100$). Now, if we suppose that the reservoir model is 3D with a moderate number of grid cells, it is not hard to imagine that flow-simulation of a fine grid model will take \~1hr. Then, simply having 100 realizations means that each forward computation of $\overline{J}(u)$ takes around \~100 hr. Considering that the enterprise has to decide in six month period (in the best case, it can be interpreted as six months CPU running time), which means that the total number of the available budget for running the forward model is$\frac{6 \times 30 \times 24 }{100}= 43.2 \approx 50$ is around 50. The budget of the only $50$ forward model in ten-dimensional, non-linear, and non-convex optimization problem is relatively low. To put this in simple terms, if we say that each dimension of the control variable $\mathbf{u}$, could be discretized into ten possible cases, then total available decision alternatives (solutions) for this optimization problem will be $\text {Number of all possible alternatives} = 10^{10}$. As it is clear, finding the best solution from a pool of ten billion possible solutions with only 50 shots is a pretty much hard undertaking.\ -->

<!-- In the rest of this paper, we will be discussing that the Bayesian Optimization workflow is well suited to deal with the three difficulties described at the beginning of the section.  -->
