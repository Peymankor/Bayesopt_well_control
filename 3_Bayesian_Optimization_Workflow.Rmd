# Bayesian Optimization Workflow

## Overall View

Bayesian Optimization (BO) is an optimization method that builds a probabilistic model to mimic an expensive objection function. The probabilistic model is build based on a finite number of function evaluations. These finite number of evaluations is done as initialization of the workflow and build a probabilistic model.

After initialization and building a probabilistic model, at each iteration, a new query point is evaluated using the the expensive objective function, then the new data $(u,f(u))$ is assimilated back to probabilistic model to update the model.The unique methodology of using a non-deterministic surrogate model makes Bayesian optimization (BO) an efficient global optimizer capable of both decision space exploration and exploitation.

## Gaussian Process

In this work, we employ the widely used Gaussian process (GP) as the probabilistic model. Known also as surrogate model (since it tries to mimic the real, expensive objective function), GPs are attractive because they are computationally tracible with capability to quantity the the uncertainty of interest [@rasmussen2006; @murphy2022]. A Gaussian process can be seen as an extension of the Gaussian distribution to the functional space. Key Assumption in (GP) is that: the function values at a set of $M > 0$ inputs, $\mathbf{J} = [J({u_1}), ...,J(u_M)]$, is jointly Gaussian, with mean and Covariance defined as:

-   Note: Here we use the objective function pdescribed in prvious section with the natotaon $\overline{J}(\mathbf{u})$, where $\mathbf{u}$ is control variables. However, just for simplicity in notation, we drop the bar sign and write objective function with $J(\mathbf{u})$.

```{=tex}
\begin{equation}
  \begin{split}
& \mathbf{\mu(u)} = [\mu(u_1),\cdots,\mu(u_M)] \\
& \text{Cov}(J(\mathbf{u}),J(\mathbf{u'}))= \kappa(\mathbf{u},\mathbf{u'})
  \end{split}
\label{eq:mean_cov}
\end{equation}
```
where $\mathbf{\mu(u)}$ is a mean function and $\kappa(\mathbf{u},\mathbf{u'})$ is a covariance function (or kernel). being specified is the similarity between two values of a function evaluated on each object A GP is a distribution over functions completely defined by its mean covariance function as:

```{=tex}
\begin{equation}
J(\mathbf{u}) \sim \mathcal{N}(\mathbf{\mu(u)}, \kappa{u,u'})
\label{eq:mean_cov_gp}
\end{equation}
```
where N denotes the normal distribution. For simplicity we assume the prior mean function to be zero: m (x) = 0. This assumption is not restrictive because as more training points are observed the prior is updated and becomes more informative. The following covariance functions are considered in this work (Shahriari et al. 2015): being specified is the similarity between two values of a function evaluated on each object A. There are many other choices of covariance functions available which may be better suited to a

```{r, echo=FALSE, message=FALSE, error=FALSE, eval=TRUE, fig.align='center'}
library(tidyverse)
library(kableExtra)
df <- data.frame(key = c("Gaussain", 
                         "Matern $\\mu=\\frac{5}{2}$", 
                         "Matern $\\mu=\\frac{3}{2}$",
                         "Exponetial",
                         "Power-Exponetial"), 
                 equation = c("$\\Large \\kappa (u,u') =\\sigma_f^2 exp(-\\frac{h^2}{2\\ell^2})$",
"$\\Large \\kappa (u,u') =\\sigma_f^2(1 + \\frac{\\sqrt{5}|h|}{\\ell}\\frac{5h^2}{3\\ell^2})exp(-\\frac{ -\\sqrt{5}|h|}{\\ell})$",
"$\\Large \\kappa (u,u') =\\sigma_f^2(1 + \\frac{\\sqrt{3}|h|}{\\ell})exp(-\\frac{-\\sqrt{3}|h|}{\\ell})$",
"$\\Large \\kappa (u,u') =\\sigma_f^2 exp(-\\frac{|h|}{\\ell})$",
"$\\Large \\kappa (u,u') =\\sigma_f^2 exp(-(\\frac{|h|}{\\ell})^p)$"
))

colnames(df) <- c("Covariance Kernels","assumeing $h=||x-x'||$")

kbl(df, booktabs = T,escape = FALSE, format = "latex") %>%
  kable_styling(position = "center", latex_options = "HOLD_position", full_width = T)
```

In this work:

```{=tex}
\begin{equation}
\kappa (u,u') =\sigma_f^2(1 + \frac{\sqrt{5}|h|}{\ell}\frac{5h^2}{3\ell^2})exp(-\frac{-\sqrt{5}|h|}{\ell})
\label{eq:kernels}
\end{equation}
```
Where $\ell$ lengthscale, and $h$ is eludian distance of $u$, $u'$ ($|h|^2=(u-u')^\intercal(u-u')$). Given $N$ observations of the objective function $J(u)$ at points $x_i$, the complete covariance/kernel matrix is given by:

Since we assume this holds for any $M>0$ this includes the case where , where $M=N+1$, containig $N$ training points $u_n$ and 1 test point $x^*$ Thus we can infer $f(u^*)$ from knowledge of $f(x_1), \cdots,f(x_N)$ by manupulating the joint gaussian distribution $p(f(x1), \cdots, f(xn), f(x*))$

```{=tex}
\begin{equation}
\left (
\begin{array}{ccc}
\begin{array}{l}
\kappa(\mathbf{u_1},\mathbf{u_2})
\end{array}
& \cdots & 
\begin{array}{l}
\kappa(\mathbf{u_1},\mathbf{u_N})
\end{array} \\
\vdots & \ddots & \vdots\\
\begin{array}{l}
\kappa(\mathbf{u_N},\mathbf{u_1})
\end{array} &
\cdots & 
\begin{array}{l}
\kappa(\mathbf{u_N},\mathbf{u_N})
\end{array} 
\end{array}
\right )
\label{eq:kernel_struct}
\end{equation}
```
<!-- $$\left ( -->

<!-- \begin{array}{ccc} -->

<!-- \begin{array}{l} -->

<!-- \kappa(\mathbf{u_1},\mathbf{u_2}) -->

<!-- \end{array} -->

<!-- & \cdots &  -->

<!-- \begin{array}{l} -->

<!-- \kappa(\mathbf{u_1},\mathbf{u_N}) -->

<!-- \end{array} \\ -->

<!-- \vdots & \ddots & \vdots\\ -->

<!-- \begin{array}{l} -->

<!-- \kappa(\mathbf{u_N},\mathbf{u_1}) -->

<!-- \end{array} & -->

<!-- \cdots &  -->

<!-- \begin{array}{l} -->

<!-- \kappa(\mathbf{u_N},\mathbf{u_N}) -->

<!-- \end{array}  -->

<!-- \end{array} -->

<!-- \right )$$ -->

Suppose we observe a training set $\mathcal{D}={(u_n,J(u_n) : n=1:N )}$ g, where $J(u_n)$ is the noise-free observation of the function evaluated at $u_n$. Now we consider the case of predicting the outputs for new inputs that may not be in $\mathcal{D}$. Specifically, given a test set (prediction set) set $U^*$ of size $N_* \times D$, we want to predict the function outputs $J^* = [J(u_1),\cdots, J(x_{N_*})]$. By definition of the GP, the joint distribution $p(f(X); f^*(J_X); X^*)$ has the following form

```{=tex}
\begin{equation}
\begin{bmatrix}  {\bf {J}_U}  \\  {{\bf J}_*} \end{bmatrix} \sim \mathcal{N} \begin{pmatrix} (\begin{bmatrix}  {{\bf \mu}_U}  \\  {{\bf \mu}_*} \end{bmatrix}),\begin{bmatrix} {{\bf K}_{X,X}}  & {{\bf
K}_{U,*}}  \\  {{\bf \mathbf{K}^\intercal}_{X,*}} & {{\bf K}_{*,*} } \end{bmatrix}\end{pmatrix}
\label{eq:gp_model}
\end{equation}
```
```{=tex}
\begin{equation}
 \begin{split}
K_{X,X} = {\Large \kappa} (X,X; \theta) , \; \; \; \; \; \ size (N \times  N) \\
K_{X,\ast} = {\Large \kappa} (X,X_\ast; \theta), \; \; \; \; \; \ size (N \times N_*) \\
K_{\ast,\ast} = {\Large \kappa} (X_\ast, X_\ast; \theta), \; \; \; \; \; \ size(N_\ast \times N_\ast)
 \end{split}
\label{eq:cov_sign}
\end{equation}
```
#### Covariance Kernel, Parameter estimation

```{=tex}
\begin{equation}
p(y|\bf{X,\theta}) = \int p(y|\bf{f,X})p(f|\bf{X,\theta})
\label{eq:lig_int}
\end{equation}
```
```{=tex}
\begin{equation}
\text{log} p(y|\bf{X,\theta})=\mathcal{L}(\zeta,\sigma_f^2)=-\frac{1}{2}(y-\mu_X)^{\intercal}\mathbf{K}_{X,X}^{-1}(y-\mu_X)-\frac{1}{2}log|K_{X,X}|-\frac{n}{2}log(2\pi)
\label{eq:log_like}
\end{equation}
```
Where the dependence of the $\bf{K}_{X,X}$ on $\theta$ is implicit.The gradient-based optimizer is performed in order to:

```{=tex}
\begin{equation}
[\zeta^\ast, \sigma_f^{2\ast}]=argmax\mathcal{L}(\zeta,\sigma^2_f)
\label{eq:log_like_opt}
\end{equation}
```
However, since the objective $\mathcal{L}$ is not convex, local minima can be a problem, so we may need to use multiple restarts.

------------------------------------------------------------------------

------------------------------------------------------------------------

<!-- -   Step 1. Choose some initial design points and build a probabilistic -->

<!--     model over the space of possible objective $f$, this probabilistic -->

<!--     model serves as prior. -->

<!-- -   Step 2. Combine prior and the likelihood to get a posterior of -->

<!--     probabilistic model over the objective given some observations. -->

<!-- -   Step 3. Use the posterior to decide where to take the next -->

<!--     evaluation $\bf{x^*}$ according to some policy for decision making. -->

<!-- -   Step 4. Evaluet the $f$ at $\bf{x^*}$ and augment it to the initial -->

<!--     data, in step 1. -->

<!-- Iterate between 2 and 4 until the evaluation budget is over. \#\# 3.1 -->

<!-- Gaussian Process -->

<!-- \newpage -->

<!-- ### Step 1. Probalistic Model as Prior -->

<!-- #### Gaussian Process (GP) -->

<!-- reference to the book [@murphy2022] -->

<!-- Key Assumption in (GP) is that: the function values at a set of $M > 0$ -->

<!-- inputs, $\bf{f} = [f(x_1), ...,f(x_M)]$, is jointly Gaussian, with mean -->

<!-- and Covariance -->

<!-- ```{=tex} -->

<!-- \begin{equation} -->

<!-- (\mu = m(x_1),...m(x_M)) -->

<!-- \sum_{i,j}= \kappa(x_i,x_j) -->

<!-- \label{eq:mean_cov} -->

<!-- \end{equation} -->

<!-- ``` -->

<!-- and $\kappa$ is a positive definite (Mercer) kernel.  -->

<!-- Now we consider the case of predicting the outputs for new inputs that may not be in D. Specifically, given a test set X∗ of size N∗ × D, we want to predict the function outputs f∗ = [f(x1); : : : ; f(xN∗)]. By definition of the GP, the joint distribution p(fX; f∗jX; X∗) has the following form -->

<!-- ```{=tex} -->

<!-- \begin{equation} -->

<!-- \bf{f_{*}} = [f(x_1),.., f(x_{N_{*}})] -->

<!-- \label{eq:pred_fun} -->

<!-- \end{equation} -->

<!-- ``` -->

<!-- By definition of the GP, the joint distribution $p(\bf{f_X},f|X,X_*)$ -->

<!-- has the following form: -->

<!-- ```{=tex} -->

<!-- \begin{equation} -->

<!-- \begin{bmatrix}  {\bf {f}_X}  \\  {{\bf f}_*} \end{bmatrix} \sim\mathcal{N} \begin{pmatrix} (\begin{bmatrix}  {{\bf \mu}_X}  \\  {{\bf \mu}_*} \end{bmatrix}),\begin{bmatrix} {{\bf K}_{X,X}}  & {{\bf -->

<!-- K}_{X,*}}  \\  {{\bf \mathbf{K}^\intercal}_{X,*}} & {{\bf K}_{*,*} } \end{bmatrix}\end{pmatrix} -->

<!-- \label{eq:gp_model} -->

<!-- \end{equation} -->

<!-- ``` -->

<!-- ```{=tex} -->

<!-- \begin{equation} -->

<!--   \begin{split} -->

<!-- \mu_X = [m(x_1),...,m(x_N)] \\  -->

<!-- \mu^\ast = [m(x^\ast_1,...m(x^\ast_N))] -->

<!--   \end{split} -->

<!-- \label{eq:mu_val} -->

<!-- \end{equation} -->

<!-- ``` -->

<!-- ```{=tex} -->

<!-- \begin{equation} -->

<!--  \begin{split} -->

<!-- K_{X,X} = {\Large \kappa} (X,X; \theta) , \; \; \; \; \; \ size (N \times  N) \\ -->

<!-- K_{X,\ast} = {\Large \kappa} (X,X_\ast; \theta), \; \; \; \; \; \ size (N \times N_*) \\ -->

<!-- K_{\ast,\ast} = {\Large \kappa} (X_\ast, X_\ast; \theta), \; \; \; \; \; \ size(N_\ast \times N_\ast) -->

<!--  \end{split} -->

<!-- \label{eq:cov_sign} -->

<!-- \end{equation} -->

<!-- ``` -->

<!-- ```{=tex} -->

<!-- \begin{equation} -->

<!-- {\Large \kappa} (x,x'; ;\theta) = (1 + \frac{\sqrt{5}|h|}{\theta} + \frac{5h^2}{3\theta^2})exp(-\frac{-\sqrt{5}|h|}{\theta} -->

<!-- \label{eq:pred_fun1} -->

<!-- \end{equation} -->

<!-- ``` -->

<!-- #### Covariance Kernel, Parameter estimation -->

<!-- ```{=tex} -->

<!-- \begin{equation} -->

<!-- p(y|\bf{X,\theta}) = \int p(y|\bf{f,X})p(f|\bf{X,\theta}) -->

<!-- \label{eq:lig_int} -->

<!-- \end{equation} -->

<!-- ``` -->

<!-- ```{=tex} -->

<!-- \begin{equation} -->

<!-- \text{log} p(y|\bf{X,\theta})=\mathcal{L}(\zeta,\sigma_f^2)=-\frac{1}{2}(y-\mu_X)^{\intercal}\mathbf{K}_{X,X}^{-1}(y-\mu_X)-\frac{1}{2}log|K_{X,X}|-\frac{n}{2}log(2\pi) -->

<!-- \label{eq:log_like} -->

<!-- \end{equation} -->

<!-- ``` -->

<!-- Where the dependence of the $\bf{K}_{X,X}$ on $\theta$ is implicit.The -->

<!-- gradient-based optimizer is performed in order to: -->

<!-- ```{=tex} -->

<!-- \begin{equation} -->

<!-- [\zeta^\ast, \sigma_f^{2\ast}]=argmax\mathcal{L}(\zeta,\sigma^2_f) -->

<!-- \label{eq:log_like_opt} -->

<!-- \end{equation} -->

<!-- ``` -->

<!-- However, since the objective $\mathcal{L}$ is not convex, local minima -->

<!-- can be a problem, so we may need to use multiple restarts. -->

<!-- ### Step 2. Posterior of Probabilistic Model -->

<!-- #### Posterior of Gaussain Process, (conditioning on initial data) -->

<!-- Here in @ref(fig:gaus-norm) -->

<!-- ```{r gaus-norm, echo=FALSE, fig.align='center', out.width="400px", out.height="100px", fig.retina=2, fig.cap="proof of"} -->

<!-- knitr::include_graphics("img/gaus_norm.png") -->

<!-- ``` -->

<!-- ```{=tex} -->

<!-- \begin{equation} -->

<!-- p(f_\ast|X_\ast,\mathcal{D}) = \mathcal{N}(f_\ast|{{\bf \mu}_\ast} , \scriptsize{\sum}_{\ast}\normalsize) -->

<!-- \label{eq:post_proba} -->

<!-- \end{equation} -->

<!-- ``` -->

<!-- ```{=tex} -->

<!-- \begin{equation} -->

<!--   \begin{split} -->

<!-- {{\bf \mu}_\ast}=m(\bf X_\ast) +{\bf \mathbf{K}^\intercal}_{X,*}{\bf \mathbf{K}^{-1}}_{X,X}(f_X-m(X)) \\ -->

<!-- \scriptsize{\sum}_{\ast}=\normalsize{\mathbf{K}_{\ast,\ast}-\mathbf{K}^\intercal_{X,\ast}\mathbf{K}_{X,X}^{-1}\mathbf{K}_{X,\ast}} -->

<!--   \end{split} -->

<!-- \label{eq:post_mean_cov} -->

<!-- \end{equation} -->

<!-- ``` -->

<!-- ### Example of Step.1 and Step.2 -->

<!-- ```{r, echo=FALSE, message=FALSE, error=FALSE} -->

<!-- library(plgp) -->

<!-- library(mvtnorm) -->

<!-- plot_multivariate_gauss <- function(vector_of_x,eps) { -->

<!--   X <- matrix(vector_of_x,ncol = 1) -->

<!--   y <- sin(X) -->

<!--   D <- distance(X)  -->

<!--   Sigma <- exp(-D) + diag(eps, ncol(D)) -->

<!--   XX <- matrix(seq(-0.5, 2*pi + 0.5, length=100), ncol=1) -->

<!--   DXX <- distance(XX) -->

<!--   SXX <- exp(-DXX) + diag(eps, ncol(DXX)) -->

<!--   DX <- distance(XX, X) -->

<!--   SX <- exp(-DX)  -->

<!--   Si <- solve(Sigma) -->

<!--   mup <- SX %*% Si %*% y -->

<!--   Sigmap <- SXX - SX %*% Si %*% t(SX) -->

<!--   YY <- rmvnorm(100, mup, Sigmap) -->

<!--   q1 <- mup + qnorm(0.05, 0, sqrt(diag(Sigmap))) -->

<!--   q2 <- mup + qnorm(0.95, 0, sqrt(diag(Sigmap))) -->

<!--   matplot(XX, t(YY), type="l", col="gray", lty=1, xlab="x", ylab="y",  -->

<!--           main="Gaussian Process Regression") -->

<!--   points(X, y, pch=20, cex=2) -->

<!--   lines(XX, sin(XX), col="blue") -->

<!--   lines(XX, mup, lwd=2) -->

<!--   lines(XX, q1, lwd=2, lty=2, col=2) -->

<!--   lines(XX, q2, lwd=2, lty=2, col=2) -->

<!--   legend("topright", legend=c("A Sample", "True function", "90% CI", "90% CI", "Training Data"), -->

<!--          col=c("gray", "blue", "red","red","black"),lty=c(1,1,2,2,NA), -->

<!--          pch = c(NA, NA,NA,NA,20), -->

<!--          cex=0.8, box.col = "white",bg = "white", ncol = 2) -->

<!-- } -->

<!-- ``` -->

<!-- Assume $X=[0,3,5,6]$ and $f_X=sin(X)$, giving $\mathcal{D}=(X,f_X)$. -->

<!-- What is $p(f_\ast|X_\ast,\mathcal{D})$ -->

<!-- ```{r guass-1, echo=FALSE, fig.retina=2, out.width="100%", fig.cap="Gaussin Process Regression conditioned on 4 points"} -->

<!-- plot_multivariate_gauss(c(0,3,5,6), 10^-6) -->

<!-- ``` -->

<!-- Now we sample the point $X=1$, and add to $\mathcal{D}$ -->

<!-- ```{r guass-2, echo=FALSE, fig.retina=2, out.width="100%", out.height="50%",fig.cap= "Gaussin Process Regression conditioned on 5 points", fig.align='center'} -->

<!-- plot_multivariate_gauss(c(0,1,3,5,6), 10^-6) -->

<!-- ``` -->

<!-- ### Step.3 Deciding on next $\bf{x}^\ast$ based on Posterior -->

<!-- Posterior of the probalistic model quantify the uncertainty over the -->

<!-- space of the $f$. The question is what is the next $\bf{x}^\ast$ to be -->

<!-- sampled from the *expensive function*? -->

<!-- Define an utility function to collect new data points satisfying some -->

<!-- optimality criterion: optimization as decision making. -->

<!-- There are a few of policies in the literature of Bayesopt, here the -->

<!-- *Expected Improvement (EI)* policy will be used. -->

<!-- #### Expected Improvement as Policy for Decision Making -->

<!-- In Expected Improvement (EI) policy choose the next query point as the -->

<!-- one which has the highest expected improvement over the space of the -->

<!-- *expensive function* -->

<!-- ```{=tex} -->

<!-- \begin{equation} -->

<!-- utility(x;\theta,\mathcal{D})=\alpha_{EI}=\int_{y}^{}max(0,y-f)p(y|x;\theta,\mathcal{D}) -->

<!-- \label{eq:uti_int} -->

<!-- \end{equation} -->

<!-- ``` -->

<!-- $$utility(x;\theta,\mathcal{D})=\alpha_{EI}=\int_{y}^{}max(0,y-f)p(y|x;\theta,\mathcal{D}) \,dy$$ -->

<!-- However, we do not have access to the *expensive function*, $f$, -->

<!-- therefore we replace the $f$ with the best available solution found so -->

<!-- far, $y^+$ -->

<!-- ```{=tex} -->

<!-- \begin{equation} -->

<!-- utility(x;\theta,\mathcal{D})=\alpha_{EI}=\int_{y}^{}max(0,y-y^{\dagger})p(y|x;\theta,\mathcal{D}) \,dy -->

<!-- \label{eq:uti_int_2} -->

<!-- \end{equation} -->

<!-- ``` -->

<!-- $y^{+}$ : The best solution found in the training dataset $\mathcal{D}$ -->

<!-- The good news: The analytical form of the utility function is available -->

<!-- for the gaussian process -->

<!-- ```{=tex} -->

<!-- \begin{equation} -->

<!-- \gamma(\mathbf{x})=\frac{\mu(\mathbf{x;\theta,\mathcal{D}})-y^{\dagger}}{\sigma(\mathbf{x;\theta,\mathcal{D}})} -->

<!-- \label{eq:uti_int_gamma} -->

<!-- \end{equation} -->

<!-- ``` -->

<!-- ```{=tex} -->

<!-- \begin{equation} -->

<!-- utility(\mathbf{x};\theta,\mathcal{D})=\alpha_{EI}(x;\theta,\mathcal{D})=(\mu(x;\theta,\mathcal{D})-y^{\dagger})\Phi(\gamma(x)) + \sigma(x;\theta,\mathcal{D})\phi(\gamma(x)) -->

<!-- \label{eq:uti_int2} -->

<!-- \end{equation} -->

<!-- ``` -->

<!-- Where $\Phi(.)$ and $\phi(.)$ are CDF and PDF of standard Gaussian -->

<!-- distribution. -->

<!-- It is too greedy in the context of the sequential decision making. -->

<!-- Therefore, an explorative term is added as explorative" parameter -->

<!-- $\epsilon$. -->

<!-- ```{=tex} -->

<!-- \begin{equation} -->

<!-- \gamma(\mathbf{x})=\frac{\mu(\mathbf{x;\theta,\mathcal{D}})-y^{\dagger}-\epsilon}{\sigma(\mathbf{x;\theta,\mathcal{D}})} -->

<!-- \label{eq:uti_greed_gamma} -->

<!-- \end{equation} -->

<!-- ``` -->

<!-- ```{=tex} -->

<!-- \begin{equation} -->

<!-- \alpha_{EI}(x;\theta,\mathcal{D})=(\mu(x;\theta,\mathcal{D})-y^{\dagger}-\epsilon)\Phi(\gamma(x)) + \sigma(x;\theta,\mathcal{D})\phi(\gamma(x)) -->

<!-- \label{eq:uti_int_gred2} -->

<!-- \end{equation} -->

<!-- ``` -->

<!-- #### BO As a "mapping" between two problems -->

<!-- BO is an strategy to transform the problem -->

<!-- ```{=tex} -->

<!-- \begin{equation} -->

<!-- u_M = \underset{u\in \text{constraints}}{\mathrm{argmax}}\overline{J}(u) -->

<!-- \label{eq:exp_eq} -->

<!-- \end{equation} -->

<!-- ``` -->

<!-- unsolvabale! -->

<!-- ```{=tex} -->

<!-- \begin{equation} -->

<!-- u^{next}=\underset{u\in \text{constraints}}{\mathrm{argmax}} \alpha_{EI}(u;\mathcal{D}_n, \theta^\ast) -->

<!-- \label{eq:exp-easy} -->

<!-- \end{equation} -->

<!-- ``` -->

<!-- solvabale! -->

<!-- -   $\alpha_{EI}(u)$ is inexpensive to evaluate. -->

<!-- -   The analytical expression for gradient of $\alpha_{EI}(u)$ is -->

<!--     available. -->

<!-- -   Still need to find $u^{next}$, the multi-start BFGS is used for -->

<!--     finding $u^{next}$. -->
