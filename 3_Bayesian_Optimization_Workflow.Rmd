---
bibliography: references.bib
---

# Bayesian Optimization Workflow

## Overall View

Bayesian Optimization (BO) is an optimization method that builds a probabilistic model to mimic an expensive objection function. The probabilistic model is a inference from a finite number of function evaluations. These finite number of evaluations is done as initialization of the workflow and build a probabilistic model.

After initialization and building a probabilistic model, at each iteration, a new query point is evaluated using the the expensive objective function, then the new data $(u^{new},f(u^{new}))$ is assimilated back to probabilistic model to update the model.The unique methodology of using a non-deterministic surrogate model makes Bayesian optimization (BO) an efficient global optimizer capable of both  exploration and exploitation of space of decision.

## Gaussian Process

In this work, we employ the widely used Gaussian process (GP) as the probabilistic model. Known also as surrogate model (since it tries to mimic the real, expensive objective function), GPs are attractive because they are computationally traceable with capability to quantity the uncertainty of interest [@rasmussen2006; @murphy2022]. A Gaussian process can be seen as an extension of the Gaussian distribution to the functional space. Key Assumption in (GP) is that: the function values at a set of $M > 0$ inputs, $\mathbf{J} = [J({u_1}), ...,J(u_M)]$, is jointly Gaussian, with mean and Covariance defined as:

```{=tex}
\begin{equation}
  \begin{split}
& \mathbb{E} \: [\mathbf{J(u)}]= m(\mathbf{u}) \\
& \text{Cov} \: [\mathbf{J(u)}),J(\mathbf{J(u')}]= \kappa(\mathbf{u},\mathbf{u'})
  \end{split}
\label{eq:mean-cov}
\end{equation}
```

Note: Here we use the objective function described in previous section with the notation $\overline{\mathbf{J(u)}}$, where $\mathbf{u}$ is control variables. However, just for simplicity in notation, we drop the bar sign and write objective function with ${\mathbf{J(u)}}$.

In \@ref(eq:mean-cov), $m(\mathbf{u})$ is a mean function and $\kappa(\mathbf{u},\mathbf{u'})$ is a covariance function (or kernel). $\kappa(\mathbf{u},\mathbf{u'})$ specifies the similarity between two values of a function evaluated on $\mathbf{u}$, and $\mathbf{u'}$ . A GP is a distribution over functions completely defined by its mean and covariance function as:

```{=tex}
\begin{equation}
J(\mathbf{u}) \sim \mathcal{N}(m(\mathbf{u}), \kappa(\mathbf{u},\mathbf{u'}))
\label{eq:mean_cov_gp}
\end{equation}
```

where $\mathcal{N}$ denotes the multivariate normal distribution. As was discussed in [@shahriari2016] there many choice for the covariance function, most commonly used ones in the literature has been depicted in the Table \@ref(tab:cov-tab).

```{r cov-table, echo=FALSE, message=FALSE, error=FALSE, eval=TRUE, fig.align='center'}
library(tidyverse)
library(kableExtra)
df <- data.frame(key = c("Gaussain", 
                         "Matern $\\mu=\\frac{5}{2}$", 
                         "Matern $\\mu=\\frac{3}{2}$",
                         "Exponetial",
                         "Power-Exponetial"), 
                 equation = c("$\\Large \\kappa (u,u') =\\sigma_f^2 exp(-\\frac{h^2}{2\\ell^2})$",
"$\\Large \\kappa (u,u') =\\sigma_f^2(1 + \\frac{\\sqrt{5}|h|}{\\ell}\\frac{5h^2}{3\\ell^2})exp(-\\frac{ -\\sqrt{5}|h|}{\\ell})$",
"$\\Large \\kappa (u,u') =\\sigma_f^2(1 + \\frac{\\sqrt{3}|h|}{\\ell})exp(-\\frac{-\\sqrt{3}|h|}{\\ell})$",
"$\\Large \\kappa (u,u') =\\sigma_f^2 exp(-\\frac{|h|}{\\ell})$",
"$\\Large \\kappa (u,u') =\\sigma_f^2 exp(-(\\frac{|h|}{\\ell})^p)$"
))

colnames(df) <- c("Covariance Kernels","assumeing $h=||x-x'||$")

kbl(df, booktabs = T,escape = FALSE, format = "html", caption=" Several types of covariance function for the GP process") %>%
  kable_styling(position = "center", latex_options = "HOLD_position", full_width = T)
```

Where in the Table \@ref(tab:cov-tab), $\ell$ is lengthscale, and $h$ is eludian distance of $u$, $u$. ( Note that $|h|^2=(u-u')^\intercal(u-u')$). In this work, Matern Covariance function with $\nu=\frac{5}{2}$ was employed. 

### Step 1. Choose some initial design points to build probalistic model conditional to those points 

Assuming we start GP with finite number of initial evaluation of $\mathbf{J(u)}$ on the points in $\mathbf{U}$, we can define the dataset $\mathcal{D}$ as: 

```{=tex}
\begin{align*}
  \begin{split}
\mathbf{U}= & \: [\mathbf{u_1},\cdots,\mathbf{u_N}] \\
\mathbf{J_U}= & \: [\mathbf{J(u_1)},\cdots,\mathbf{J(u_N)}] \\
\mathcal{D}= & \: \{\mathbf{U},\mathbf{\mathbf{J_U}}\}
  \end{split}
\label{eq:init-data}
\end{align*}
```

Now we consider the case of predicting the outputs for new inputs that are not be in $\mathcal{D}$. Specifically, given a test set (prediction set) set $\mathbf{U_*}$ of size $N_* \times D$, we want to predict the function outputs $\mathbf{J_*} = [\mathbf{J(u_1)},\cdots, \mathbf{J(u_{N_*})}]$. By definition of the GP, the joint distribution $p(\mathbf{{J}_{U}}, \mathbf{J}_*| \mathbf{U}, \mathbf{U_*})$ has the following form:

```{=tex}
\begin{equation}
\begin{bmatrix}  {\bf {J}_U}  \\  {{\bf J}_*} \end{bmatrix} \sim \mathcal{N} \begin{pmatrix} \begin{bmatrix}  {m(\mathbf{U})}  \\  {m(\mathbf{U^*})} \end{bmatrix},\begin{bmatrix} {{\bf K}_{U,U}}  & {{\bf
K}_{U,*}}  \\  {{\bf \mathbf{K}^\intercal}_{U,*}} & {{\bf K}_{*,*} } \end{bmatrix}\end{pmatrix}
\label{eq:gp-model-mat}
\end{equation}
```

Where,$m(\mathbf{U})$ is prior knolwdge about mean value of $\mathbf{J_U}$, defined as $m(\mathbf{U})=[m(\mathbf{u_1}),\cdots,m(\mathbf{u_N})]$. For simplicity someone can assume the prior mean function to be zero: $m(\mathbf{U}) = 0$. This assumption is not restrictive because as more training points are observed the prior is updated and becomes more informative. In this work, we considered the case where the mean function could have linear trend in the form of:


```{=tex}
\begin{equation}
m(\mathbf{u}) = \sum_{j=1}^p \beta_j \mathbf{u}
\label{eq:linear-mean}
\end{equation}
```


The *Gram* matrix, $\mathbf{K}_{U,U}$, is $N \times N$ matrix, with each element is covariance of $\mathbf{u}$ and $\mathbf{u'}$:

```{=tex}
\begin{equation}
\mathbf{K}_{U,U}=\kappa(\mathbf{U,U})=\left (
\begin{array}{ccc}
\begin{array}{l}
\kappa(\mathbf{u_1},\mathbf{u_2})
\end{array}
& \cdots & 
\begin{array}{l}
\kappa(\mathbf{u_1},\mathbf{u_N})
\end{array} \\
\vdots & \ddots & \vdots\\
\begin{array}{l}
\kappa(\mathbf{u_N},\mathbf{u_1})
\end{array} &
\cdots & 
\begin{array}{l}
\kappa(\mathbf{u_N},\mathbf{u_N})
\end{array} 
\end{array}
\right )
\label{eq:kernel_struct}
\end{equation}
```

By the standard rules for conditioning mutivariate gaussain distribution,we can drive the posterior (conditional distribution of $\mathbf{J(U_*)}$ given the $\mathcal{D}$, in closed form as following:

```{=tex}
\begin{align*}
  \begin{split}
p(\mathbf{J}_*|\mathbf{U_*,\mathcal{D})}= & \:  \mathcal{N}(\mathbf{J_*| \mathbf{\mu_*},\textstyle \sum_{\ast}}) \\
{\mathbf{\mu_\ast}}= & \:  m(\mathbf{U_\ast}) +\mathbf{K}^\intercal_{U,*} \mathbf{K}^{-1}_{U,U}(\mathbf{J}_U-m(\mathbf{U})) \\
\textstyle \sum_{\ast}=& \:  \normalsize{\mathbf{K}_{\ast,\ast}-\mathbf{K}^\intercal_{U,\ast}\mathbf{K}_{U,U}^{-1}\mathbf{K}_{U,\ast}}
  \end{split}
\label{eq:post_mean_cov}
\end{align*}
```

#### Parameter Estimation of Covariance Kernel

As it shown in the \@ref(tab:cov-tab), the Matern Covariance function with $\nu=\frac{5}{2}$ has two parametrs to be estimated, namely $\sigma^2_f$ and $\ell$.

```{=tex}
\begin{equation}
p(y|\bf{X,\theta}) = \int p(y|\bf{f,X})p(f|\bf{X,\theta})
\label{eq:lig_int}
\end{equation}
```

```{=tex}
\begin{equation}
\text{log} p(y|\bf{X,\theta})=\mathcal{L}(\zeta,\sigma_f^2)=-\frac{1}{2}(y-\mu_X)^{\intercal}\mathbf{K}_{X,X}^{-1}(y-\mu_X)-\frac{1}{2}log|K_{X,X}|-\frac{n}{2}log(2\pi)
\label{eq:log_like}
\end{equation}
```

Where the dependence of the $\bf{K}_{X,X}$ on $\theta$ is implicit.The gradient-based optimizer is performed in order to:

```{=tex}
\begin{equation}
[\zeta^\ast, \sigma_f^{2\ast}]=argmax\mathcal{L}(\zeta,\sigma^2_f)
\label{eq:log_like_opt}
\end{equation}
```
However, since the objective $\mathcal{L}$ is not convex, local minima can be a problem, so we may need to use multiple restarts.

### Step.2 Deciding on next $\bf{u}^{next}$ based on brobalistic model

Posterior of the probalistic model quantify the uncertainty over the space of the unknown function, $f$. The question is what is the next $\mathbf{u}^\ast$ to be sampled from the *expensive function*? One could select the next point arbitrarily but that would be wasteful.

To answer this question, we define an utility function and the next query point is the point which has the maximum utility. The literature of BO have seen many utility function (called acquisition function in the computer science community). These include the Improvement based policies (Probability of Improvement (PI), Expected Improvement(EI)), optimistic policies (Upper Confidence Bound (UCB)) or Information-based (like Thompson Sampling (TS)). The full review of these utility function an their strengthen and weakness could be reviewed in [@shahriari2016].

In Expected Improvement (EI) policy choose the next query point as the one which has the highest expected improvement over the space of the *expensive function*

```{=tex}
\begin{equation}

utility(u;\theta,\mathcal{D})=\alpha_{EI}=\int_{y}^{}max(0,\mathbf{J}(u_*)-f)p(\mathbf{J}(\mathbf{u_*})|\mathcal{D}) \,dy

\label{eq:uti_int}

\end{equation}
```


However, we do not have access to the *expensive function*, $f$, therefore we replace the $f$ with the best available solution found so far, $\mathbf{J}^+$ . We would like to note that $\mathbf{u}_*$ is

```{=tex}
\begin{eqution}

utility(u;\theta,\mathcal{D})=\alpha_{EI}=\int_{y}^{}max(0,\mathbf{J}(u_*)-\mathbf{J}^+)p(\mathbf{J}(\mathbf{u_*})|\mathcal{D}) \,dy

\label{eq:uti_int_2}

\end{equation}
```


