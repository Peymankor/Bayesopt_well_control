
@misc{2019dshb,
  title = {Feature {{Selection}} Using {{Genetic Algorithms}} in {{R}}},
  year = {2019},
  month = jan,
  abstract = {From a gentle introduction to a practical solution, this is a post about feature selection using genetic algorithms in R.},
  howpublished = {https://blog.datascienceheroes.com/feature-selection-using-genetic-algorithms-in-r/},
  journal = {Data Science Heroes Blog},
  language = {en},
  organization = {{Data Science Heroes Blog}}
}

@misc{2019dshba,
  title = {Feature {{Selection}} Using {{Genetic Algorithms}} in {{R}}},
  year = {2019},
  month = jan,
  abstract = {From a gentle introduction to a practical solution, this is a post about feature selection using genetic algorithms in R.},
  howpublished = {https://blog.datascienceheroes.com/feature-selection-using-genetic-algorithms-in-r/},
  journal = {Data Science Heroes Blog},
  language = {en}
}

@misc{2019ys,
  title = {Gaussian {{Process}}, Not Quite for Dummies},
  year = {2019},
  month = sep,
  abstract = {Before diving inFor a long time, I recall having this vague impression about Gaussian Processes (GPs) being able to magically define probability distributions over sets of functions, yet I procrastinated reading up about them for many many moons. However, as always, I'd like to think that this is not just due to my procrastination superpowers. Whenever I look up ``Gaussian Process'' on Google, I find these well-written tutorials with vivid plots that explain everything up until non-linear regression in detail, but shy away at the very first glimpse of any sort of information theory. The key takeaway is always, A Gaussian process is a probability distribution over possible functions that fit a set of points.},
  howpublished = {https://yugeten.github.io/posts/2019/09/GP/},
  journal = {Yuge Shi},
  language = {en}
}

@article{2021w,
  title = {Amdahl's Law},
  year = {2021},
  month = feb,
  abstract = {In computer architecture, Amdahl's law (or Amdahl's argument) is a formula which gives the theoretical speedup in latency of the execution of a task at fixed workload that can be expected of a system whose resources are improved. It is named after computer scientist Gene Amdahl, and was presented at the AFIPS Spring Joint Computer Conference in 1967. Amdahl's law is often used in parallel computing to predict the theoretical speedup when using multiple processors. For example, if a program needs 20 hours to complete using a single thread, but a one-hour portion of the program cannot be parallelized, therefore only the remaining 19 hours (p = 0.95) of execution time can be parallelized, then regardless of how many threads are devoted to a parallelized execution of this program, the minimum execution time cannot be less than one hour. Hence, the theoretical speedup is limited to at most 20 times the single thread performance,                                    (                                                                           1                                        1                     -                     p                                                                             =             20                      )                          \{\textbackslash displaystyle \textbackslash left(\{\textbackslash dfrac \{1\}\{1-p\}\}=20\textbackslash right)\}   .},
  annotation = {Page Version ID: 1006721080},
  copyright = {Creative Commons Attribution-ShareAlike License},
  journal = {Wikipedia},
  language = {en}
}

@article{2021wa,
  title = {Computational Complexity of Mathematical Operations},
  year = {2021},
  month = jun,
  abstract = {The following tables list the computational complexity of various algorithms for common mathematical operations. Here, complexity refers to the time complexity of performing computations on a multitape Turing machine. See big O notation for an explanation of the notation used. Note: Due to the variety of multiplication algorithms,                         M         (         n         )                 \{\textbackslash displaystyle M(n)\}    below stands in for the complexity of the chosen multiplication algorithm.},
  annotation = {Page Version ID: 1028958664},
  copyright = {Creative Commons Attribution-ShareAlike License},
  journal = {Wikipedia},
  language = {en}
}

@misc{aa,
  title = {Numerical {{Optimization}}: {{Understanding L}}-{{BFGS}}},
  shorttitle = {Numerical {{Optimization}}},
  abstract = {Numerical optimization is at the core of much of machine learning. In this post, we derive the L-BFGS algorithm, commonly used in batch machine learning applications.},
  howpublished = {http://aria42.com/blog/2014/12/understanding-lbfgs},
  journal = {aria42},
  organization = {{aria42}}
}

@article{adams,
  title = {A {{Tutorial}} on! {{Bayesian Optimization}}! For {{Machine Learning}}},
  author = {Adams, Ryan P},
  pages = {45},
  file = {/home/peyman/Zotero/storage/T3SG9A73/Adams - A Tutorial on! Bayesian Optimization! for Machine .pdf},
  language = {en}
}

@article{agnihotri2020d,
  title = {Exploring {{Bayesian Optimization}}},
  author = {Agnihotri, Apoorv and Batra, Nipun},
  year = {2020},
  month = may,
  volume = {5},
  pages = {e26},
  issn = {2476-0757},
  doi = {10.23915/distill.00026},
  abstract = {How to tune hyperparameters for your machine learning model using Bayesian optimization.},
  journal = {Distill},
  language = {en},
  number = {5}
}

@article{agnihotri2020da,
  title = {Exploring {{Bayesian Optimization}}},
  author = {Agnihotri, Apoorv and Batra, Nipun},
  year = {2020},
  month = may,
  volume = {5},
  pages = {e26},
  issn = {2476-0757},
  doi = {10.23915/distill.00026},
  abstract = {How to tune hyperparameters for your machine learning model using Bayesian optimization.},
  journal = {Distill},
  language = {en},
  number = {5}
}

@article{agnihotri2020db,
  title = {Exploring {{Bayesian Optimization}}},
  author = {Agnihotri, Apoorv and Batra, Nipun},
  year = {2020},
  month = may,
  volume = {5},
  pages = {e26},
  issn = {2476-0757},
  doi = {10.23915/distill.00026},
  abstract = {How to tune hyperparameters for your machine learning model using Bayesian optimization.},
  journal = {Distill},
  language = {en},
  number = {5}
}

@article{al2020c&ce,
  title = {Stochastic Simulation-Based Superstructure Optimization Framework for Process Synthesis and Design under Uncertainty},
  author = {Al, Resul and Behera, Chitta Ranjan and Gernaey, Krist V. and Sin, G{\"u}rkan},
  year = {2020},
  month = dec,
  volume = {143},
  pages = {107118},
  issn = {0098-1354},
  doi = {10.1016/j.compchemeng.2020.107118},
  abstract = {Advances in simulation and optimization technologies coupled with the continued growth in computing power now increasingly pave the way for the development of advanced model-based engineering design frameworks. In this work, we propose an extensive computational framework, which brings together state-of-the-art engineering practices, such as high fidelity process simulation, superstructure-based conceptual design, global sensitivity analysis, Monte Carlo procedures for uncertainty quantification, and a stochastic simulation-based design space optimizer in order to foster decision making under uncertainty. The capabilities of the framework are highlighted in a case study, which addresses the challenges of how to synthesize and design wastewater treatment plant configurations under influent uncertainties. In order to handle multiple stochastic constraints, a black-box solver using a new infill criterion for surrogate-based optimization is also proposed. The results demonstrate the promising potential of the simulation and sampling-based framework for effectively addressing stochastic design problems arising in broader engineering domains.},
  file = {/home/peyman/Zotero/storage/VZTEGQT2/Al et al. - 2020 - Stochastic simulation-based superstructure optimiz.pdf},
  journal = {Computers \& Chemical Engineering},
  keywords = {Monte Carlo simulation,Simulation-based optimization,Stochastic Kriging,Superstructure optimization,Wastewater treatment plant design},
  language = {en}
}

@article{albertoni2003sreeb,
  ids = {albertoni2003sree},
  title = {Inferring {{Interwell Connectivity Only From Well}}-{{Rate Fluctuations}} in {{Waterfloods}}},
  author = {Albertoni, Alejandro and Lake, Larry W.},
  year = {2003},
  month = feb,
  volume = {6},
  pages = {6--16},
  issn = {1094-6470, 1930-0212},
  doi = {10.2118/83381-PA},
  abstract = {This paper presents a practical technique to quantify communication between wells in a reservoir using only production and injection rate data. The technique combines a constrained multivariate linear regression analysis with diffusivity filters to provide information about permeability trends and the presence of transmissibility barriers. The method was developed and tested using a numerical simulator and then applied to a waterflooded field in Argentina. The simulation results indicate that the connectivity between wells is described by coefficients that only depend on geology and relative position between wells; they are independent of injection/production rates. The results of this work can be used to improve the performance of an existing waterflood by suggesting how well patterns might be changed or managed. They could also be used to model flow in the reservoir.},
  file = {/home/peyman/Zotero/storage/5YN3H93A/Albertoni_Lake_2003_Inferring Interwell Connectivity Only From Well-Rate Fluctuations in Waterfloods.pdf;/home/peyman/Zotero/storage/KN5CVFTY/Albertoni and Lake - 2003 - Inferring Interwell Connectivity Only From Well-Ra.pdf;/home/peyman/Zotero/storage/SBR95897/Albertoni_Lake_2003_Inferring Interwell Connectivity Only From Well-Rate Fluctuations in Waterfloods.pdf},
  journal = {SPE Reservoir Evaluation \& Engineering},
  keywords = {1st},
  language = {en},
  number = {01}
}

@article{aliyev2017mga,
  title = {Multilevel {{Field Development Optimization Under Uncertainty Using}} a {{Sequence}} of {{Upscaled Models}}},
  author = {Aliyev, Elnur and Durlofsky, Louis J.},
  year = {2017},
  month = apr,
  volume = {49},
  pages = {307--339},
  issn = {1874-8961, 1874-8953},
  doi = {10.1007/s11004-016-9643-0},
  file = {/home/peyman/Zotero/storage/L92ZMP53/Aliyev and Durlofsky - 2017 - Multilevel Field Development Optimization Under Un.pdf;/home/peyman/Zotero/storage/UFFIZK8R/Aliyev_Durlofsky_2017_Multilevel Field Development Optimization Under Uncertainty Using a Sequence of.pdf},
  journal = {Mathematical Geosciences},
  language = {en},
  number = {3}
}

@article{almansour2020sreea,
  ids = {almansour2020sre&e},
  title = {Value-of-{{Information Analysis}} of a {{Fracture Prediction Method}}},
  author = {Almansour, Abdulaziz and Laubach, Stephen E. and Bickel, J. Eric and Schultz, Richard A.},
  year = {2020},
  month = aug,
  volume = {23},
  pages = {0811--0823},
  issn = {1094-6470, 1930-0212},
  doi = {10.2118/198906-PA},
  abstract = {A core-based fracture prediction method is used to illustrate a value-of-information (VOI) decision-analysis protocol to inform completion decisions in tight gas sandstones. The ratio of late host-rock cement to available pore volume (PV), or degradation index, uses petrographic observations of cement distributions in core (including sidewall cores) to predict whether nearby but unsampled fractures (widths {$>$} 0.5 to 1 mm) are sealed (nonconductive) or open (conductive). Measurements from four sandstone plays suggest that the index correctly predicts open vs. sealed fractures with an accuracy in excess of 80\%. The value added is calculated using Bayesian inference in which the accuracy of the index serves as the likelihood of the prior distribution of open fractures to assess the posterior probability that data represent a useful predictor of producibility. VOI of the prediction method is more than three times the cost to acquire the data. VOI is most sensitive to play-specific geologic and cost parameters including cost to drill, expected revenue from a successful well, cost of completion, cost of acquiring data for the index, and fracture probability distributions. The approach provides a way to value acquiring fracture data and points to a need for zone-specific production data in tight gas sandstones.},
  file = {/home/peyman/Zotero/storage/K3MGZAWR/Almansour et al_2020_Value-of-Information Analysis of a Fracture Prediction Method.pdf;/home/peyman/Zotero/storage/TJPUKKT5/Almansour et al_2020_Value-of-Information Analysis of a Fracture Prediction Method.pdf;/home/peyman/Zotero/storage/W3C7HXH9/Almansour et al. - 2020 - Value-of-Information Analysis of a Fracture Predic.pdf},
  journal = {SPE Reservoir Evaluation \& Engineering},
  keywords = {1st},
  language = {en},
  number = {03}
}

@article{almasov2021sj,
  title = {Life-{{Cycle Optimization}} of the {{Carbon Dioxide Huff}}-n-{{Puff Process}} in an {{Unconventional Oil Reservoir Using Least}}-{{SquaresSupport Vector}} and {{Gaussian Process Regression Proxies}}},
  author = {Almasov, Azad and Onur, Mustafa},
  year = {2021},
  month = may,
  pages = {1--32},
  issn = {1086-055X, 1930-0220},
  doi = {10.2118/201721-PA},
  abstract = {In this work, we investigate the efficient estimation of the optimal design variables that maximize net present value (NPV) for the lifecycle production optimization during a single-well carbon dioxide (CO2) huff-n-puff (HnP) process in unconventional oil reservoirs. A synthetic unconventional reservoir model based on Bakken Formation oil composition is used. The model accounts for the natural fracture and geomechanical effects. Both the deterministic (based on a single reservoir model) and robust (based on an ensemble of reservoir models) production optimization strategies are considered. The injection rate of CO2, the production bottomhole pressure (BHP), the duration of injection and the production periods in each cycle of the HnP process, and the cycle lengths for a predetermined lifecycle time can be included in the set of optimum design (or well control) variables. During optimization, the NPV is calculated by a machine learning (ML) proxy model trained to accurately approximate the NPV that would be calculated from a reservoir simulator run. Similar to the ML algorithms, we use both least-squares (LS) support vector regression (SVR) and Gaussian process regression (GPR). Given a set of forward simulation runs with a commercial compositional simulator that simulates the miscible CO2 HnP process, a proxy is built based on the ML method chosen. Having the proxy model, we use it in an iterative-sampling-refinement optimization algorithm directly to optimize the design variables. As an optimization tool, the sequential quadratic programming (SQP) method is used inside this iterative-sampling-refinement optimization algorithm. Computational efficiencies of the ML proxy-based optimization methods are compared with those of the conventional stochastic simplex approximate gradient (StoSAG)-based methods. Our results show that the LS-SVR- and GPR-based proxy models are accurate and useful in approximating NPV in the optimization of the CO2 HnP process. The results also indicate that both the GPR and LS-SVR methods exhibit very similar convergence rates, but GPR requires 10 times more computational time than LS-SVR. However, GPR provides flexibility over LS-SVR to access uncertainty in our NPV predictions because it considers the covariance information of the GPR model. Both ML-based methods prove to be quite efficient in production optimization, saving significant computational times (at least 4 times more efficient) over a stochastic gradient computed from a high-fidelity compositional simulator directly in a gradient ascent algorithm. To our knowledge, this is the first study presenting a comprehensive review and comparison of two different ML-proxy-based optimization methods with traditional StoSAG-based optimization methods for the production optimization problem of a miscible CO2 HnP.},
  file = {/home/peyman/Zotero/storage/CW8A7XX2/Almasov and Onur - 2021 - Life-Cycle Optimization of the Carbon Dioxide Huff.pdf},
  journal = {SPE Journal},
  language = {en}
}

@article{alpak2021sj,
  title = {Field-{{Development Optimization}} of the {{In}}-{{Situ Upgrading Process Including}} the {{Ramp}}-{{Up Phase}}},
  author = {Alpak, Faruk O. and Gao, Guohua},
  year = {2021},
  month = apr,
  pages = {1--16},
  issn = {1086-055X},
  doi = {10.2118/205395-PA},
  abstract = {Field-development optimization and optimization at the pattern scale are crucial to maximize the value of thermal enhanced-oil-recovery (EOR) projects. Application of a field net-present-value (NPV)-based pattern optimization algorithm honoring field-scale surface and subsurface constraints for in-situ-upgrading (IUP) projects has been described in the recent past. In this paper, we describe the development and application of a novel field-development-optimization capability, including the optimization of the ramp-up phase to accelerate the production to achieve a faster cash flow and high surface-facility utilization. We integrate this new capability into a robust field NPV optimization platform.A two-stagefield-development optimization algorithm is developed in this work. First, the steady-state pattern is optimized using the field-scale pattern optimization algorithm while honoring field-scale constraints and using a combined surface and subsurface performance-indicator-driven objective function. Ramp-up pattern designs are optimized separately using a solely pattern-scaleperformance-driven objective function in this stage. A preliminary pattern-delay time optimization follows next to precondition the problem for the subsequent field-scale optimization stage. The ramp-up pattern and pattern-delay times are optimized using a constant steady-state pattern in the second step of the algorithm. An appropriately penalized field-NPV-based objective function is used in this step to enforce field-scale surface and subsurface constraints.Optimization results on a realistic example application indicate that the time to oil-rate plateau could be significantly reduced on the order of multiple years while honoring the surface production constraints. This requires the use of an optimized ramp-up pattern in conjunction with the optimal steady-state pattern. The ramp-up pattern is approximately two patterns wide and features an increased heater density to deliver production acceleration. It is also notably more robust against the effects of subsurface uncertainties.},
  journal = {SPE Journal}
}

@article{audet2006sjo,
  title = {Mesh {{Adaptive Direct Search Algorithms}} for {{Constrained Optimization}}},
  author = {Audet, Charles and Dennis, J. E.},
  year = {2006},
  month = jan,
  volume = {17},
  pages = {188--217},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1052-6234},
  doi = {10.1137/040603371},
  abstract = {This paper addresses the problem of minimization of a nonsmooth function under general nonsmooth constraints when no derivatives of the objective or constraint functions are available. We introduce the mesh adaptive direct search (MADS) class of algorithms which extends the generalized pattern search (GPS) class by allowing local exploration, called polling, in an asymptotically dense set of directions in the space of optimization variables. This means that under certain hypotheses, including a weak constraint qualification due to Rockafellar, MADS can treat constraints by the extreme barrier approach of setting the objective to infinity for infeasible points and treating the problem as unconstrained.The main GPS convergence result is to identify limit points \$\textbackslash hat\{x\}\$, where the Clarke generalized derivatives are nonnegative in a finite set of directions, called refining directions. Although in the unconstrained case, nonnegative combinations of these directions span the whole space, the fact that there can only be finitely many GPS refining directions limits rigorous justification of the barrier approach to finitely many linear constraints for GPS. The main result of this paper is that the general MADS framework is flexible enough to allow the generation of an asymptotically dense set of refining directions along which the Clarke derivatives are nonnegative. We propose an instance of MADS for which the refining directions are dense in the hypertangent cone at \$\textbackslash hat\{x\}\$ with probability 1 whenever the iterates associated with the refining directions converge to a single \$\textbackslash hat\{x\}\$. The instance of MADS is compared to versions of GPS on some test problems. We also illustrate the limitation of our results with examples.An erratum to this article has been appended at the end of the pdf file.},
  file = {/home/peyman/Zotero/storage/W85SYZ8M/Audet_Dennis_2006_Mesh Adaptive Direct Search Algorithms for Constrained Optimization.pdf},
  journal = {SIAM Journal on Optimization},
  number = {1}
}

@inproceedings{barros2020ex,
  title = {Identification of {{Critical Operational Uncertainties}} in {{Field Development Planning Using Stochastic Gradients}}},
  booktitle = {{{ECMOR XVII}}},
  author = {Barros, E. and Hanea, R. and Hustoft, L. and Leeuwenburgh, O. and Fonseca, R.},
  year = {2020},
  pages = {1--12},
  publisher = {{European Association of Geoscientists \& Engineers}},
  address = {{Online Event,}},
  doi = {10.3997/2214-4609.202035173},
  abstract = {The development of oil and gas fields requires asset teams to make complex decisions in the presence of uncertainties. Studies of reservoir management strategies typically focus exclusively on geological uncertainties by working with an ensemble of reservoir model realizations. However, the development of hydrocarbon reservoirs is often also subject to operational uncertainties such as rig delays or drilling operation delays (which may in turn be related to unpredictable externalities of technical, economical, political or meteorological nature). Production attainment aims to minimize the associated economic risks by employing appropriate mitigation strategies that should ensure that targets are realized.},
  file = {/home/peyman/Zotero/storage/JYUKQTBB/Barros et al. - 2020 - Identification of Critical Operational Uncertainti.pdf},
  language = {en}
}

@article{baxendale,
  title = {{{OPEN POROUS MEDIA}}},
  author = {Baxendale, David},
  pages = {2007},
  file = {/home/peyman/Zotero/storage/QE4Q9Y86/Baxendale - OPEN POROUS MEDIA.pdf},
  language = {en}
}

@article{bellout2012cg,
  title = {Joint Optimization of Oil Well Placement and Controls},
  author = {Bellout, Mathias C. and Echeverr{\'i}a Ciaurri, David and Durlofsky, Louis J. and Foss, Bjarne and Kleppe, Jon},
  year = {2012},
  month = sep,
  volume = {16},
  pages = {1061--1079},
  issn = {1420-0597, 1573-1499},
  doi = {10.1007/s10596-012-9303-5},
  file = {/home/peyman/Zotero/storage/QKNWIZ69/Bellout et al. - 2012 - Joint optimization of oil well placement and contr.pdf},
  journal = {Computational Geosciences},
  language = {en},
  number = {4}
}

@article{beyer2007cmiamaea,
  title = {Robust Optimization \textendash{} {{A}} Comprehensive Survey},
  author = {Beyer, Hans-Georg and Sendhoff, Bernhard},
  year = {2007},
  month = jul,
  volume = {196},
  pages = {3190--3218},
  issn = {0045-7825},
  doi = {10.1016/j.cma.2007.03.003},
  abstract = {This paper reviews the state-of-the-art in robust design optimization \textendash{} the search for designs and solutions which are immune with respect to production tolerances, parameter drifts during operation time, model sensitivities and others. Starting with a short glimps of Taguchi's robust design methodology, a detailed survey of approaches to robust optimization is presented. This includes a detailed discussion on how to account for design uncertainties and how to measure robustness (i.e., how to evaluate robustness). The main focus will be on the different approaches to perform robust optimization in practice including the methods of mathematical programming, deterministic nonlinear optimization, and direct search methods such as stochastic approximation and evolutionary computation. It discusses the strengths and weaknesses of the different methods, thus, providing a basis for guiding the engineer to the most appropriate techniques. It also addresses performance aspects and test scenarios for direct robust optimization techniques.},
  file = {/home/peyman/Zotero/storage/HQJXJINF/Beyer_Sendhoff_2007_Robust optimization – A comprehensive survey.pdf;/home/peyman/Zotero/storage/RVMEV6VL/Beyer_Sendhoff_2007_Robust optimization – A comprehensive survey.pdf},
  journal = {Computer Methods in Applied Mechanics and Engineering},
  keywords = {Direct search methods,Evolutionary computation,Handling design uncertainties,Mathematical programming,Noisy optimization,Robust design,Robust optimization},
  language = {en},
  number = {33}
}

@article{bhadani2021ams,
  title = {Nonlinear {{Optimization}} in {{R}} Using Nlopt},
  author = {Bhadani, Rahul},
  year = {2021},
  month = jan,
  abstract = {In this article, we present a problem of nonlinear constraint optimization with equality and inequality constraints. Objective functions are defined to be nonlinear and optimizers may have a lower and upper bound. We solve the optimization problem using the open-source R package nloptr. Several examples have been presented.},
  archiveprefix = {arXiv},
  eprint = {2101.02912},
  eprinttype = {arxiv},
  file = {/home/peyman/Zotero/storage/93UDRNBY/Bhadani - 2021 - Nonlinear Optimization in R using nlopt.pdf},
  journal = {arXiv:2101.02912 [math, stat]},
  keywords = {Mathematics - Optimization and Control,Statistics - Computation},
  language = {en},
  primaryclass = {math, stat}
}

@article{borji,
  title = {Bayesian Optimization Explains Human Active Search},
  author = {Borji, Ali and Itti, Laurent},
  pages = {9},
  abstract = {Many real-world problems have complicated objective functions. To optimize such functions, humans utilize sophisticated sequential decision-making strategies. Many optimization algorithms have also been developed for this same purpose, but how do they compare to humans in terms of both performance and behavior? We try to unravel the general underlying algorithm people may be using while searching for the maximum of an invisible 1D function. Subjects click on a blank screen and are shown the ordinate of the function at each clicked abscissa location. Their task is to find the function's maximum in as few clicks as possible. Subjects win if they get close enough to the maximum location. Analysis over 23 non-maths undergraduates, optimizing 25 functions from different families, shows that humans outperform 24 well-known optimization algorithms. Bayesian Optimization based on Gaussian Processes, which exploits all the x values tried and all the f (x) values obtained so far to pick the next x, predicts human performance and searched locations better. In 6 follow-up controlled experiments over 76 subjects, covering interpolation, extrapolation, and optimization tasks, we further confirm that Gaussian Processes provide a general and unified theoretical account to explain passive and active function learning and search in humans.},
  file = {/home/peyman/Zotero/storage/VX8VQ9UF/Borji and Itti - Bayesian optimization explains human active search.pdf},
  language = {en}
}

@article{bratvold2009b,
  ids = {bratvold2009},
  title = {Value of {{Information}} in the {{Oil}} and {{Gas Industry}}: {{Past}}, {{Present}}, and {{Future}}},
  author = {Bratvold, Reidar B},
  year = {2009},
  pages = {9},
  abstract = {An important task that petroleum engineers and geoscientists undertake is to produce decision-relevant information. Some of the most important decisions we make concern what type and what quality of information to produce. When decisions are fraught with geologic and market uncertainties, this information gathering may such forms as seismic surveys, core and well test analyses, reservoir simulations, market analyses, and price forecasts\textemdash which the industry spends billions of US dollars each year. Yet, considerably less time and resources are expended on assessing the profitability or value of this information. Why is that? This paper addresses how to make value-of-information (VOI) analysis more accessible and useful by discussing its past, present, and future. On the basis of a survey of SPE publications, we provide an overview of the use of VOI in the oil and gas industry, focusing on how the analysis was carried out and for which types of decisions VOI analysis has been performed. We highlight areas in which VOI methods have been used successfully and identify important challenges.},
  file = {/home/peyman/Zotero/storage/AYQWX9FN/Bratvold - 2009 - Value of Information in the Oil and Gas Industry .pdf;/home/peyman/Zotero/storage/VL5A4FWG/Bratvold_2009_Value of Information in the Oil and Gas Industry.pdf;/home/peyman/Zotero/storage/ZCQN6XCU/Bratvold_2009_Value of Information in the Oil and Gas Industry.pdf},
  keywords = {2ed},
  language = {en}
}

@article{brochu2010ac,
  title = {A {{Tutorial}} on {{Bayesian Optimization}} of {{Expensive Cost Functions}}, with {{Application}} to {{Active User Modeling}} and {{Hierarchical Reinforcement Learning}}},
  author = {Brochu, Eric and Cora, Vlad M. and {de Freitas}, Nando},
  year = {2010},
  month = dec,
  abstract = {We present a tutorial on Bayesian optimization, a method of finding the maximum of expensive cost functions. Bayesian optimization employs the Bayesian technique of setting a prior over the objective function and combining it with evidence to get a posterior function. This permits a utility-based selection of the next observation to make on the objective function, which must take into account both exploration (sampling from areas of high uncertainty) and exploitation (sampling areas likely to offer improvement over the current best observation). We also present two detailed extensions of Bayesian optimization, with experiments---active user modelling with preferences, and hierarchical reinforcement learning---and a discussion of the pros and cons of Bayesian optimization based on our experiences.},
  archiveprefix = {arXiv},
  eprint = {1012.2599},
  eprinttype = {arxiv},
  file = {/home/peyman/Zotero/storage/9WMUJ9ET/Brochu et al_2010_A Tutorial on Bayesian Optimization of Expensive Cost Functions, with.pdf},
  journal = {arXiv:1012.2599 [cs]},
  keywords = {Computer Science - Machine Learning,G.1.6,G.3,I.2.6},
  primaryclass = {cs}
}

@article{bruce1943tab,
  ids = {bruce1943ta},
  title = {An {{Electrical Device}} for {{Analyzing Oil}}-Reservoir {{Behavior}}},
  author = {Bruce, W.A.},
  year = {1943},
  month = dec,
  volume = {151},
  pages = {112--124},
  issn = {0081-1696},
  doi = {10.2118/943112-G},
  abstract = {THIS paper covers the theory and present state of development of an apparatus for the nonmathematical analysis of complex problems of reservoir and well behavior.},
  file = {/home/peyman/Zotero/storage/5SBDZEAM/Bruce_1943_An Electrical Device for Analyzing Oil-Reservoir Behavior.pdf;/home/peyman/Zotero/storage/GVEEHFDV/Bruce - 1943 - An Electrical Device for Analyzing Oil-reservoir B.pdf},
  journal = {Transactions of the AIME},
  keywords = {1st,Proxy models},
  language = {en},
  number = {01}
}

@article{byrd1995sjoscb,
  ids = {byrd1995sjosc},
  title = {A Limited Memory Algorithm for Bound Constrained Optimization},
  author = {Byrd, Richard H. and Lu, Peihuang and Nocedal, Jorge and Zhu, Ciyou},
  year = {1995},
  month = sep,
  volume = {16},
  pages = {1190--1208},
  publisher = {{Society for Industrial and Applied Mathematics Publications}},
  issn = {1064-8275},
  doi = {10.1137/0916069},
  file = {/home/peyman/Zotero/storage/IRS4TWID/Byrd et al_1995_A limited memory algorithm for bound constrained optimization.pdf;/home/peyman/Zotero/storage/LQU5J27G/Byrd et al_1995_A limited memory algorithm for bound constrained optimization.pdf;/home/peyman/Zotero/storage/UA45GCJK/Byrd et al_1995_A limited memory algorithm for bound constrained optimization.pdf},
  journal = {SIAM Journal on Scientific Computing},
  language = {English}
}

@article{chai2021jopsaea,
  ids = {chai2021jopsae,chai2021jpse,chai2021jpsea,chai2021jpseb,chai2021jpsec},
  title = {An Integrated Closed-Loop Solution to Assisted History Matching and Field Optimization with Machine Learning Techniques},
  author = {Chai, Zhi and Nwachukwu, Azor and Zagayevskiy, Yevgeniy and Amini, Shohreh and Madasu, Srinath},
  year = {2021},
  month = mar,
  volume = {198},
  pages = {108204},
  issn = {0920-4105},
  doi = {10.1016/j.petrol.2020.108204},
  abstract = {The traditional petroleum reservoir modeling workflow for reservoir characterization, history matching, and field development optimization requires a significant amount of computation during reservoir simulation and post-processing. In this work, we focus on incorporating various optimization, machine learning, and model-order reduction techniques to reduce the computational cost and build an integrated closed-loop workflow, in which the history matching and optimization procedures are carried out sequentially. The uncertainty in the predictions of petroleum reservoir behavior is addressed through multiple realizations of the petroleum reservoir system under study. The initial reservoir characterization is performed with a full physics flow simulator. Bayesian optimization (BO) is introduced for assisted history matching to find a solution reasonably fast with a small number of reservoir simulation runs. To determine the optimal field development strategy, several optimization algorithms are compared, including particle swarm optimization (PSO), genetic algorithm (GA), and a hybrid approach of these two, called genetical swarm optimization (GSO). The implementation of a proxy model for flow to replace full physics simulation effectively reduces the CPU time for the optimization tasks in the workflow. The proxy is built using machine learning algorithms applied to a set of simulation runs. In this work, proxy models built using simple multivariate regression (MVR), artificial neural network (ANN), and a decision tree-based algorithm named extreme gradient boosting (XGB) are compared. As a preprocessing step to both history matching and optimization, the parameter space for the reservoir model is reduced with Karhunen\textendash Lo\`eve expansion (KLE) to make the size of the problem more manageable. The proposed integrated closed-loop reservoir management approach is demonstrated on a dataset representing a South Cowden reservoir in which waterflooding has been implemented.},
  file = {/home/peyman/Zotero/storage/9JJWU7WF/Chai et al. - 2021 - An integrated closed-loop solution to assisted his.pdf;/home/peyman/Zotero/storage/NBYZIING/Chai et al_2021_An integrated closed-loop solution to assisted history matching and field.pdf;/home/peyman/Zotero/storage/ZVSDKRPM/Chai et al_2021_An integrated closed-loop solution to assisted history matching and field.pdf},
  journal = {Journal of Petroleum Science and Engineering},
  keywords = {1st,Artificial neural network,Bayesian optimization,Extreme gradient boosting,Genetic algorithm,Karhunen-Loève expansion,Particle swarm optimization,Proxy models},
  language = {en}
}

@phdthesis{chang2015,
  title = {Decision-{{Making}} for {{Well Placement Optimization}} in {{Oil Field Development}}},
  author = {Chang, Yuqing},
  year = {2015},
  abstract = {Well placement is a method to improve oil recovery by drilling new infill wells in a reservoir. Drilling new wells is a critical yet very challenging task in field development, because the optimal well locations are rarely known and difficult to decide in practice due to complex reservoir and depletion situations. This dissertation focuses on the development of mathematical optimization techniques to assist decision-making for well planning and placement. The following topics are included in this dissertation.    1. To study and develop two stochastic approximated gradient-based approaches: the ensemble based optimization method (EnOpt) and the fixed-gain simultaneous perturbation stochastic approximation (FSP) for well placement; Evaluate the performance and effectiveness of these two methods on case studies.  2. To develop an efficient method to decide optimal number of wells and the corresponding locations, evaluate the performance on study cases.  3. To handle geological uncertainty and decision-making risk, propose a new workflow for multi-objective well placement optimization.  4. To ensure an efficient decision-making and a fast turnaround time, the use of engineering prior knowledge and a few acceleration routines are discussed in the context of optimization.    All approaches are evaluated on synthetic reservoir models, some are performed on real field-like cases. This dissertation provides various optimization methods with an enhanced capability of addressing geological uncertainty for well placement in oilfield development. However, it should also be noted that while the techniques proposed in this dissertation are applicable to a diverse set of reservoirs with no known limitations, the additional value of this dissertation lies in its ability to address well placement needs for highly complex reservoirs. For reservoirs that lack the complexity seen, for example, in deepwater basins, conventional well placement methods may be sufficient.},
  annotation = {Accepted: 2015-12-18T14:50:36Z},
  file = {/home/peyman/Zotero/storage/GIUCW532/Chang_2015_Decision-Making for Well Placement Optimization in Oil Field Development.pdf},
  language = {en\_US}
}

@article{chang2020cg,
  title = {{{OLYMPUS}} Optimization under Geological Uncertainty},
  author = {Chang, Yuqing and Lorentzen, Rolf J. and N{\ae}vdal, Geir and Feng, Tao},
  year = {2020},
  month = dec,
  volume = {24},
  pages = {2027--2042},
  issn = {1420-0597, 1573-1499},
  doi = {10.1007/s10596-019-09892-x},
  abstract = {Field development strategies are crucial for reservoir management, and over the last decade there has been quite some development of new optimization algorithms for solving this problem when the uncertainty in the reservoir description is provided by a set of reservoir models. To compare different approaches for this problem, the OLYMPUS benchmark challenge (Fonseca et al. 2018; TNO 2017) was defined, with three different tasks: well control optimization (task 1), field development optimization (task 2), and joint field development and well control optimization (task 3). This work presents solutions to the three exercises with two main optimization methods and problem-specific workflows. The main algorithms used in all three exercises are the ensemble-based optimization (EnOpt) and the line search derivative-free (LSDF) method. EnOpt is constructed for solving optimization problems where the uncertainty is represented by an ensemble of models, and in general it produced good results. However, we also found that the LSDF played an important role in quality checking the results obtained by EnOpt, and in some cases it provided superior results.},
  file = {/home/peyman/Zotero/storage/QCCKNZ2Q/Chang et al. - 2020 - OLYMPUS optimization under geological uncertainty.pdf},
  journal = {Computational Geosciences},
  language = {en},
  number = {6}
}

@article{chen2017jopsaeb,
  ids = {chen2017jopsae},
  title = {Uncertainty Quantification and Value of Information Assessment Using Proxies and {{Markov}} Chain {{Monte Carlo}} Method for a Pilot Project},
  author = {Chen, Bailian and He, Jincong and Wen, Xian-Huan and Chen, Wen and Reynolds, Albert C.},
  year = {2017},
  month = aug,
  volume = {157},
  pages = {328--339},
  issn = {0920-4105},
  doi = {10.1016/j.petrol.2017.07.039},
  abstract = {A pilot project is a crucial step of reservoir management that enables the minimization of subsurface risks and improves the quality of decisions on full-field development. Selecting a pilot project involves evaluating the expected uncertainty reduction and the value of information (VOI) attainable from a set of plausible pilot projects. Proxy-based pilot analysis (PBPA) represents a promising approach for characterizing the uncertainty reduction and VOI from each of a set of feasible pilot projects. In the PBPA method, multiple plausible realizations of observed data from a pilot are generated and probabilistic history matching (based on filtering) is performed for each realization of the vector of observed data in order to obtain the corresponding posterior distribution. The multiple history-matching runs are accomplished with a manageable number of simulations with the help of proxies. Previously, PBPA was successfully applied to quantify the expected value of uncertainty reduction in cases where the history-matching tolerance is high, but as shown here, the filtering-based history-matching procedure can fail when the tolerance is low. Moreover, it has not been demonstrated previously that the PBPA method can quantify VOI. In this paper, enhancements to PBPA that eliminate these two PBPA shortcomings are introduced. First, a Markov chain Monte Carlo (MCMC) method is used in place of the filtering procedure to calculate the posterior distribution. The combined MCMC-PBPA procedure is shown to outperform the filtering-based PBPA when the history-matching tolerance is low. Secondly, we define a framework that combines the MCMC-PBPA method with decision tree analysis in order to calculate the VOI. The proposed framework is demonstrated for a synthetic waterflooding pilot in the Brugge reservoir where it successfully quantifies the VOI for different pilot designs.},
  file = {/home/peyman/Documents/PhD_UiS/zotero_library/Chen et al/Chen et al_2017_Uncertainty quantification and value of information assessment using proxies.pdf;/home/peyman/Zotero/storage/7LQ8PCQ8/download1.pdf;/home/peyman/Zotero/storage/8Y7TZ2BQ/Chen et al_2017_Uncertainty quantification and value of information assessment using proxies.pdf;/home/peyman/Zotero/storage/AUQI4Y8T/Chen et al_2017_Uncertainty quantification and value of information assessment using proxies.pdf;/home/peyman/Zotero/storage/JVZGZIJ2/download1.pdf;/home/peyman/Zotero/storage/W6XBWJPU/download1.pdf},
  journal = {Journal of Petroleum Science and Engineering},
  keywords = {MCMC,Pilot design analysis,Proxy models,Uncertainty quantification,Value of information},
  language = {en}
}

@misc{constantinecaramanis2020a,
  title = {8.2 {{Quasi Newton}} and {{BFGS}}},
  author = {{Constantine Caramanis}},
  year = {2020},
  month = nov
}

@article{cui2018acsa,
  title = {Evolutionary {{Stochastic Gradient Descent}} for {{Optimization}} of {{Deep Neural Networks}}},
  author = {Cui, Xiaodong and Zhang, Wei and T{\"u}ske, Zolt{\'a}n and Picheny, Michael},
  year = {2018},
  month = oct,
  abstract = {We propose a population-based Evolutionary Stochastic Gradient Descent (ESGD) framework for optimizing deep neural networks. ESGD combines SGD and gradient-free evolutionary algorithms as complementary algorithms in one framework in which the optimization alternates between the SGD step and evolution step to improve the average fitness of the population. With a back-off strategy in the SGD step and an elitist strategy in the evolution step, it guarantees that the best fitness in the population will never degrade. In addition, individuals in the population optimized with various SGD-based optimizers using distinct hyper-parameters in the SGD step are considered as competing species in a coevolution setting such that the complementarity of the optimizers is also taken into account. The effectiveness of ESGD is demonstrated across multiple applications including speech recognition, image recognition and language modeling, using networks with a variety of deep architectures.},
  archiveprefix = {arXiv},
  eprint = {1810.06773},
  eprinttype = {arxiv},
  file = {/home/peyman/Zotero/storage/M2HTGTHI/v51i01.pdf;/home/peyman/Zotero/storage/P68VKIX5/Cui et al_2018_Evolutionary Stochastic Gradient Descent for Optimization of Deep Neural.pdf},
  journal = {arXiv:1810.06773 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@misc{cv,
  title = {Advantages of {{Particle Swarm Optimization}} over {{Bayesian Optimization}} for Hyperparameter Tuning?},
  howpublished = {https://stats.stackexchange.com/questions/194056/advantages-of-particle-swarm-optimization-over-bayesian-optimization-for-hyperpa},
  journal = {Cross Validated}
}

@misc{cva,
  title = {Deriving the Conditional Distributions of a Multivariate Normal Distribution},
  howpublished = {https://stats.stackexchange.com/questions/30588/deriving-the-conditional-distributions-of-a-multivariate-normal-distribution},
  journal = {Cross Validated}
}

@misc{cvb,
  title = {Log Marginal Likelihood for {{Gaussian Process}}},
  howpublished = {https://stats.stackexchange.com/questions/280105/log-marginal-likelihood-for-gaussian-process},
  journal = {Cross Validated}
}

@misc{dc&f,
  title = {Optimization for (Simulation) Engineering},
  abstract = {around DiceKriging package, examples, applications, theory and more.},
  howpublished = {https://github.com/DiceKrigingClub//r/jekyll/2018/04/24/OptimSimEngineering.html},
  journal = {DiceKriging Club \& Friends},
  language = {en}
}

@article{debrito2020jopsaea,
  ids = {debrito2020jopsae},
  title = {Well Control Optimization Using a Two-Step Surrogate Treatment},
  author = {{de Brito}, Daniel U. and Durlofsky, Louis J.},
  year = {2020},
  month = apr,
  volume = {187},
  pages = {106565},
  issn = {0920-4105},
  doi = {10.1016/j.petrol.2019.106565},
  abstract = {Large numbers of flow simulations are typically required for the determination of optimal well settings. These simulations are often computationally demanding, which poses challenges for the optimizations. In this paper we present a new two-step surrogate treatment (ST) that reduces the computational expense associated with well control optimization. The method is applicable for oil production via waterflood, with well rates optimized at a single control period. The two-step ST entails two separate optimizations, which can both be performed very efficiently. In the first optimization, optimal well-rate ratios (i.e., the fraction of total injection or production associated with each well) are determined such that a measure of velocity variability over the field is minimized, leading to more uniform sweep. In the second step, overall injection and production rates are determined. The flow physics in the first step is highly simplified, while the actual physical system is simulated in the second step. Near-globally-optimal results can be determined in both cases, as the first optimization is posed as a QP problem, and the second step entails just a single optimization variable. Under full parallelization, the overall elapsed time for the ST corresponds to the runtime for 1\textendash 2 full-order simulations. Results are presented for multiple well configurations, for 2D and 3D channelized models, and comparisons with formal optimization procedures (mesh adaptive direct search or MADS, and an adjoint-gradient method) are conducted. Three different fluid mobility ratios (M=1, 3 and 5) are considered. Optimization results demonstrate that the two-step ST provides results in reasonable agreement with those from MADS and adjoint-gradient methods, with speedups of 5\texttimes{} or more. We also show that the ST is applicable in the inner-loop in field development optimization, where it will be especially useful since many different well configurations must be evaluated.},
  file = {/home/peyman/Zotero/storage/9Y5F2K5M/de Brito_Durlofsky_2020_Well control optimization using a two-step surrogate treatment.pdf;/home/peyman/Zotero/storage/V9U24935/de Brito_Durlofsky_2020_Well control optimization using a two-step surrogate treatment.pdf},
  journal = {Journal of Petroleum Science and Engineering},
  keywords = {Field development optimization,Proxy model,Reservoir simulation,Surrogate model,Well control optimization},
  language = {en},
  options = {useprefix=true}
}

@article{debrito2021cg,
  ids = {debrito2021cga,debrito2021cgb},
  title = {Field Development Optimization Using a Sequence of Surrogate Treatments},
  author = {{de Brito}, Daniel U. and Durlofsky, Louis J.},
  year = {2021},
  month = feb,
  volume = {25},
  pages = {35--65},
  issn = {1573-1499},
  doi = {10.1007/s10596-020-09985-y},
  abstract = {Field development optimization, in which well configuration, well types, and well controls are determined, represents a computationally demanding mixed integer nonlinear programming problem. Such problems may require very large numbers of function evaluations, and if each of these corresponds to a detailed flow simulation, the optimization can become intractable. In this paper, we incorporate a set of surrogate treatments (STs) into the field development optimization problem. The basic ST is a variant of a recently developed surrogate procedure for optimizing well rates. It entails the solution of two optimization problems that both involve simplified physics (unit-mobility ratio displacement) and can be solved very efficiently. In the first problem, we find optimal well-rate ratios (i.e., the fraction of total injection or production allocated to each well), while in the second problem we determine optimal overall field injection and production rates. This ST is incorporated into a particle swarm optimization (PSO) framework. Three treatments are considered for subsequent optimization steps. All of these approaches involve full-physics simulations, and two of the methods entail the use of mesh adaptive direct search (MADS). The ST-based procedures are evaluated for two different 3D problems involving waterflood (with mobility ratios of 2 and 5) and water-alternating-gas (WAG) injection. The surrogate treatments are compared with standard approaches involving PSO, MADS, and a PSO-MADS hybrid. Extensive optimization results demonstrate that the ST-based methods provide consistent improvement in optimizer performance. For example, in the WAG case, the ST-based approach gives an optimal net present value that is 3.2\% higher than that achieved using standard PSO-MADS, while also providing a 2.4 \texttimes{} computational speedup.},
  file = {/home/peyman/Zotero/storage/CWALPHQ4/de Brito_Durlofsky_2021_Field development optimization using a sequence of surrogate treatments.pdf;/home/peyman/Zotero/storage/DUQK4DAD/de Brito_Durlofsky_2021_Field development optimization using a sequence of surrogate treatments.pdf;/home/peyman/Zotero/storage/XT7DT3UY/de Brito_Durlofsky_2021_Field development optimization using a sequence of surrogate treatments.pdf},
  journal = {Computational Geosciences},
  language = {en},
  number = {1},
  options = {useprefix=true}
}

@misc{doirab,
  title = {{{RStudio AI Blog}}: {{Gallery}} of Featured Posts},
  shorttitle = {{{RStudio AI Blog}}},
  author = {published yet DOI, Authors Affiliations Published Not},
  howpublished = {https://blogs.rstudio.com/ai/gallery.html},
  journal = {RStudio AI Blog}
}

@inproceedings{eikje2020,
  title = {Towards {{A Recovery Ambition Of}} ``{{More Than}} 70\%'' {{For The Johan Sverdrup Field}}},
  booktitle = {Offshore {{Technology Conference}}},
  author = {Eikje, Eli and Nedrelid, Tone and Bratli, Elisabeth and Kulkarni, Raghavendra and Fylling, Arne Egil and Lyse, Ottar and Aarrestad, Henriette Dorthea},
  year = {2020},
  month = may,
  publisher = {{OnePetro}},
  doi = {10.4043/30525-MS},
  file = {/home/peyman/Zotero/storage/7YB6DGKP/Eikje et al_2020_Towards A Recovery Ambition Of “More Than 70%” For The Johan Sverdrup Field.pdf},
  language = {en}
}

@inproceedings{fedutenko2014d2wj12a,
  title = {Time-{{Dependent Neural Network Based Proxy Modeling}} of {{SAGD Process}}},
  booktitle = {Day 2 {{Wed}}, {{June}} 11, 2014},
  author = {Fedutenko, E.. and Yang, C.. and Card, C.. and Nghiem, L. X.},
  year = {2014},
  month = jun,
  pages = {D021S008R001},
  publisher = {{SPE}},
  address = {{Calgary, Alberta, Canada}},
  doi = {10.2118/170085-MS},
  abstract = {Abstract             The present study proposes a novel single-layer Neural Network proxy to efficiently predict the production performance of oil reservoirs from a limited number of reservoir simulations. The proposed model is shown to provide powerful means for learning reservoir's dynamics from input-output relationships that is defined by multiple combinations of inputs and controls. A SAGD case with 3 well pairs is used to illustrate the approach. The workflow is organized as follows: Different numbers (from 30 to 200) of direct numerical simulations are conducted for the time horizon of ten years for the given reservoir. These simulations correspond to different combinations of the operational parameters sampled according to the Latin Hypercube Experimental Design (LHD).The time series of the simulated entire field production performance (particularly: Cumulative Oil Production, cumulative SOR, Oil Recovery Factor, and Oil Production Rate) are used to build the corresponding Radial Basis Function (RBF) Network proxy model which represents production performance as objective functions of the operational parameters and time. The nodal Radial Functions of the Network are defined to exactly match the simulator's training outputs. The big advantage of this model is a combination of low computational complexity with high prediction accuracy.The proxy model is then used to predict the production data for the given reservoir for any time period (within 10 training years) and any combination of the operational parameters.The predicted data are compared with the actual simulation results for the same time period and the same combinations of the operational parameters to evaluate the prediction quality. It is shown that the proposed RBF proxy model can be used as a light version of simulator to estimate the production results for any combination of operational parameters and time horizon with much less computational efforts. The proposed approach is shown to provide a very efficient forecasting mechanism for the reservoir considered. The difference between the predicted and actual data could be as low as a few percent for the majority of the operational parameters depending on the number of simulations used to train the RBF model. In general, the accuracy of the proxy model increases with the number of training simulations.},
  eventtitle = {{{SPE Heavy Oil Conference}}-{{Canada}}},
  file = {/home/peyman/Zotero/storage/BA9J75QD/Fedutenko et al_2014_Time-Dependent Neural Network Based Proxy Modeling of SAGD Process.pdf;/home/peyman/Zotero/storage/LAP3FHZR/Fedutenko et al_2014_Time-Dependent Neural Network Based Proxy Modeling of SAGD Process.pdf;/home/peyman/Zotero/storage/QTYFE8FL/Fedutenko et al. - 2014 - Time-Dependent Neural Network Based Proxy Modeling.pdf},
  language = {en}
}

@article{fonseca2020cga,
  ids = {fonseca2020cg},
  title = {Introduction to the Special Issue: {{Overview}} of {{OLYMPUS Optimization Benchmark Challenge}}},
  shorttitle = {Introduction to the Special Issue},
  author = {Fonseca, R. M. and Rossa, E. Della and Emerick, A. A. and Hanea, R. G. and Jansen, J. D.},
  year = {2020},
  month = dec,
  volume = {24},
  pages = {1933--1941},
  issn = {1420-0597, 1573-1499},
  doi = {10.1007/s10596-020-10003-4},
  file = {/home/peyman/Zotero/storage/MNMZKXP3/Fonseca et al_2020_Introduction to the special issue.pdf;/home/peyman/Zotero/storage/V9T2EIPJ/Fonseca et al. - 2020 - Introduction to the special issue Overview of OLY.pdf},
  journal = {Computational Geosciences},
  language = {en},
  number = {6}
}

@article{forouzanfar2013jopsaeb,
  ids = {forouzanfar2013jopsae},
  title = {Well-Placement Optimization Using a Derivative-Free Method},
  author = {Forouzanfar, Fahim and Reynolds, A. C.},
  year = {2013},
  month = sep,
  volume = {109},
  pages = {96--116},
  issn = {0920-4105},
  doi = {10.1016/j.petrol.2013.07.009},
  abstract = {A new well-placement optimization algorithm for the estimation of the trajectory of directional wells is introduced to maximize the life-cycle net-present-value (NPV) of production from a reservoir. A directional well is considered as a straight line in 3D. The well-placement problem is formulated in terms of six continuous variables which define the trajectory of a well. The trajectory parameters are the xw, yw and zw coordinates of the center point of the well, the length of the well, lw, and \texttheta w and {$\varphi$}w which are the orientation angles of the well in the horizontal and vertical directions, respectively. The life-cycle NPV functional of production from the reservoir is defined as a function of these six continuous well trajectory parameters (xw,yw,zw,lw,\texttheta w,{$\varphi$}w). The smoothness of the NPV functional is promoted by distributing the rate of the well among ``gridblock perforations'' which are ``close'' to the trajectory of the well. The NPV functional is efficiently maximized using a Bound Optimization BY Quadratic Approximation, BOBYQA, algorithm. In order to improve the performance of BOBYQA for the well-placement optimization problem, we use a transformation of the control variables. Application of a derivative-free optimization algorithm makes our well-placement method easy to apply using any reservoir simulator because no gradient computation is required. We illustrate the applicability of our well-placement method for a set of problems.},
  file = {/home/peyman/Zotero/storage/6JQAXFSC/Forouzanfar_Reynolds_2013_Well-placement optimization using a derivative-free method.pdf;/home/peyman/Zotero/storage/FL2AFQVJ/Forouzanfar_Reynolds_2013_Well-placement optimization using a derivative-free method.pdf;/home/peyman/Zotero/storage/WLMRI5KQ/Forouzanfar_Reynolds_2013_Well-placement optimization using a derivative-free method.pdf},
  journal = {Journal of Petroleum Science and Engineering},
  keywords = {BOBYQA,derivative-free optimization,directional wells,net present value (NPV),optimal well-placement},
  language = {en}
}

@inproceedings{frazier2011p2wscwa,
  title = {Value of Information Methods for Pairwise Sampling with Correlations},
  booktitle = {Proceedings of the 2011 {{Winter Simulation Conference}} ({{WSC}})},
  author = {Frazier, Peter I. and Xie, Jing and Chick, Stephen E.},
  year = {2011},
  month = dec,
  pages = {3974--3986},
  issn = {1558-4305},
  doi = {10.1109/WSC.2011.6148088},
  abstract = {We consider optimization via simulation over a finite set of alternatives. We employ a Bayesian value-of-information approach in which we allow both correlated prior beliefs on the sampling means and correlated sampling. Correlation in the prior belief allow us to learn about an alternative's value from samples of similar alternatives. Correlation in sampling, achieved through common random numbers, allows us to reduce the variance in comparing one alternative to another. We allow for a more general combination of both types of correlation than has been offered previously in the Bayesian ranking and selection literature. We do so by giving an exact expression for the value of information for sampling the difference between a pair of alternatives, and derive new knowledge-gradient methods based on this valuation.},
  file = {/home/peyman/Zotero/storage/C9Y7XABP/Frazier et al_2011_Value of information methods for pairwise sampling with correlations.pdf},
  keywords = {Bayesian methods,Correlation,Covariance matrix,Manganese,Optimization,Tin,Vectors}
}

@article{frazier2018acms,
  title = {A {{Tutorial}} on {{Bayesian Optimization}}},
  author = {Frazier, Peter I.},
  year = {2018},
  month = jul,
  abstract = {Bayesian optimization is an approach to optimizing objective functions that take a long time (minutes or hours) to evaluate. It is best-suited for optimization over continuous domains of less than 20 dimensions, and tolerates stochastic noise in function evaluations. It builds a surrogate for the objective and quantifies the uncertainty in that surrogate using a Bayesian machine learning technique, Gaussian process regression, and then uses an acquisition function defined from this surrogate to decide where to sample. In this tutorial, we describe how Bayesian optimization works, including Gaussian process regression and three common acquisition functions: expected improvement, entropy search, and knowledge gradient. We then discuss more advanced techniques, including running multiple function evaluations in parallel, multi-fidelity and multi-information source optimization, expensive-to-evaluate constraints, random environmental conditions, multi-task Bayesian optimization, and the inclusion of derivative information. We conclude with a discussion of Bayesian optimization software and future research directions in the field. Within our tutorial material we provide a generalization of expected improvement to noisy evaluations, beyond the noise-free setting where it is more commonly applied. This generalization is justified by a formal decision-theoretic argument, standing in contrast to previous ad hoc modifications.},
  archiveprefix = {arXiv},
  eprint = {1807.02811},
  eprinttype = {arxiv},
  file = {/home/peyman/Zotero/storage/V8T47M4D/Frazier_2018_A Tutorial on Bayesian Optimization.pdf},
  journal = {arXiv:1807.02811 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  primaryclass = {cs, math, stat}
}

@misc{ga,
  title = {Scikit-Fmm/Scikit-Fmm},
  abstract = {scikit-fmm is a Python extension module which implements the fast marching method. - scikit-fmm/scikit-fmm},
  howpublished = {https://github.com/scikit-fmm/scikit-fmm},
  journal = {GitHub},
  language = {en},
  organization = {{GitHub}}
}

@misc{gad2018m,
  title = {Introduction to {{Optimization}} with {{Genetic Algorithm}}},
  author = {Gad, Ahmed},
  year = {2018},
  month = jul,
  abstract = {Selection of the optimal parameters for machine learning tasks is challenging. Some results may be bad not because the data is noisy or the\ldots},
  file = {/home/peyman/Zotero/storage/R7IBW2SE/Gad_2018_Introduction to Optimization with Genetic Algorithm.pdf},
  howpublished = {https://towardsdatascience.com/introduction-to-optimization-with-genetic-algorithm-2f5001d9964b},
  journal = {Medium},
  language = {en},
  organization = {{Medium}}
}

@misc{gb,
  title = {Jeffheaton/T81\_558\_deep\_learning},
  abstract = {Washington University (in St. Louis) Course T81-558: Applications of Deep Neural Networks - jeffheaton/t81\_558\_deep\_learning},
  howpublished = {https://github.com/jeffheaton/t81\_558\_deep\_learning},
  journal = {GitHub},
  language = {en},
  organization = {{GitHub}}
}

@misc{gc,
  title = {{{SurajGupta}}/r-Source},
  abstract = {R Source Code. Contribute to SurajGupta/r-source development by creating an account on GitHub.},
  howpublished = {https://github.com/SurajGupta/r-source},
  journal = {GitHub},
  language = {en},
  organization = {{GitHub}}
}

@misc{ge,
  title = {Fmfn/{{BayesianOptimization}}},
  abstract = {A Python implementation of global optimization with gaussian processes. - fmfn/BayesianOptimization},
  howpublished = {https://github.com/fmfn/BayesianOptimization},
  journal = {GitHub},
  language = {en},
  organization = {{GitHub}}
}

@misc{gf,
  title = {Glouppe/Talk-Bayesian-Optimisation},
  abstract = {Talk on "Bayesian optimisation", beginner level. Contribute to glouppe/talk-bayesian-optimisation development by creating an account on GitHub.},
  howpublished = {https://github.com/glouppe/talk-bayesian-optimisation},
  journal = {GitHub},
  language = {en}
}

@article{gonzalez,
  title = {{{GLASSES}}: {{Relieving The Myopia Of Bayesian Optimisation}}},
  author = {Gonzalez, Javier and Osborne, Michael and Lawrence, Neil D},
  pages = {10},
  abstract = {We present glasses: Global optimisation with Look-Ahead through Stochastic Simulation and Expected-loss Search. The majority of global optimisation approaches in use are myopic, in only considering the impact of the next function value; the non-myopic approaches that do exist are able to consider only a handful of future evaluations. Our novel algorithm, glasses, permits the consideration of dozens of evaluations into the future. This is done by approximating the ideal look-ahead loss function, which is expensive to evaluate, by a cheaper alternative in which the future steps of the algorithm are simulated beforehand. An Expectation Propagation algorithm is used to compute the expected value of the loss. We show that the far-horizon planning thus enabled leads to substantive performance gains in empirical tests.},
  file = {/home/peyman/Zotero/storage/BGYWNJ7A/Gonzalez et al. - GLASSES Relieving The Myopia Of Bayesian Optimisa.pdf},
  language = {en}
}

@article{gorissen2015o,
  title = {A Practical Guide to Robust Optimization},
  author = {Gorissen, Bram L. and Yan{\i}ko{\u g}lu, {\.I}hsan and {den Hertog}, Dick},
  year = {2015},
  month = jun,
  volume = {53},
  pages = {124--137},
  issn = {0305-0483},
  doi = {10.1016/j.omega.2014.12.006},
  abstract = {Robust optimization is a young and active research field that has been mainly developed in the last 15 years. Robust optimization is very useful for practice, since it is tailored to the information at hand, and it leads to computationally tractable formulations. It is therefore remarkable that real-life applications of robust optimization are still lagging behind; there is much more potential for real-life applications than has been exploited hitherto. The aim of this paper is to help practitioners to understand robust optimization and to successfully apply it in practice. We provide a brief introduction to robust optimization, and also describe important do׳s and don׳ts for using it in practice. We use many small examples to illustrate our discussions.},
  file = {/home/peyman/Zotero/storage/YWWI66SC/Gorissen et al_2015_A practical guide to robust optimization.pdf},
  journal = {Omega},
  keywords = {Adjustable robust optimization,Robust optimization},
  language = {en}
}

@book{gramacy,
  title = {Chapter 5 {{Gaussian Process Regression}} | {{Surrogates}}},
  author = {Gramacy, Robert B.},
  abstract = {Chapter 5 Gaussian Process Regression | Surrogates: a new graduate level textbook on topics lying at the interface between machine learning, spatial statistics, computer simulation, meta-modeling (i.e., emulation), and design of experiments. Gaussian process emphasis facilitates flexible nonparametric and nonlinear modeling, with applications to uncertainty quantification, sensitivity analysis, calibration of computer models to field data, sequential design and (blackbox) optimization under uncertainty. Presentation targets numerically competent scientists in the engineering, physical, and biological sciences. Treatment includes historical perspective and canonical examples, but primarily concentrates on modern statistical methods, computation and implementation in R at modern scale. Rmarkdown facilitates a fully reproducible tour complete with motivation from, application to, and illustration with, compelling real-data examples.}
}

@book{gramacya,
  title = {Surrogates},
  author = {Gramacy, Robert B.},
  abstract = {Surrogates: a new graduate level textbook on topics lying at the interface between machine learning, spatial statistics, computer simulation, meta-modeling (i.e., emulation), and design of experiments. Gaussian process emphasis facilitates flexible nonparametric and nonlinear modeling, with applications to uncertainty quantification, sensitivity analysis, calibration of computer models to field data, sequential design and (blackbox) optimization under uncertainty. Presentation targets numerically competent scientists in the engineering, physical, and biological sciences. Treatment includes historical perspective and canonical examples, but primarily concentrates on modern statistical methods, computation and implementation in R at modern scale. Rmarkdown facilitates a fully reproducible tour complete with motivation from, application to, and illustration with, compelling real-data examples.}
}

@article{gu2021jopsae,
  title = {Reservoir {{Production Optimization Based}} on {{Surrograte Model}} and {{Differential Evolution}} Algorithm},
  author = {Gu, Jianwei and Liu, Wei and Zhang, Kai and Zhai, Liang and Zhang, Yigen},
  year = {2021},
  month = may,
  pages = {108879},
  issn = {0920-4105},
  doi = {10.1016/j.petrol.2021.108879},
  abstract = {Production Optimization is a significant method for oilfields to control water cut and stabilize oil production. When the oilfield enters the high or ultra-high water cut stage, it becomes particularly important to use production optimization methods for improving the water-flooding efficiency. Currently, the commonly used production optimization methods are based on reservoir simulators. Such methods require lots of forward simulations during optimizing, which results in low computational efficiency. It's not applicable to the reservoir without numerical simulation models. Thus, a new production optimization method based on the reservoir proxy model is proposed in this work. Firstly, the dynamic production data of the oilfield are collected and preprocessed for training the Extreme Gradient Boosting model, and constructing the proxy model for water cut prediction of producers and the reservoir. Then, an optimal control model for minimizing the water cut of the reservoir can be constructed based on the proxy model. Finally, an optimal injection-production scheme can be obtained by using the differential evolution algorithm. For the evaluation and verification purposes, the proposed method is applied to a well block from SL oilfield, China. Empirical results demonstrated that the proposed method can effectively improve the water-flooding efficiency.},
  journal = {Journal of Petroleum Science and Engineering},
  keywords = {Differential evolution algorithm,Extreme Gradient Boosting,Machine learning,Production optimization,Proxy model},
  language = {en}
}

@article{hanea2019sreeb,
  ids = {hanea2019sreea},
  title = {Drill and {{Learn}}: {{A Decision}}-{{Making Work Flow To Quantify Value}} of {{Learning}}},
  shorttitle = {Drill and {{Learn}}},
  author = {Hanea, R. G. and Casanova, P.. and Hustoft, L.. and Bratvold, R. B. and Nair, R.. and Hewson, C.. and Leeuwenburgh, O.. and Fonseca, R.-M.. -M.},
  year = {2019},
  month = aug,
  volume = {22},
  pages = {1131--1143},
  issn = {1094-6470, 1930-0212},
  doi = {10.2118/182719-PA},
  abstract = {The goal of reservoir management is to make decisions with the objective of maximizing the value creation from oil or gas production. To achieve this, models that preserve geological realism and have predictive capabilities are being developed and used. These models are commonly calibrated using assisted-history-matching (AHM) methods which, in general, will lead to reduced uncertainty in the predicted production. Although uncertainty assessment and reduction are often elements of high-quality decision making, they are not value-creating. Value can only be created through decisions, and any decision changes resulting from AHM should be modeled explicitly. Recently, there has been a surge in the application and understanding of value-of-information (VOI) work flows for reservoir management. In this text, we present a comparison of existing work flows and note the differences between them. After this, we introduce a practically driven approach, referred to as ``drill and learn,'' with elements and concepts from existing work flows to quantify the value of learning (VOL). VOL can be used as a metric to quantify the potential of such work flows and the strategies obtained. Ensemble methods [ensemble smoother with multiple data assimilation (ES-MDA) and stochastic simplex approximate gradient (StoSAG)] are used for the history matching and optimization. The results presented are obtained by applying the proposed drill-and-learn work flow on a realistic synthetic case. Sensitivities to the amount of information obtained before a closed-loop exercise is performed are also investigated. We show the benefit of performing the closed-loop approach to quantify the VOL to modify field-development decisions, which leads to a mature and robust decision-making framework.},
  file = {/home/peyman/Zotero/storage/DMBHTCGE/Hanea et al. - 2019 - Drill and Learn A Decision-Making Work Flow To Qu.pdf;/home/peyman/Zotero/storage/EMYNDCCL/Hanea et al_2019_Drill and Learn.pdf;/home/peyman/Zotero/storage/FQVDYZUK/Hanea et al. - 2019 - Drill and Learn A Decision-Making Work Flow To Qu.pdf;/home/peyman/Zotero/storage/HZ8H5GIE/Hanea et al_2019_Drill and Learn.pdf;/home/peyman/Zotero/storage/LG3RNSB8/Hanea et al_2019_Drill and Learn.pdf},
  journal = {SPE Reservoir Evaluation \& Engineering},
  keywords = {1st},
  language = {en},
  number = {03}
}

@article{he2016sj,
  title = {Proxy-{{Based Work Flow}} for a {{Priori Evaluation}} of {{Data}}-{{Acquisition Programs}}},
  author = {He, Jincong and Xie, Jiang and Sarma, Pallav and Wen, Xian-Huan and Chen, Wen H. and Kamath, Jairam},
  year = {2016},
  month = aug,
  volume = {21},
  pages = {1400--1412},
  issn = {1086-055X, 1930-0220},
  doi = {10.2118/173229-PA},
  abstract = {Data-acquisition programs, such as surveillance and pilot, play an important role in reservoir management, and are crucial for minimizing subsurface risks and improving decision quality. Optimal design of the data-acquisition plan requires predicting the performance (e.g., in terms of the expected amount of uncertainty reduction in an objective function) of a given design before it is implemented. Because the data from the acquisition program are uncertain at the time of the analysis, multiple history-matching runs are required for different plausible realizations of the observed data to evaluate the expected effectiveness of the program in reducing uncertainty. As such, the computational cost may be prohibitive because the number of reservoir simulations needed for the multiple history-matching runs would be substantial. This paper proposes a framework on the basis of proxies and rejection sampling (filtering) to perform the multiple historymatching runs with a manageable number of reservoir simulations. The work flow proposed does not depend on the linear Gaussian assumption that is a common, yet questionable, assumption in existing methods. The work flow also enables both qualitative and quantitative analysis of a surveillance plan. Qualitatively, heavy-hitter alignment analysis for the objective function and the observed data provides actionable measures for screening different surveillance designs. Quantitatively, the evaluation of expected uncertainty reduction from different surveillance plans allows for optimal design and selection of surveillance plans.},
  file = {/home/peyman/Zotero/storage/LFW2L42E/He et al. - 2016 - Proxy-Based Work Flow for a Priori Evaluation of D.pdf;/home/peyman/Zotero/storage/ZQVQC28Z/He et al_2016_Proxy-Based Work Flow for a Priori Evaluation of Data-Acquisition Programs.pdf},
  journal = {SPE Journal},
  keywords = {first read},
  language = {en},
  number = {04}
}

@article{helbert2009asmbi,
  title = {Assessment of Uncertainty in Computer Experiments from {{Universal}} to {{Bayesian Kriging}}},
  author = {Helbert, C. and Dupuy, D. and Carraro, L.},
  year = {2009},
  volume = {25},
  pages = {99--113},
  issn = {1526-4025},
  doi = {10.1002/asmb.743},
  abstract = {Kriging was first introduced in the field of geostatistics. Nowadays, it is widely used to model computer experiments. Since the results of deterministic computer experiments have no experimental variability, Kriging is appropriate in that it interpolates observations at data points. Moreover, Kriging quantifies prediction uncertainty, which plays a major role in many applications. Among practitioners we can distinguish those who use Universal Kriging where the parameters of the model are estimated and those who use Bayesian Kriging where model parameters are random variables. The aim of this article is to show that the prediction uncertainty has a correct interpretation only in the case of Bayesian Kriging. Different cases of prior distributions have been studied and it is shown that in one specific case, Bayesian Kriging supplies an interpretation as a conditional variance for the prediction variance provided by Universal Kriging. Finally, a simple petroleum engineering case study presents the importance of prior information in the Bayesian approach. Copyright \textcopyright{} 2009 John Wiley \& Sons, Ltd.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/asmb.743},
  file = {/home/peyman/Zotero/storage/JI7F8BMH/Helbert et al. - 2009 - Assessment of uncertainty in computer experiments .pdf},
  journal = {Applied Stochastic Models in Business and Industry},
  keywords = {Bayesian Kriging,computer experiments,Gaussian random field,informative prior,Markov chain Monte Carlo,Universal Kriging},
  language = {en},
  number = {2}
}

@article{hong2017cg,
  title = {Robust Production Optimization with Capacitance-Resistance Model as Precursor},
  author = {Hong, A. J. and Bratvold, R. B. and N{\ae}vdal, G.},
  year = {2017},
  month = dec,
  volume = {21},
  pages = {1423--1442},
  issn = {1420-0597, 1573-1499},
  doi = {10.1007/s10596-017-9666-8},
  file = {/home/peyman/Zotero/storage/7NMT5C2S/Hong et al_2017_Robust production optimization with capacitance-resistance model as precursor.pdf;/home/peyman/Zotero/storage/986HMM5H/Hong et al. - 2017 - Robust production optimization with capacitance-re.pdf;/home/peyman/Zotero/storage/B2P46BPK/feart-08-00108.pdf},
  journal = {Computational Geosciences},
  keywords = {Proxy models},
  language = {en},
  number = {5-6}
}

@misc{icl,
  title = {About Us},
  abstract = {The~Optimisation and Machine Learning for Process Systems Engineering Group is a part of the Department of Chemical Engineering at Imperial Coll...},
  howpublished = {http://www.imperial.ac.uk/a-z-research/optimisation-and-machine-learning-for-process-engineering/about-us/},
  journal = {Imperial College London},
  language = {en-GB}
}

@misc{informs,
  title = {{{TutORial}}: {{Bayesian Optimization}}},
  shorttitle = {{{TutORial}}},
  author = {{INFORMS}},
  abstract = {By Peter Frazier.  Bayesian optimization is widely used for tuning deep neural networks and optimizing other black-box objective functions that take a long time to evaluate. In this tutorial, we describe how Bayesian optimization works, including the Bayesian machine learning model it uses to model the objective function, Gaussian process regression, and three common acquisition functions: expected improvement, entropy search, and knowledge gradient. We then describe applications at Yelp and Uber, explain techniques important for making it work well in practice, and survey techniques for solving "exotic" Bayesian optimization problems.}
}

@inproceedings{isebor2013,
  title = {Generalized {{Field Development Optimization Using Derivative}}-{{Free Procedures}}},
  booktitle = {{{SPE Reservoir Simulation Symposium}}},
  author = {Isebor, Obiajulu J. and Ciaurri, David Echeverr{\'i}a and Durlofsky, Louis J.},
  year = {2013},
  month = feb,
  publisher = {{OnePetro}},
  doi = {10.2118/163631-MS},
  file = {/home/peyman/Zotero/storage/META9BU6/Isebor et al_2013_Generalized Field Development Optimization Using Derivative-Free Procedures.pdf},
  language = {en}
}

@article{jeong2020fes,
  title = {Efficient {{Ensemble}}-{{Based Stochastic Gradient Methods}} for {{Optimization Under Geological Uncertainty}}},
  author = {Jeong, Hoonyoung and Sun, Alexander Y. and Jeon, Jonghyeon and Min, Baehyun and Jeong, Daein},
  year = {2020},
  month = may,
  volume = {8},
  pages = {108},
  issn = {2296-6463},
  doi = {10.3389/feart.2020.00108},
  abstract = {Ensemble-based stochastic gradient methods, such as the ensemble optimization (EnOpt) method, the simplex gradient (SG) method, and the stochastic simplex approximate gradient (StoSAG) method, approximate the gradient of an objective function using an ensemble of perturbed control vectors. These methods are increasingly used in solving reservoir optimization problems because they are not only easy to parallelize and couple with any simulator but also computationally more efficient than the conventional finite-difference method for gradient calculations. In this work, we show that EnOpt may fail to achieve sufficient improvement of the objective function when the differences between the objective function values of perturbed control variables and their ensemble mean are large. On the basis of the comparison of EnOpt and SG, we propose a hybrid gradient of EnOpt and SG to save on the computational cost of SG. We also suggest practical ways to reduce the computational cost of EnOpt and StoSAG by approximating the objective function values of unperturbed control variables using the values of perturbed ones. We first demonstrate the performance of our improved ensemble schemes using a benchmark problem. Results show that the proposed gradients saved about 30\textendash 50\% of the computational cost of the same optimization by using EnOpt, SG, and StoSAG. As a real application, we consider pressure management in carbon storage reservoirs, for which brine extraction wells need to be optimally placed to reduce reservoir pressure buildup while maximizing the net present value. Results show that our improved schemes reduce the computational cost significantly.},
  file = {/home/peyman/Zotero/storage/6PRUH6RN/Jeong et al. - 2020 - Efficient Ensemble-Based Stochastic Gradient Metho.pdf},
  journal = {Frontiers in Earth Science},
  language = {en}
}

@article{jesmani2016cg,
  title = {Well Placement Optimization Subject to Realistic Field Development Constraints},
  author = {Jesmani, Mansoureh and Bellout, Mathias C. and Hanea, Remus and Foss, Bjarne},
  year = {2016},
  month = dec,
  volume = {20},
  pages = {1185--1209},
  issn = {1420-0597, 1573-1499},
  doi = {10.1007/s10596-016-9584-1},
  file = {/home/peyman/Zotero/storage/MM8VGAU5/Jesmani et al. - 2016 - Well placement optimization subject to realistic f.pdf},
  journal = {Computational Geosciences},
  language = {en},
  number = {6}
}

@article{jesmani2016cga,
  title = {Well Placement Optimization Subject to Realistic Field Development Constraints},
  author = {Jesmani, Mansoureh and Bellout, Mathias C. and Hanea, Remus and Foss, Bjarne},
  year = {2016},
  month = dec,
  volume = {20},
  pages = {1185--1209},
  issn = {1420-0597, 1573-1499},
  doi = {10.1007/s10596-016-9584-1},
  file = {/home/peyman/Zotero/storage/ZXSP52QU/Jesmani et al. - 2016 - Well placement optimization subject to realistic f.pdf},
  journal = {Computational Geosciences},
  language = {en},
  number = {6}
}

@inproceedings{jin2000p2acgeca,
  title = {On Evolutionary Optimization with Approximate Fitness Functions},
  booktitle = {Proceedings of the 2nd {{Annual Conference}} on {{Genetic}} and {{Evolutionary Computation}}},
  author = {Jin, Yaochu and Olhofer, Markus and Sendhoff, Bernhard},
  year = {2000},
  month = jul,
  pages = {786--793},
  publisher = {{Morgan Kaufmann Publishers Inc.}},
  address = {{San Francisco, CA, USA}},
  abstract = {The evaluation of the quality of solutions is usually very time-consuming in design optimization. Therefore, time-efficient approximate models can be particularly beneficial for the evaluation when evolutionary algorithms are applied. In this paper, the convergence property of an evolution strategy (ES) with neural network based fitness evaluations is investigated. It is found that the evolutionary algorithm will converge incorrectly if the approximate model has false optima. To address this problem, two strategies to control the evolution process are introduced. In addition, methods to eliminate false minima in neural network training are proposed. The effectiveness of the methods are shown with simulation studies on the Ackley function and the Rosenbrock function.},
  file = {/home/peyman/Zotero/storage/ZJ6JBFA5/Jin et al_2000_On evolutionary optimization with approximate fitness functions.pdf},
  isbn = {978-1-55860-708-8},
  series = {{{GECCO}}'00}
}

@book{jin2005a,
  title = {Knowledge {{Incorporation}} in {{Evolutionary Computation}}},
  editor = {Jin, Yaochu and Kacprzyk, Janusz},
  year = {2005},
  volume = {167},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-540-44511-1},
  editorbtype = {redactor},
  file = {/home/peyman/Zotero/storage/CEKSTK9U/Jin - 2005 - Knowledge Incorporation in Evolutionary Computatio.pdf;/home/peyman/Zotero/storage/D2JRWYZL/Jin_Kacprzyk_2005_Knowledge Incorporation in Evolutionary Computation.pdf},
  isbn = {978-3-642-06174-5 978-3-540-44511-1},
  language = {en},
  series = {Studies in {{Fuzziness}} and {{Soft Computing}}}
}

@article{jin2005sca,
  ids = {jin2005sc},
  title = {A Comprehensive Survey of Fitness Approximation in Evolutionary Computation},
  author = {Jin, Y.},
  year = {2005},
  month = jan,
  volume = {9},
  pages = {3--12},
  issn = {1432-7643, 1433-7479},
  doi = {10.1007/s00500-003-0328-5},
  file = {/home/peyman/Zotero/storage/AQ4QWBNY/Jin - 2005 - A comprehensive survey of fitness approximation in.pdf;/home/peyman/Zotero/storage/KDBUJJQV/Jin_2005_A comprehensive survey of fitness approximation in evolutionary computation.pdf},
  journal = {Soft Computing},
  keywords = {first read},
  language = {en},
  number = {1}
}

@article{jin2011saeca,
  ids = {jin2011saec},
  title = {Surrogate-Assisted Evolutionary Computation: {{Recent}} Advances and Future Challenges},
  shorttitle = {Surrogate-Assisted Evolutionary Computation},
  author = {Jin, Yaochu},
  year = {2011},
  month = jun,
  volume = {1},
  pages = {61--70},
  issn = {22106502},
  doi = {10.1016/j.swevo.2011.05.001},
  abstract = {Surrogate-assisted, or meta-model based evolutionary computation uses efficient computational models, often known as surrogates or meta-models, for approximating the fitness function in evolutionary algorithms. Research on surrogate-assisted evolutionary computation began over a decade ago and has received considerably increasing interest in recent years. Very interestingly, surrogate-assisted evolutionary computation has found successful applications not only in solving computationally expensive single- or multi-objective optimization problems, but also in addressing dynamic optimization problems, constrained optimization problems and multi-modal optimization problems. This paper provides a concise overview of the history and recent developments in surrogate-assisted evolutionary computation and suggests a few future trends in this research area.},
  file = {/home/peyman/Zotero/storage/YCP9CA9B/Jin - 2011 - Surrogate-assisted evolutionary computation Recen.pdf;/home/peyman/Zotero/storage/ZECXL7S2/Jin_2011_Surrogate-assisted evolutionary computation.pdf},
  journal = {Swarm and Evolutionary Computation},
  keywords = {2ed},
  language = {en},
  number = {2}
}

@article{jina,
  title = {On {{Evolutionary Optimization}} with {{Approximate Fitness Functions}}},
  author = {Jin, Yaochu and Olhofer, Markus and Sendhoff, Bernhard},
  pages = {9},
  abstract = {The evaluation of the quality of solutions is usually very time-consuming in design optimization. Therefore, time-efficient approximate models can be particularly beneficial for the evaluation when evolutionary algorithms are applied. In this paper, the convergence property of an evolution strategy (ES) with neural network based fitness evaluations is investigated. It is found that the evolutionary algorithm will converge incorrectly if the approximate model has false optima. To address this problem, two strategies to control the evolution process are introduced. In addition, methods to eliminate false minima in neural network training are proposed. The effectiveness of the methods are shown with simulation studies on the Ackley function and the Rosenbrock function.},
  file = {/home/peyman/Zotero/storage/5XAJTR5T/Jin et al. - On Evolutionary Optimization with Approximate Fitn.pdf},
  language = {en}
}

@article{jones,
  title = {Efficient {{Global Optimization}} of {{Expensive Black}}-{{Box Functions}}},
  author = {Jones, Donald R and Schonlau, Matthias},
  pages = {38},
  abstract = {In many engineering optimization problems, the number of function evaluations is severely limited by time or cost. These problems pose a special challenge to the field of global optimization, since existing methods often require more function evaluations than can be comfortably afforded. One way to address this challenge is to fit response surfaces to data collected by evaluating the objective and constraint functions at a few points. These surfaces can then be used for visualization, tradeoff analysis, and optimization. In this paper, we introduce the reader to a response surface methodology that is especially good at modeling the nonlinear, multimodal functions that often occur in engineering. We then show how these approximating functions can be used to construct an efficient global optimization algorithm with a credible stopping rule. The key to using response surfaces for global optimization lies in balancing the need to exploit the approximating surface (by sampling where it is minimized) with the need to improve the approximation (by sampling where prediction error may be high). Striking this balance requires solving certain auxiliary problems which have previously been considered intractable, but we show how these computational obstacles can be overcome.},
  file = {/home/peyman/Zotero/storage/DG8EUDWH/Jones and Schonlau - Efficient Global Optimization of Expensive Black-B.pdf},
  language = {en}
}

@article{kim2020jopsaea,
  ids = {kim2020jopsae},
  title = {Robust Optimization of the Locations and Types of Multiple Wells Using {{CNN}} Based Proxy Models},
  author = {Kim, Joonyi and Yang, Hyungjun and Choe, Jonggeun},
  year = {2020},
  month = oct,
  volume = {193},
  pages = {107424},
  issn = {09204105},
  doi = {10.1016/j.petrol.2020.107424},
  abstract = {For the cost-effective optimization of well locations and types under geologic uncertainty, proxy modeling or surrogate modeling of reservoir simulation is required. Recently, a machine learning algorithm has been widely applied to predict reservoir responses and expedite an optimization. Since non-physics-based approach with machine learning algorithms suffers from emulating nonlinear reservoir responses from different well locations, types, and reservoir models, we propose to incorporate physical information to handle this limitation. We utilize streamline time of flight into the training data, and the predictive accuracy of the proxy model increases significantly due to the additional information.},
  file = {/home/peyman/Zotero/storage/TNEFGS68/Kim et al. - 2020 - Robust optimization of the locations and types of .pdf;/home/peyman/Zotero/storage/XKPU5MGD/Kim et al_2020_Robust optimization of the locations and types of multiple wells using CNN.pdf},
  journal = {Journal of Petroleum Science and Engineering},
  language = {en}
}

@article{kim2021sj,
  title = {A {{Recurrent Neural Network}}\textendash{{Based Proxy Model}} for {{Well}}-{{Control Optimization}} with {{Nonlinear Output Constraints}}},
  author = {Kim, Yong Do and Durlofsky, Louis J.},
  year = {2021},
  month = may,
  pages = {1--21},
  issn = {1086-055X, 1930-0220},
  doi = {10.2118/203980-PA},
  abstract = {In well-control optimization problems, the goal is to determine the time-varying well settings that maximize an objective function, which is often the net present value (NPV). Various proxy models have been developed to predict NPV for a set of inputs such as timevarying well bottomhole pressures (BHPs). However, when nonlinear output constraints (e.g., maximum well/field water production rate or minimum well/field oil rate) are specified, the problem is more challenging because well rates as a function of time are required. In this work, we develop a recurrent neural network (RNN)\textendash based proxy model to treat constrained production optimization problems. The network developed here accepts sequences of BHPs as inputs and predicts sequences of oil and water rates for each well. A longshort-term memory (LSTM) cell, which is capable of learning long-term dependencies, is used. The RNN is trained using well-rate results from 256 full-order simulation runs that involve different injection and production-well BHP schedules. After detailed validation against full-order simulation results, the RNN-based proxy is used for 2D and 3D production optimization problems. Optimizations are performed using a particle swarm optimization (PSO) algorithm with a filter-based nonlinear-constraint treatment. The trained proxy is extremely fast, although optimizations that apply the RNN-based proxy at all iterations are found to be suboptimal relative to full simulation-based (standard) optimization. Through use of a few additional simulation-based PSO iterations after proxy-based optimization, we achieve NPVs comparable with those from simulation-based optimization but with speedups of 10 or more (relative to performing five simulation-based optimization runs). It is important to note that because the RNN-based proxy provides full well-rate time sequences, optimization constraint types or limits, as well as economic parameters, can be varied without retraining.},
  file = {/home/peyman/Zotero/storage/B354BUUW/Kim and Durlofsky - 2021 - A Recurrent Neural Network–Based Proxy Model for W.pdf},
  journal = {SPE Journal},
  language = {en}
}

@misc{koehrsen2018ma,
  title = {A {{Conceptual Explanation}} of {{Bayesian Hyperparameter Optimization}} for {{Machine Learning}}},
  author = {Koehrsen, Will},
  year = {2018},
  month = jul,
  abstract = {The concepts behind efficient hyperparameter tuning using Bayesian optimization},
  howpublished = {https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f},
  journal = {Medium},
  language = {en},
  organization = {{Medium}}
}

@article{koval1963spej,
  title = {A {{Method}} for {{Predicting}} the {{Performance}} of {{Unstable Miscible Displacement}} in {{Heterogeneous Media}}},
  author = {Koval, E.J.},
  year = {1963},
  month = jun,
  volume = {3},
  pages = {145--154},
  issn = {0197-7520},
  doi = {10.2118/450-PA},
  abstract = {Practical miscible displacement processes will be characterized by fingering of the solvent into the oil. The fingering process is brought on by viscosity differences, and can be accentuated by channeling and longitudinal dispersion. The effects of these factors on the efficiency of unstable completely miscible displacements are combined in what is called the K-factor method. This method, analogous to the Buckley-Leverett method, predicts recovery and solvent cut as a function of pore volumes of solvent injected. Experimental data are included and show excellent agreement with theory for a wide variety of sandstone cores and viscosity ratios.},
  file = {/home/peyman/Zotero/storage/Z48LPMCE/Koval - 1963 - A Method for Predicting the Performance of Unstabl.pdf},
  journal = {Society of Petroleum Engineers Journal},
  language = {en},
  number = {02}
}

@article{lavrov,
  title = {Chapter 6, {{Lecture}} 1: {{The Penalty Method}}},
  author = {Lavrov, Mikhail},
  pages = {3},
  file = {/home/peyman/Zotero/storage/9ET88TQK/Lavrov - Chapter 6, Lecture 1 The Penalty Method.pdf},
  language = {en}
}

@misc{levy2016,
  title = {Data from a Dynamically Downscaled Projection of Past and Future Microclimates Covering {{North America}} from 1980-1999 and 2080-2099},
  author = {Levy, Ofir and Buckley, Lauren B. and Keitt, Timothy and J, Michael, Angilletta Jr},
  year = {2016},
  publisher = {{KNB Data Repository}},
  doi = {10.5063/F1Z899CZ},
  abstract = {Ecological forecasting requires information about the climatic conditions experienced by organisms. Despite impressive methodological and computational advances, ecological forecasting still suffers from poor resolutions of environmental data. Published data comprise relatively few layers of surface climate and suffer from coarse temporal resolution. Hence, models using these data might underestimate heterogeneity of microclimates and miss biological consequences of climatic extremes. Moreover, we currently lack predictions about vegetation cover in future environments, a key factor for estimating the spatial heterogeneity of microclimates and hence the capacity for behavioral thermoregulation. Here, we describe microclimates and vegetation for the past and the future at spatial and temporal resolutions of 36 km (approximately 0.3\textdegree ) and 1 h, respectively. We used the Weather Research and Forecasting model to downscale published, bias-corrected predictions of a global-circulation model from a resolution of 0.9\textdegree{} latitude and 1.25\textdegree{} longitude (approximately 100 km in latitude and 130 km in longitude). Output from this model was used as input for a microclimate model, which generated predictions for 19 variables for 1980-1999 and 2080-2099 at various heights, depths, sun angle and shade intensities. The data was evaluated using several criteria, each of which shed light on a different aspect of value to researchers. The metadata describe the modeling protocol, microclimate calculations, computer programs, and the evaluation process. The 19 predicted variables include albedo, snow layers, microclimate temperatures and pressures, among others. For a list of all variables please see the 'Model variables table' below. The dataset is structured as follows: (1) Main package: 19 monthly summaries, one for each microclimate variable (listed above) are available in this packagePackage structure schema/infographicR-script to extract and save NetCDF filesLocations table with latitude and longitude points covered in this data (csv)19 sub-packages (externally hosted, linked below) are available for this project, one for each microclimate variable.(2) Sub-packages: Within each sub-package are 44 tar files representing: 2 scenarios (past; future) across 22 geographical regions (see CoverageMap\_Levy.png for distribution of regions). The .tar file name template is [region]\_[variable code]\_[scenario]; i.e. B3\_ISNOW\_future.(3) .tar file: Each .tar file contains projection data in NetCDF format binary files for one region, one variable and for either past or future climates (1980-1999 and 2080- 2099).(4) NetCDF files : Each NetCDF file is a time-series of data for a particular variable in one location (indexed by the longitudinal-latitudinal coordinates) for either past or future climates (1980-1999 and 2080-2099). Resolutions are of 36 km and 1 hour.},
  keywords = {soil; air; albedo; canopy; radiation; humidity; snow layers; visible radiation flux; temperature; velocity; pressure; air density; climate change; vegetation; shade; downscaling; soil temperatures; wind speed; microclimate; extreme events; stochasticity},
  language = {en}
}

@article{li,
  title = {18-660: {{Numerical Methods}} for {{Engineering Design}} and {{Optimization}}},
  author = {Li, Xin},
  pages = {19},
  file = {/home/peyman/Zotero/storage/5AR4ULKV/Li - 18-660 Numerical Methods for Engineering Design a.pdf},
  language = {en}
}

@article{li2020sja,
  title = {Integration of {{Pressure Transient Data}} into {{Reservoir Models Using}} the {{Fast Marching Method}}},
  author = {Li, Chen and King, Michael J.},
  year = {2020},
  month = aug,
  volume = {25},
  pages = {1557--1577},
  issn = {1086-055X},
  doi = {10.2118/180148-PA},
  abstract = {Calibration of reservoir model properties by integration of well-test data remains an important research topic. Well-test data have been recognized as an effective tool to describe transient flow behavior in petroleum reservoirs. It is also closely related to the drainage volume of the well and the pressure-front propagation in the subsurface. Traditional analytic means of estimating reservoir permeability relies on an interpretation of the diagnostic plot of the well pressure and production data, which usually leads to a bulk average estimation of the reservoir permeability. When more detailed characterization is needed, a forward model that is sensitive to the reservoir heterogeneity needs to be established, and a numerical inversion technique is required.We use the concept of the diffusive time of flight (DTOF) to formulate an asymptotic solution of the diffusivity equation that describes transient flow behavior in heterogeneous petroleum reservoirs. The DTOF is obtained from the solution of the Eikonal equation using the fast marching method (FMM). It can be used as a spatial coordinate that reduces the 3D diffusivity equation to an equivalent 1D formulation. We investigate the drainage-volume evolution as a function of time in terms of the DTOF. The drainage volume might be directly related to the well-test derivative, which can be used in an inversion calculation to calibrate reservoir model parameters.The analytic sensitivity coefficients of the well-test derivative with respect to reservoir permeability are derived and incorporated into an objective function to perform model calibration. The key to formulating the sensitivity coefficients is to use the functional derivative of the Eikonal equation to derive the analytic sensitivity of the DTOF to reservoir permeability. Its solution is implemented by tracking the characteristic trajectory of the local Eikonal solver within the FMM. The major advantage of calculating the sensitivity coefficients using the FMM is its significant computational efficiency during the iterative inversion process.This inverse-modeling approach is tested on a 2D synthetic heterogeneous reservoir model and then applied to the 3D Brugge Field, where a single well with constant flow rate is simulated. The well-test derivative is shown to be inversely proportional to the drainage volume and is treated as the objective function for inversion. With an additional constraint to honor the prior model, our inverse-modeling approach will adjust the reservoir model to obtain permeability as a function of distance from the well within the drainage volume. It provides a modification of reservoir permeability both within and beyond the depth of investigation (DOI).},
  file = {/home/peyman/Zotero/storage/MYG99QZP/Li_King_2020_Integration of Pressure Transient Data into Reservoir Models Using the Fast.pdf;/home/peyman/Zotero/storage/QLA9X3B7/Li_King_2020_Integration of Pressure Transient Data into Reservoir Models Using the Fast.pdf},
  journal = {SPE Journal},
  number = {04}
}

@article{lim2010iteca,
  ids = {lim2010itec},
  title = {Generalizing {{Surrogate}}-{{Assisted Evolutionary Computation}}},
  author = {Lim, D. and Jin, Y. and Ong, Y. and Sendhoff, B.},
  year = {2010},
  month = jun,
  volume = {14},
  pages = {329--355},
  issn = {1941-0026},
  doi = {10.1109/TEVC.2009.2027359},
  abstract = {Using surrogate models in evolutionary search provides an efficient means of handling today's complex applications plagued with increasing high-computational needs. Recent surrogate-assisted evolutionary frameworks have relied on the use of a variety of different modeling approaches to approximate the complex problem landscape. From these recent studies, one main research issue is with the choice of modeling scheme used, which has been found to affect the performance of evolutionary search significantly. Given that theoretical knowledge available for making a decision on an approximation model a priori is very much limited, this paper describes a generalization of surrogate-assisted evolutionary frameworks for optimization of problems with objectives and constraints that are computationally expensive to evaluate. The generalized evolutionary framework unifies diverse surrogate models synergistically in the evolutionary search. In particular, it focuses on attaining reliable search performance in the surrogate-assisted evolutionary framework by working on two major issues: 1) to mitigate the 'curse of uncertainty' robustly, and 2) to benefit from the 'bless of uncertainty.' The backbone of the generalized framework is a surrogate-assisted memetic algorithm that conducts simultaneous local searches using ensemble and smoothing surrogate models, with the aims of generating reliable fitness prediction and search improvements simultaneously. Empirical study on commonly used optimization benchmark problems indicates that the generalized framework is capable of attaining reliable, high quality, and efficient performance under a limited computational budget.},
  eventtitle = {{{IEEE Transactions}} on {{Evolutionary Computation}}},
  file = {/home/peyman/Documents/PhD_UiS/zotero_library/Lim et al/Lim et al_2010_Generalizing Surrogate-Assisted Evolutionary Computation.pdf;/home/peyman/Zotero/storage/GRDWV9XI/Lim et al_2010_Generalizing Surrogate-Assisted Evolutionary Computation.pdf},
  journal = {IEEE Transactions on Evolutionary Computation},
  keywords = {Approximation models,Computational modeling,computationally expensive problems,Constraint optimization,Constraint theory,Evolutionary computation,High performance computing,memetic algorithms,metamodels,Predictive models,Robustness,Smoothing methods,Spine,surrogate models,surrogate-assisted evolutionary algorithms,Uncertainty},
  number = {3}
}

@article{louppe,
  title = {Likelihood-Free Inference in {{Physical Sciences}}},
  author = {Louppe, Gilles},
  pages = {70},
  file = {/home/peyman/Zotero/storage/KSTZHZ3J/Louppe - Likelihood-free inference in Physical Sciences.pdf},
  language = {en}
}

@misc{marcdeisenroth,
  title = {Gaussian {{Processes}} - {{Part}} 2},
  author = {{Marc Deisenroth}},
  abstract = {685 views \textbullet{} Jan 6, 2021                       Show less                       Show more}
}

@inproceedings{memon20142sic,
  title = {Surrogate Reservoir Modeling-Prediction of {{Bottom}}-{{Hole Flowing Pressure}} Using {{Radial Basis Neural Network}}},
  booktitle = {2014 {{Science}} and {{Information Conference}}},
  author = {Memon, P. Q. and Yong, S.-P. and Pao, W. and Sean, P. J.},
  year = {2014},
  month = aug,
  pages = {499--504},
  doi = {10.1109/SAI.2014.6918234},
  abstract = {Reservoir simulation provides information about the behaviour of a reservoir in various production and injection conditions. Reservoir simulator is used to predict the future behaviour and performance of a reservoir field. However, the heterogeneity of reservoir and uncertainty in the reservoir field cause some obstacles in selecting the best calculation of oil, water and gas components that lead to the production system in oil and gas. Due to intrinsic uncertainty in the reservoir simulation models, large number of computational resources such as simulation runs and long processing time are required to predict the properties in a reservoir. This paper presents an application of Surrogate Reservoir Model (SRM) for predicting the Bottom-Hole Flowing Pressure (BHFP) at different time step for an initially under-saturated reservoir. The developed SRM is based on Artificial Neural Network to regenerate the results of a numerical simulation model in considerable amount of time. The output of the reservoir simulation consists of oil production, gas rate, average reservoir pressure, saturation and BHFP etc. The proposed SRM adopted Radial Basis Neural Network to predict the BHFP based on the output data extracted from the Black Oil Applied Simulation Tool (BOAST). It is found that the developed SRM is capable in supporting fast track analysis, decision optimization and manage to generate the results in a shorter time as compared to the conventional reservoir model.},
  eventtitle = {2014 {{Science}} and {{Information Conference}}},
  file = {/home/peyman/Documents/PhD_UiS/zotero_library/Memon et al/Memon et al_2014_Surrogate reservoir modeling-prediction of Bottom-Hole Flowing Pressure using.pdf;/home/peyman/Zotero/storage/5KJA2QJ9/Memon et al_2014_Surrogate reservoir modeling-prediction of Bottom-Hole Flowing Pressure using.pdf},
  keywords = {artificial neural network,average reservoir pressure,Black Oil Applied Simulation Tool,bottom-hole flowing pressure,Computational modeling,computational resources,decision optimization,digital simulation,fast track analysis,gas industry,gas rate,hydrocarbon reservoirs,injection conditions,Neurons,oil production,Permeability,petroleum industry,Predictive models,pressure measurement,processing time,Production,radial basis function networks,radial basis neural network,Radial Basis Neural Network,reservoir simulation,Reservoirs,simulation runs,Surrogate Reservoir Model,surrogate reservoir modeling-prediction,Training,under-saturated reservoir,water component}
}

@article{mirjalili2015aies,
  title = {The {{Ant Lion Optimizer}}},
  author = {Mirjalili, Seyedali},
  year = {2015},
  month = may,
  volume = {83},
  pages = {80--98},
  issn = {09659978},
  doi = {10.1016/j.advengsoft.2015.01.010},
  file = {/home/peyman/Zotero/storage/DQ4KKN4P/Mirjalili - 2015 - The Ant Lion Optimizer.pdf},
  journal = {Advances in Engineering Software},
  language = {en}
}

@incollection{mockus1975otitcnj11,
  title = {On Bayesian Methods for Seeking the Extremum},
  booktitle = {Optimization {{Techniques IFIP Technical Conference Novosibirsk}}, {{July}} 1\textendash 7, 1974},
  author = {Mo{\v c}kus, J.},
  editor = {Goos, G. and Hartmanis, J. and Brinch Hansen, P. and Gries, D. and Moler, C. and Seegm{\"u}ller, G. and Wirth, N. and Marchuk, G. I.},
  year = {1975},
  volume = {27},
  pages = {400--404},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/3-540-07165-2_55},
  file = {/home/peyman/Zotero/storage/IXVTDFMZ/Močkus_1975_On bayesian methods for seeking the extremum.pdf},
  isbn = {978-3-540-07165-5 978-3-540-37497-8}
}

@inproceedings{mohaghegh2006satce,
  title = {Development of {{Surrogate Reservoir Models}} ({{SRM}}) for {{Fast}}-{{Track Analysis}} of {{Complex Reservoirs}}},
  booktitle = {{{SPE Annual Technical Conference}} and {{Exhibition}}},
  author = {Mohaghegh, S D and Guruswamy, S},
  year = {2006},
  pages = {9},
  address = {{San Antonio, Texas, U.S.A}},
  abstract = {Reservoir simulation has become the industry standard for reservoir management. It is now used in all phases of field development in the oil and gas industry. The full field reservoir models that have become the major source of information and prediction for decision making are continuously updated and major fields now have several versions of their model with each new version being a major improvement over the previous one. The newer versions have the latest information (geologic, geophysical and petrophysical measurements, interpretations and calculations based on new logs, seismic data, injection and productions, etc.) incorporated in them along with adjustments that usually are the result of single-well or multi-well history matching.},
  file = {/home/peyman/Zotero/storage/7JHNUAKG/Mohaghegh_Guruswamy_2006_Development of Surrogate Reservoir Models (SRM) for Fast-Track Analysis of.pdf;/home/peyman/Zotero/storage/IX7GDC2H/Mohaghegh and Guruswamy - Development of Surrogate Reservoir Models (SRM) fo.pdf},
  language = {en}
}

@article{mohaghegha,
  ids = {mohaghegh},
  title = {Quantifying {{Uncertainties Associated}} with {{Reservoir Simulation Studies Using Surrogate Reservoir Models}}},
  author = {Mohaghegh, S D},
  pages = {10},
  abstract = {Reservoir simulation is routinely used as a reservoir management tool. The static model that is used as the basis for simulation is the result of an integrated effort that usually includes the latest geological, geophysical and petro-physical measurements and interpretations. As such, it is inherently a model with some uncertainty. Analysis of these uncertainties and quantification of their effects on oil production and water cut using a new and efficient technique is the subject of this paper.},
  file = {/home/peyman/Zotero/storage/A8J2IYBV/Mohaghegh_Quantifying Uncertainties Associated with Reservoir Simulation Studies Using.pdf;/home/peyman/Zotero/storage/KJ3PDKPT/Mohaghegh - Quantifying Uncertainties Associated with Reservoi.pdf},
  language = {en}
}

@article{mokhtari,
  title = {Global {{Convergence}} of {{Online Limited Memory BFGS}}},
  author = {Mokhtari, Aryan and Ribeiro, Alejandro},
  pages = {31},
  abstract = {Global convergence of an online (stochastic) limited memory version of the Broyden-FletcherGoldfarb-Shanno (BFGS) quasi-Newton method for solving optimization problems with stochastic objectives that arise in large scale machine learning is established. Lower and upper bounds on the Hessian eigenvalues of the sample functions are shown to suffice to guarantee that the curvature approximation matrices have bounded determinants and traces, which, in turn, permits establishing convergence to optimal arguments with probability 1. Experimental evaluation on a search engine advertising problem showcase reductions in convergence time relative to stochastic gradient descent algorithms.},
  file = {/home/peyman/Zotero/storage/4H32XBTF/Mokhtari and Ribeiro - Global Convergence of Online Limited Memory BFGS.pdf},
  language = {en}
}

@article{mullen2014jss,
  title = {Continuous {{Global Optimization}} in {{R}}},
  author = {Mullen, Katharine M.},
  year = {2014},
  month = sep,
  volume = {60},
  pages = {1--45},
  issn = {1548-7660},
  doi = {10.18637/jss.v060.i06},
  copyright = {Copyright (c) 2012 Katharine M. Mullen},
  file = {/home/peyman/Zotero/storage/L9K4S7BR/Mullen_2014_Continuous Global Optimization in R.pdf},
  journal = {Journal of Statistical Software},
  language = {en},
  number = {1}
}

@article{nasir2020jopsae,
  title = {Hybrid Derivative-Free Technique and Effective Machine Learning Surrogate for Nonlinear Constrained Well Placement and Production Optimization},
  author = {Nasir, Yusuf and Yu, Wei and Sepehrnoori, Kamy},
  year = {2020},
  month = mar,
  volume = {186},
  pages = {106726},
  issn = {0920-4105},
  doi = {10.1016/j.petrol.2019.106726},
  abstract = {It is imperative that wells in an oil field be located and controlled in an optimal fashion to maximize asset value while satisfying the optimization constraints which can be in the form of production limits, water cut, or well spacing. Computational optimization algorithms coupled with a reservoir simulator have become increasingly popular in determining the optimal locations of wells and the optimal controls to be imposed on them. These algorithms should be able to deal with highly non-linear objective functions, the absence of gradient information, and a limited reservoir simulation budget. In this work, we considered derivative-free and non-invasive techniques: Enhanced Success History-Based Adaptive Differential Evolution (ESHADE) strategy with linear population size reduction, which is a variant of L-SHADE (recognized as one of the state-of-the-art global stochastic optimizers for continuous variable), and a Mesh Adaptive Direct Search (MADS) local pattern search method. These two methods are hybridized to develop a hybrid framework (E-MADS) that combines the advantageous aspects of both methods in order to improve optimization efficiency. In order to further improve the efficiency of the framework, gradient boosting machine learning technique is used to generate proxy model, based on regression and classification methods, to predict the objective function and classify optimization solutions into feasibless (satisfies all prescribed constraints) and infeasible groups. This information is then used to screen out solutions that are not expected to improve the objective function. Applications of these algorithms to the joint optimization of well location and time-varying control problem, with bounds and nonlinear constraints, are presented in this work. ESHADE is shown to outperform traditional global optimization algorithms such as Particle Swarm Optimization (PSO) and a real-coded Genetic Algorithm (GA). The E-MADS hybrid is also shown to have a superior performance relative to the standalone ESHADE and MADS methods for the joint optimization problem.},
  file = {/home/peyman/Zotero/storage/JVLXUQPK/Nasir et al_2020_Hybrid derivative-free technique and effective machine learning surrogate for.pdf},
  journal = {Journal of Petroleum Science and Engineering},
  keywords = {Derivative-free optimization,Differential evolution,Machine learning,Production optimization,Well placement},
  language = {en}
}

@article{nasir2021oe,
  title = {A Two-Stage Optimization Strategy for Large-Scale Oil Field Development},
  author = {Nasir, Yusuf and Volkov, Oleg and Durlofsky, Louis J.},
  year = {2021},
  month = jan,
  issn = {1573-2924},
  doi = {10.1007/s11081-020-09591-y},
  abstract = {The optimization of the locations of a large number of wells in an oil or gas field represents a challenging computational problem. This is because the number of optimization variables scales with the maximum number of wells considered. In this work, we develop and test a new two-stage strategy for large-scale oil field optimization problems. In the first stage, wells are constrained to lie in repeated patterns, and the reduced set of optimization variables defines the pattern type and geometry (e.g., well spacing, orientation). For this component of the optimization, we introduce several important modifications, including optimization of the drilling sequence, to an existing well-pattern optimization procedure. The solutions obtained in the first stage are then used to initialize the second stage optimization. In this stage we apply comprehensive field development optimization, where the well location, type (injection or production well), drill/do not drill decision, completion interval for 3D models, and drilling time variables are determined for each well. Pattern geometry is no longer enforced in this stage. Specialized treatments (consistent with actual drilling practice) are introduced for cases where multiple geomodels, used to capture geological uncertainty, are considered. In both stages optimization is achieved using a particle swarm optimization-mesh adaptive direct search (PSO-MADS) method. The two-stage procedure is applied to 2D and 3D models corresponding to different geological scenarios. Both deterministic and geologically uncertain systems are considered. Optimization results using the new procedure are shown to clearly outperform those from the single-stage comprehensive field development optimization approach. Specifically, for the same number of function evaluations, the two-stage treatment provides net present values that exceed those of the single-stage approach by about 15\textendash 18\% for the cases considered. This suggests that this optimization strategy may indeed lead to improved results in practical problems.},
  file = {/home/peyman/Zotero/storage/Y27U4QY5/Nasir et al_2021_A two-stage optimization strategy for large-scale oil field development.pdf},
  journal = {Optimization and Engineering},
  language = {en}
}

@article{nasir2021oea,
  title = {A Two-Stage Optimization Strategy for Large-Scale Oil Field Development},
  author = {Nasir, Yusuf and Volkov, Oleg and Durlofsky, Louis J.},
  year = {2021},
  month = jan,
  issn = {1389-4420, 1573-2924},
  doi = {10.1007/s11081-020-09591-y},
  abstract = {The optimization of the locations of a large number of wells in an oil or gas field represents a challenging computational problem. This is because the number of optimization variables scales with the maximum number of wells considered. In this work, we develop and test a new two-stage strategy for large-scale oil field optimization problems. In the first stage, wells are constrained to lie in repeated patterns, and the reduced set of optimization variables defines the pattern type and geometry (e.g., well spacing, orientation). For this component of the optimization, we introduce several important modifications, including optimization of the drilling sequence, to an existing well-pattern optimization procedure. The solutions obtained in the first stage are then used to initialize the second stage optimization. In this stage we apply comprehensive field development optimization, where the well location, type (injection or production well), drill/do not drill decision, completion interval for 3D models, and drilling time variables are determined for each well. Pattern geometry is no longer enforced in this stage. Specialized treatments (consistent with actual drilling practice) are introduced for cases where multiple geomodels, used to capture geological uncertainty, are considered. In both stages optimization is achieved using a particle swarm optimization-mesh adaptive direct search (PSO-MADS) method. The two-stage procedure is applied to 2D and 3D models corresponding to different geological scenarios. Both deterministic and geologically uncertain systems are considered. Optimization results using the new procedure are shown to clearly outperform those from the single-stage comprehensive field development optimization approach. Specifically, for the same number of function evaluations, the two-stage treatment provides net present values that exceed those of the single-stage approach by about 15\textendash 18\% for the cases considered. This suggests that this optimization strategy may indeed lead to improved results in practical problems.},
  file = {/home/peyman/Zotero/storage/5549F8ZK/Nasir et al. - 2021 - A two-stage optimization strategy for large-scale .pdf},
  journal = {Optimization and Engineering},
  language = {en}
}

@phdthesis{nezhadali,
  title = {Hybridization of Gradient-Based and Gradient-Free Optimization Techniques for Simultaneous Optimization of Number of Wells, Their Location and Drilling Time in a 2-Dimensional Reservoir.},
  author = {Nezhadali, Moahmmad},
  file = {/home/peyman/Zotero/storage/BN49PFGP/Nezhadali_Hybridization of gradient-based and gradient-free optimization techniques for.pdf;/home/peyman/Zotero/storage/XI6F4RKU/Nezhadali_Moahmmad.pdf},
  school = {University of Stavanger}
}

@book{nocedal2006,
  title = {Numerical Optimization},
  author = {Nocedal, Jorge and Wright, Stephen J.},
  year = {2006},
  edition = {2nd ed},
  publisher = {{Springer}},
  address = {{New York}},
  annotation = {OCLC: ocm68629100},
  file = {/home/peyman/Zotero/storage/CH4BIPZN/Nocedal and Wright - 2006 - Numerical optimization.pdf},
  isbn = {978-0-387-30303-1},
  keywords = {Mathematical optimization},
  language = {en},
  lccn = {QA402.5 .N62 2006},
  series = {Springer Series in Operations Research}
}

@book{nuwara2020,
  title = {Coupling {{Python}} with {{MATLAB Reservoir Simulation Toolbox}} ({{MRST}}) to {{Enhance Well Placement Optimization}} and Its {{Opportunity}} for {{Computational Parallelization}}},
  author = {Nuwara, Ignatius},
  year = {2020},
  month = nov,
  doi = {10.13140/RG.2.2.10261.55529},
  abstract = {A Bayesian optimizer in Python tries to optimize the cumulative oil production as the only objective function in a five-spot waterflooding simulation in the 61st layer of the SPE 10 model using MATLAB Reservoir Simulation Toolbox (MRST), in Google Colab. This experiment is not intended to conduct the optimization commonly done in the well placement optimization but to show that any Python optimizer could be coupled to a simulator of a different programming language, such as the MRST in MATLAB. What is more interesting is that the coupling is done in Google Colab, a free Python cloud IDE that is widely used for deep learning.},
  file = {/home/peyman/Zotero/storage/4IRUFAYC/Nuwara_2020_Coupling Python with MATLAB Reservoir Simulation Toolbox (MRST) to Enhance Well.pdf}
}

@phdthesis{nwachukwu2018,
  title = {Machine {{Learning Solutions}} for {{Reservoir Characterization}}, {{Management}}, and {{Optimization}}},
  author = {Nwachukwu, Chiazor},
  year = {2018},
  month = dec,
  file = {/home/peyman/Zotero/storage/8588FZDC/Nwachukwu_2018_Machine Learning Solutions for Reservoir Characterization, Management, and.pdf;/home/peyman/Zotero/storage/ENBQHPEU/NWACHUKWU-DISSERTATION-2018.pdf}
}

@inproceedings{nwachukwu2018a,
  title = {Machine {{Learning}}-{{Based Optimization}} of {{Well Locations}} and {{WAG Parameters}} under {{Geologic Uncertainty}}},
  booktitle = {{{SPE Improved Oil Recovery Conference}}},
  author = {Nwachukwu, Azor and Jeong, Hoonyoung and Sun, Alexander and Pyrcz, Michael and Lake, Larry W.},
  year = {2018},
  month = apr,
  publisher = {{OnePetro}},
  doi = {10.2118/190239-MS},
  file = {/home/peyman/Zotero/storage/JE49KUBW/Nwachukwu et al_2018_Machine Learning-Based Optimization of Well Locations and WAG Parameters under.pdf},
  language = {en}
}

@article{nwachukwu2018jopsae,
  title = {Fast Evaluation of Well Placements in Heterogeneous Reservoir Models Using Machine Learning},
  author = {Nwachukwu, Azor and Jeong, Hoonyoung and Pyrcz, Michael and Lake, Larry W.},
  year = {2018},
  month = apr,
  volume = {163},
  pages = {463--475},
  issn = {09204105},
  doi = {10.1016/j.petrol.2018.01.019},
  abstract = {Surrogate models, or proxies, provide computationally inexpensive alternatives for approximating reservoir responses. Proxy models are routinely developed to generate spatially-varying output such as field pressures and saturations, or well responses such as production rates and bottom-hole pressures. In this study, a machine learning approach is adopted to predict reservoir responses based on injector well locations. The proxy developed in this work is trained to reproduce reservoir-wide objective functions, i.e., total profit, cumulative oil/gas produced, or net CO2 stored.},
  file = {/home/peyman/Zotero/storage/A2SI7XT8/Nwachukwu et al_2018_Fast evaluation of well placements in heterogeneous reservoir models using.pdf;/home/peyman/Zotero/storage/HXC6PT2Y/Nwachukwu et al. - 2018 - Fast evaluation of well placements in heterogeneou.pdf},
  journal = {Journal of Petroleum Science and Engineering},
  language = {en}
}

@article{nygard2020sja,
  title = {Simulation of {{Immiscible Water}}-{{Alternating}}-{{Gas Injection}} in a {{Stratified Reservoir}}: {{Performance Characterization Using}} a {{New Dimensionless Number}}},
  shorttitle = {Simulation of {{Immiscible Water}}-{{Alternating}}-{{Gas Injection}} in a {{Stratified Reservoir}}},
  author = {Nyg{\aa}rd, Jan Inge and Andersen, P{\aa}l {\O}steb{\o}},
  year = {2020},
  month = aug,
  volume = {25},
  pages = {1711--1728},
  issn = {1086-055X, 1930-0220},
  doi = {10.2118/200479-PA},
  abstract = {Water alternating gas (WAG) is a well-established enhanced-oil-recovery process where gas and water are injected in alternating fashion. Good volumetric sweep is achieved as water and gas target both the oil residing in low and high portions of the reservoir, respectively. Other important features in three-phase hysteretic flow include phase trapping, which is believed to be more strongly associated with the gas phase. With these aspects in mind, a vast simulation study has been performed investigating immiscible WAG injection focusing on mechanisms such as mobility, gravity, injected volume fractions, reservoir heterogeneity, gas entrapment, and relative permeability hysteresis.},
  file = {/home/peyman/Zotero/storage/G36G2FKS/Nygård_Andersen_2020_Simulation of Immiscible Water-Alternating-Gas Injection in a Stratified.pdf;/home/peyman/Zotero/storage/UHLKB76J/Nygård and Andersen - 2020 - Simulation of Immiscible Water-Alternating-Gas Inj.pdf},
  journal = {SPE Journal},
  language = {en},
  number = {04}
}

@misc{ph.d2019m,
  ids = {ph.d2019ma},
  title = {Genetic {{Algorithm}} \textemdash{} Explained Step by Step with Example},
  author = {Ph.D, Niranjan Pramanik},
  year = {2019},
  month = sep,
  abstract = {A step by step description of Genetic Algorithm and its application in numerical optimization problem.},
  howpublished = {https://towardsdatascience.com/genetic-algorithm-explained-step-by-step-65358abe2bf},
  journal = {Medium},
  language = {en},
  organization = {{Medium}}
}

@article{raissi2019jocp,
  title = {Physics-Informed Neural Networks: {{A}} Deep Learning Framework for Solving Forward and Inverse Problems Involving Nonlinear Partial Differential Equations},
  shorttitle = {Physics-Informed Neural Networks},
  author = {Raissi, M. and Perdikaris, P. and Karniadakis, G. E.},
  year = {2019},
  month = feb,
  volume = {378},
  pages = {686--707},
  issn = {0021-9991},
  doi = {10.1016/j.jcp.2018.10.045},
  abstract = {We introduce physics-informed neural networks \textendash{} neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge\textendash Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction\textendash diffusion systems, and the propagation of nonlinear shallow-water waves.},
  file = {/home/peyman/Zotero/storage/XK47TJIR/Raissi et al_2019_Physics-informed neural networks.pdf},
  journal = {Journal of Computational Physics},
  keywords = {Data-driven scientific computing,Machine learning,Nonlinear dynamics,Predictive modeling,Runge–Kutta methods},
  language = {en}
}

@article{rammay2019joh,
  title = {Quantification of Prediction Uncertainty Using Imperfect Subsurface Models with Model Error Estimation},
  author = {Rammay, Muzammil Hussain and Elsheikh, Ahmed H. and Chen, Yan},
  year = {2019},
  month = sep,
  volume = {576},
  pages = {764--783},
  issn = {0022-1694},
  doi = {10.1016/j.jhydrol.2019.02.056},
  abstract = {Subsurface reservoirs are far more heterogeneous and complex than the simulation models in terms of scale, assumptions and description. In this work, we address the issue of prediction reliability while calibrating imperfect/low-fidelity reservoir models. The main goal is to avoid over-confident and inaccurate predictions by including a model for the bias terms (i.e. error-model of a predefined form) during the history matching process. Our aim is to obtain unbiased posterior distributions of the physical model parameters and thus improving the prediction capacity of the calibrated low-fidelity reservoir models. We formulate the parameter estimation problem as a joint estimation of the imperfect model parameters and the error-model parameters. The structure of the error-model and the prior distributions of the error-model parameters are evaluated before calibration through analysis of leading sources of the modeling errors. We adopt a Bayesian framework for solving the inverse problem, where we utilize the ensemble smoother with multiple data assimilation (ES-MDA) as a practical history matching algorithm. We provide two test cases, where the impact of typical model errors originating from grid coarsening/up-scaling and from utilizing an imperfect geological model description is investigated. For both cases results from the ES-MDA update with and without accounting for model error are compared in terms of estimated physical model parameters, quality of match to historical data and forecasting ability compared to held out data. The test results show that calibration of the imperfect physical model without accounting for model errors results in extreme values of the calibrated model parameters and a biased posterior distribution. With accounting for modeling errors the posterior distribution of the model parameters is less biased (i.e. nearly unbiased) and improved forecasting skills with higher prediction accuracy/reliability is observed. Moreover, the consistency between the different runs of the ES-MDA is improved by including the modeling error component. Although the examples in the paper consider the oil-water system with permeabilities being parameters of the physical model, the developed methodology is general and can be applied to typical ground water hydrology models.},
  file = {/home/peyman/Zotero/storage/I2BC6EDC/Rammay et al_2019_Quantification of prediction uncertainty using imperfect subsurface models with.pdf},
  journal = {Journal of Hydrology},
  keywords = {Bayesian inversion,Error-model,History matching (calibration),Model error (model bias/model discrepancy),Principle component analysis (PCA)},
  language = {en}
}

@article{rasmussen2021c&mwa,
  title = {The {{Open Porous Media Flow}} Reservoir Simulator},
  author = {Rasmussen, Atgeirr Fl{\o} and Sandve, Tor Harald and Bao, Kai and Lauser, Andreas and Hove, Joakim and Skaflestad, B{\aa}rd and Kl{\"o}fkorn, Robert and Blatt, Markus and Rustad, Alf Birger and S{\ae}vareid, Ove and Lie, Knut-Andreas and Thune, Andreas},
  year = {2021},
  month = jan,
  volume = {81},
  pages = {159--185},
  issn = {0898-1221},
  doi = {10.1016/j.camwa.2020.05.014},
  abstract = {The Open Porous Media (OPM) initiative is a community effort that encourages open innovation and reproducible research for simulation of porous media processes. OPM coordinates collaborative software development, maintains and distributes open-source software and open data sets, and seeks to ensure that these are available under a free license in a long-term perspective. In this paper, we present OPM Flow, which is a reservoir simulator developed for industrial use, as well as some of the individual components used to make OPM Flow. The descriptions apply to the 2019.10 release of OPM.},
  file = {/home/peyman/Zotero/storage/NQJ7ZDQC/Rasmussen et al_2021_The Open Porous Media Flow reservoir simulator.pdf},
  journal = {Computers \& Mathematics with Applications},
  language = {en},
  series = {Development and {{Application}} of {{Open}}-Source {{Software}} for {{Problems}} with {{Numerical PDEs}}}
}

@article{razghandi2021jpept,
  title = {Application of Particle Swarm Optimization and Genetic Algorithm for Optimization of a Southern {{Iranian}} Oilfield},
  author = {Razghandi, Milad and Dehghan, Aliakbar and Yousefzadeh, Reza},
  year = {2021},
  month = apr,
  volume = {11},
  pages = {1781--1796},
  issn = {2190-0566},
  doi = {10.1007/s13202-021-01120-6},
  abstract = {Optimization of the placement and operational conditions of oil wells plays an important role in the development of the oilfields. Several automatic optimization algorithms have been used by different authors in recent years. However, different optimizers give different results depending on the nature of the problem. In the current study, a comparison between the genetic algorithm and particle swarm optimization algorithms~was made to optimize the operational conditions of the injection and production wells and also to optimize the location of the injection wells in a southern Iranian oilfield. The current study was~carried out with the principal~purpose of evaluating and comparing the performance of the two most used optimization algorithms for field development optimization on real-field data. Also, a comparison was made between the results of sequential and simultaneous optimization of the decision variables. Net present value of the project was used as the objective function, and the two algorithms were compared in terms of the profitability incremental added to the project over twelve years. First, the production rate of the producers was optimized, and then water alternating gas injection wells were added to the field at locations determined by engineering judgment. Afterward, the location, injection rate, and water alternating gas ratio of the injectors were optimized sequentially using the two algorithms. Next, the production rate of the producers was optimized again. Finally, a simultaneous optimization was~done in two manners to evaluate its effect on the optimization results: simultaneous optimization of the last two steps and simultaneous optimization of all decision variables. Results showed the positive effect of the algorithms on the profitability of the project~and superiority of~the particle swarm optimization over the genetic algorithm at every stage. Also, simultaneous optimization was beneficial at finiding better results compared to~sequential optimization approach. In the end, a sensitivity analysis was made to specify the most influencing decision variable on the project's profitability.},
  file = {/home/peyman/Zotero/storage/RQFW5Z2Y/Razghandi et al_2021_Application of particle swarm optimization and genetic algorithm for.pdf},
  journal = {Journal of Petroleum Exploration and Production},
  language = {en},
  number = {4}
}

@book{riederer,
  title = {R {{Markdown Cookbook}}},
  author = {Riederer, Christophe Dervieux, Emily, Yihui Xie},
  abstract = {This book showcases short, practical examples of lesser-known tips and tricks to helps users get the most out of these tools. After reading this book, you will understand how R Markdown documents are transformed from plain text and how you may customize nearly every step of this processing. For example, you will learn how to dynamically create content from R code, reference code in other documents or chunks, control the formatting with customer templates, fine-tune how your code is processed, and incorporate multiple languages into your analysis.}
}

@article{roeva2013,
  title = {Influence of the {{Population Size}} on the {{Genetic Algorithm Performance}} in {{Case}} of {{Cultivation Process Modelling}}},
  author = {Roeva, Olympia and Fidanova, Stefka and Paprzycki, Marcin},
  year = {2013},
  pages = {6},
  abstract = {In this paper, an investigation of the influence of the population size on the genetic algorithm (GA) performance for a model parameter identification problem, is considered. The mathematical model of an E. coli fed-batch cultivation process is studied. The three model parameters \textendash{} maximum specific growth rate (\textmu max), saturation constant (kS) and yield coefficient (YS/X ) are estimated using different population sizes. Population sizes between 5 and 200 chromosomes in the population are tested with constant number of generations. In order to obtain meaningful information about the influence of the population size a considerable number of independent runs of the GA are performed. The observed results show that the optimal population size is 100 chromosomes for 200 generations. In this case accurate model parameters values are obtained in reasonable computational time. Further increase of the population size, above 100 chromosomes, does not improve the solution accuracy. Moreover, the computational time is increased significantly.},
  file = {/home/peyman/Zotero/storage/ZHY53CFN/Roeva et al. - 2013 - Influence of the Population Size on the Genetic Al.pdf},
  language = {en}
}

@article{roustant2012jss,
  title = {{{{\textbf{DiceKriging}}}} , {{{\textbf{DiceOptim}}}} : {{Two}} {{{\emph{R}}}} {{Packages}} for the {{Analysis}} of {{Computer Experiments}} by {{Kriging}}-{{Based Metamodeling}} and {{Optimization}}},
  shorttitle = {{{{\textbf{DiceKriging}}}} , {{{\textbf{DiceOptim}}}}},
  author = {Roustant, Olivier and Ginsbourger, David and Deville, Yves},
  year = {2012},
  volume = {51},
  issn = {1548-7660},
  doi = {10.18637/jss.v051.i01},
  abstract = {We present two recently released R packages, DiceKriging and DiceOptim, for the approximation and the optimization of expensive-to-evaluate deterministic functions. Following a self-contained mini tutorial on Kriging-based approximation and optimization, the functionalities of both packages are detailed and demonstrated in two distinct sections. In particular, the versatility of DiceKriging with respect to trend and noise specifications, covariance parameter estimation, as well as conditional and unconditional simulations are illustrated on the basis of several reproducible numerical experiments. We then put to the fore the implementation of sequential and parallel optimization strategies relying on the expected improvement criterion on the occasion of DiceOptim's presentation. An appendix is dedicated to complementary mathematical and computational details.},
  file = {/home/peyman/Zotero/storage/D8SN8YVB/Roustant et al. - 2012 - DiceKriging , DiceOptim  Two R.pdf},
  journal = {Journal of Statistical Software},
  language = {en},
  number = {1}
}

@article{roustant2012jssa,
  title = {{{{\textbf{DiceKriging}}}} , {{{\textbf{DiceOptim}}}} : {{Two}} {{{\emph{R}}}} {{Packages}} for the {{Analysis}} of {{Computer Experiments}} by {{Kriging}}-{{Based Metamodeling}} and {{Optimization}}},
  shorttitle = {{{{\textbf{DiceKriging}}}} , {{{\textbf{DiceOptim}}}}},
  author = {Roustant, Olivier and Ginsbourger, David and Deville, Yves},
  year = {2012},
  volume = {51},
  issn = {1548-7660},
  doi = {10.18637/jss.v051.i01},
  abstract = {We present two recently released R packages, DiceKriging and DiceOptim, for the approximation and the optimization of expensive-to-evaluate deterministic functions. Following a self-contained mini tutorial on Kriging-based approximation and optimization, the functionalities of both packages are detailed and demonstrated in two distinct sections. In particular, the versatility of DiceKriging with respect to trend and noise specifications, covariance parameter estimation, as well as conditional and unconditional simulations are illustrated on the basis of several reproducible numerical experiments. We then put to the fore the implementation of sequential and parallel optimization strategies relying on the expected improvement criterion on the occasion of DiceOptim's presentation. An appendix is dedicated to complementary mathematical and computational details.},
  file = {/home/peyman/Zotero/storage/2G34HC8S/Roustant et al. - 2012 - DiceKriging , DiceOptim  Two R.pdf},
  journal = {Journal of Statistical Software},
  language = {en},
  number = {1}
}

@article{sampaio2009a,
  ids = {sampaio2009,sampaioa},
  title = {An {{Application}} of {{Feed Forward Neural Network}} as {{Nonlinear Proxies}} for the {{Use During}} the {{History Matching Phase}}},
  author = {Sampaio, T P},
  year = {2009},
  pages = {11},
  abstract = {Reservoir simulation is an important tool used in the industry for reservoir management. While developing a field, a reservoir simulation model is used as a decision tool to select the best development scheme and also to forecast the oil, gas, and water production expected for the field. Uncertainties are much higher at the early phases and, when production data are gathered during the field development phase, most of the time the initial reservoir simulation model needs to be reviewed once the field observed data is not as the same as the predicted by the model. Some of these uncertainties of these input parameters are related to the reservoir rock reservoir heterogeneities.},
  file = {/home/peyman/Zotero/storage/8M6FVKYT/Sampaio - An Application of Feed Forward Neural Network as N.pdf;/home/peyman/Zotero/storage/SWEBHDKS/Sampaio - An Application of Feed Forward Neural Network as N.pdf;/home/peyman/Zotero/storage/UGIYZ5V7/Sampaio - An Application of Feed Forward Neural Network as N.pdf;/home/peyman/Zotero/storage/ZQBCQQAN/Sampaio - An Application of Feed Forward Neural Network as N.pdf},
  language = {en}
}

@phdthesis{sayarpour2008,
  title = {Development and Application of Capacitance-Resistive Models to Water/{{CO}}{$_2$} Floods},
  author = {Sayarpour, Morteza},
  year = {2008},
  month = aug,
  abstract = {Quick evaluation of reservoir performance is a main concern in decision making. Time-consuming input data preparation and computing, along with data uncertainty tend to inhibit the use of numerical reservoir simulators. New analytical solutions are developed for capacitance-resistive models (CRMs) as fast predictive techniques, and their application in history-matching, optimization, and evaluating reservoir uncertainty for water/CO{$_2$} floods are demonstrated. Because the CRM circumvents reservoir geologic modeling and saturation-matching issues, and only uses injection/production rate and bottomhole pressure data, it lends itself to rapid and frequent reservoir performance evaluation. This study presents analytical solutions for the continuity equation using superposition in time and space for three different reservoir-control volumes: 1) entire field volume, 2) volume drained by each producer, and 3) drainage volume between an injector/producer pair. These analytical solutions allow rapid estimation of the CRM unknown parameters: the interwell connectivity and production response time constant. The calibrated model is then combined with oil fractional-flow models for water/CO{$_2$} floods to match the oil production history. Thereafter, the CRM is used for prediction, optimization, flood performance evaluation, and reservoir uncertainty quantification. Reservoir uncertainty quantification is directly obtained from several equiprobable history-matched solutions (EPHMS) of the CRM. We validated CRM's capabilities with numerical flow-simulation results and tested its applicability in several field case studies involving water/CO{$_2$} floods. Development and application of fast, simple and yet powerful analytic tools, like CRMs that only rely on injection and production data, enable rapid reservoir performance evaluation with an acceptable accuracy. Field engineers can quickly obtain significant insights about flood efficiency by estimating interwell connectivities and use the CRM to manage and optimize real time reservoir performance. Frequent usage of the CRM enables evaluation of numerous sets of the EPHMS and consequently quantification of reservoir uncertainty. The EPHMS sets provide good sampling domains and reasonable guidelines for selecting appropriate input data for full-field numerical modeling by evaluating the range and proper combination of uncertain reservoir parameters. Significant engineering and computing time can be saved by limiting numerical simulation input data to the EPHMS sets obtained from the CRMs.},
  annotation = {Accepted: 2012-04-13T16:22:22Z},
  copyright = {Copyright is held by the author. Presentation of this material on the Libraries' web site by University Libraries, The University of Texas at Austin was made possible under a limited license grant from the author who has retained all copyrights in the works.},
  file = {/home/peyman/Documents/PhD_UiS/zotero_library/Sayarpour/Sayarpour_2008_Development and application of capacitance-resistive models to water-CO₂ floods.pdf;/home/peyman/Zotero/storage/GFET5VSN/Sayarpour_2008_Development and application of capacitance-resistive models to water-CO₂ floods.pdf},
  language = {eng}
}

@article{sayarpoura,
  title = {The {{Use}} of {{Capacitance}}-{{Resistive Models}} for {{Rapid Estimation}} of {{Waterflood Performance}} and {{Optimization}}},
  author = {Sayarpour, M},
  pages = {13},
  abstract = {The capacitance-resistive model (CRM) offers the promise of rapid evaluation of waterflood performance. This semianalytical modeling approach is a generalized nonlinear multivariate regression technique that is rooted in signal processing. Put simply, a rate variation at an injector introduces a signal, with the corresponding response felt at one or more producers. CRM uses production and injection rate data and bottomhole pressure, if available, to calibrate the model against a specific reservoir. Thereafter, the model is used for predictions.},
  file = {/home/peyman/Zotero/storage/6X8GK8H9/Sayarpour_The Use of Capacitance-Resistive Models for Rapid Estimation of Waterflood.pdf;/home/peyman/Zotero/storage/CQ8D9FXJ/Sayarpour - The Use of Capacitance-Resistive Models for Rapid .pdf},
  language = {en}
}

@article{scrucca2013jssa,
  ids = {scrucca2013jss},
  title = {{{GA}}: {{A Package}} for {{Genetic Algorithms}} in {{R}}},
  shorttitle = {{{GA}}},
  author = {Scrucca, Luca},
  year = {2013},
  month = apr,
  volume = {53},
  pages = {1--37},
  issn = {1548-7660},
  doi = {10.18637/jss.v053.i04},
  copyright = {Copyright (c) 2011 Luca Scrucca},
  file = {/home/peyman/Zotero/storage/9U9M4J8T/Scrucca_2013_GA.pdf;/home/peyman/Zotero/storage/Y3FY2YNX/Scrucca_2013_GA.pdf},
  journal = {Journal of Statistical Software},
  language = {en},
  number = {1}
}

@article{scrucca2017,
  title = {On {{Some Extensions}} to {{GA Package}}: {{Hybrid Optimisation}}, {{Parallelisation}} and {{Islands Evolution}}},
  author = {Scrucca, Luca},
  year = {2017},
  volume = {9},
  pages = {20},
  abstract = {Genetic algorithms are stochastic iterative algorithms in which a population of individuals evolve by emulating the process of biological evolution and natural selection. The R package GA provides a collection of general purpose functions for optimisation using genetic algorithms. This paper describes some enhancements recently introduced in version 3 of the package. In particular, hybrid GAs have been implemented by including the option to perform local searches during the evolution. This allows to combine the power of genetic algorithms with the speed of a local optimiser. Another major improvement is the provision of facilities for parallel computing. Parallelisation has been implemented using both the master-slave approach and the islands evolution model. Several examples of usage are presented, with both real-world data examples and benchmark functions, showing that often high-quality solutions can be obtained more efficiently.},
  file = {/home/peyman/Zotero/storage/LN89VZGA/Scrucca - 2017 - On Some Extensions to GA Package Hybrid Optimisat.pdf},
  language = {en}
}

@article{semnani,
  ids = {semnani2021jopsae},
  title = {Joint Optimization of Constrained Well Placement and Control Parameters Using Teaching-Learning Based Optimization and an Inter-Distance Algorithm},
  author = {Semnani, Amir},
  pages = {45},
  file = {/home/peyman/Zotero/storage/2C6VAUPX/Semnani_Joint optimization of constrained well placement and control parameters using.pdf;/home/peyman/Zotero/storage/HGF6Z72C/Semnani - Joint optimization of constrained well placement a.pdf},
  language = {en}
}

@inproceedings{sen2020,
  title = {Data-{{Driven Rate Optimization Under Geologic Uncertainty}}},
  booktitle = {{{SPE Annual Technical Conference}} and {{Exhibition}}},
  author = {Sen, Deepthi and Chen, Hongquan and {Datta-Gupta}, Akhil and Kwon, Joseph and Mishra, Srikanta},
  year = {2020},
  month = oct,
  publisher = {{OnePetro}},
  doi = {10.2118/201325-MS},
  file = {/home/peyman/Zotero/storage/H4MTUEVK/Sen et al_2020_Data-Driven Rate Optimization Under Geologic Uncertainty.pdf},
  language = {en}
}

@article{shahriari2016pi,
  title = {Taking the {{Human Out}} of the {{Loop}}: {{A Review}} of {{Bayesian Optimization}}},
  shorttitle = {Taking the {{Human Out}} of the {{Loop}}},
  author = {Shahriari, Bobak and Swersky, Kevin and Wang, Ziyu and Adams, Ryan P. and {de Freitas}, Nando},
  year = {2016},
  month = jan,
  volume = {104},
  pages = {148--175},
  issn = {1558-2256},
  doi = {10.1109/JPROC.2015.2494218},
  abstract = {Big Data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing and storage architectures. The construction of such systems involves many distributed design choices. The end products (e.g., recommendation systems, medical analysis tools, real-time game engines, speech recognizers) thus involve many tunable configuration parameters. These parameters are often specified and hard-coded into the software by various developers or teams. If optimized jointly, these parameters can result in significant improvements. Bayesian optimization is a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years. It promises greater automation so as to increase both product quality and human productivity. This review paper introduces Bayesian optimization, highlights some of its methodological aspects, and showcases a wide range of applications.},
  file = {/home/peyman/Zotero/storage/M7IQQXQA/Shahriari et al_2016_Taking the Human Out of the Loop.pdf},
  journal = {Proceedings of the IEEE},
  keywords = {Bayes methods,Big data,decision making,Decision making,design of experiments,Design of experiments,Genomes,genomic medicine,Linear programming,optimization,Optimization,response surface methodology,Statistical analysis,statistical learning},
  number = {1}
}

@article{shende2021samo,
  title = {Bayesian Topology Optimization for Efficient Design of Origami Folding Structures},
  author = {Shende, Sourabh and Gillman, Andrew and Buskohl, Philip and Yoo, David and Vemaganti, Kumar},
  year = {2021},
  month = apr,
  volume = {63},
  doi = {10.1007/s00158-020-02787-x},
  abstract = {Bayesian optimization (BO) is a popular method for solving optimization problems involving expensive objective functions. Although BO has been applied across various fields, its use in structural optimization area is in its early stages. Origami folding structures provide a complex design space where the use of an efficient optimizer is critical. In this work for the first time we demonstrate the ability of BO to solve origami-inspired design problems. We use a Gaussian process (GP) as the surrogate model that is trained to mimic the response of the expensive finite element (FE) objective function. The ability of this BO-FE framework to find optimal designs is verified by applying it to well-known origami design problems. We compare the performance of the proposed approach to traditional gradient-based optimization techniques and genetic algorithm methods in terms of ability to discover designs and computational efficiency. BO has many user-defined components/parameters and intuitions for these for structural optimization are currently limited. In this work, we study the role of hyperparameter tuning and the sensitivity of Bayesian optimization to the quality and size of the initial training set. Taking a holistic view of the computational expense, we propose various heuristic approaches to reduce the overall cost of optimization. Our results show that Bayesian optimization is an efficient alternative to traditional methods. It allows for the discovery of optimal designs using fewer finite element solutions, which makes it an attractive choice for the non-convex design space of origami fold mechanics.},
  file = {/home/peyman/Zotero/storage/UNS7GBA7/Shende et al_2021_Bayesian topology optimization for efficient design of origami folding.pdf},
  journal = {Structural and Multidisciplinary Optimization}
}

@article{skajaa,
  title = {Limited {{Memory BFGS}} for {{Nonsmooth Optimization}}},
  author = {Skajaa, Anders},
  pages = {50},
  abstract = {We investigate the behavior of seven algorithms when used for nonsmooth optimization. Particular emphasis is put on the BFGS method and its limited memory variant, the LBFGS method. Numerical results from running the algorithms on a range of different nonsmooth problems, both convex and nonconvex, show that LBFGS can be useful for many nonsmooth problems. Comparisons via performance profiles show that for large-scale problems \textendash its intended use \textendash{} it compares very well against the only other algorithm for which we have an implementation targeted at that range of problems. For small- and medium-scale nonsmooth problems, BFGS is a very robust and efficient algorithm and amongst the algorithms tested, there is an equally robust, but somewhat less efficient alternative.},
  file = {/home/peyman/Zotero/storage/46Z9VA6R/Skajaa - Limited Memory BFGS for Nonsmooth Optimization.pdf},
  language = {en}
}

@article{snoek2012acs,
  title = {Practical {{Bayesian Optimization}} of {{Machine Learning Algorithms}}},
  author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P.},
  year = {2012},
  month = aug,
  abstract = {Machine learning algorithms frequently require careful tuning of model hyperparameters, regularization terms, and optimization parameters. Unfortunately, this tuning is often a "black art" that requires expert experience, unwritten rules of thumb, or sometimes brute-force search. Much more appealing is the idea of developing automatic approaches which can optimize the performance of a given learning algorithm to the task at hand. In this work, we consider the automatic tuning problem within the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). The tractable posterior distribution induced by the GP leads to efficient use of the information gathered by previous experiments, enabling optimal choices about what parameters to try next. Here we show how the effects of the Gaussian process prior and the associated inference procedure can have a large impact on the success or failure of Bayesian optimization. We show that thoughtful choices can lead to results that exceed expert-level performance in tuning machine learning algorithms. We also describe new algorithms that take into account the variable cost (duration) of learning experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization on a diverse set of contemporary algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.},
  archiveprefix = {arXiv},
  eprint = {1206.2944},
  eprinttype = {arxiv},
  file = {/home/peyman/Zotero/storage/KJE3SKFF/Snoek et al_2012_Practical Bayesian Optimization of Machine Learning Algorithms.pdf},
  journal = {arXiv:1206.2944 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  primaryclass = {cs, stat}
}

@misc{soa,
  title = {Optimization - {{How}} to Optimize for Integer Parameters (and Other Discontinuous Parameter Space) in {{R}}?},
  howpublished = {https://stackoverflow.com/questions/11110848/how-to-optimize-for-integer-parameters-and-other-discontinuous-parameter-space},
  journal = {Stack Overflow}
}

@article{stordal2016mg,
  title = {A {{Theoretical}} Look at {{Ensemble}}-{{Based Optimization}} in {{Reservoir Management}}},
  author = {Stordal, Andreas S. and Szklarz, Slawomir P. and Leeuwenburgh, Olwijn},
  year = {2016},
  month = may,
  volume = {48},
  pages = {399--417},
  issn = {1874-8961, 1874-8953},
  doi = {10.1007/s11004-015-9598-6},
  abstract = {Ensemble-based optimization has recently received great attention as a potentially powerful technique for life-cycle production optimization, which is a crucial element of reservoir management. Recent publications have increased both the number of applications and the theoretical understanding of the algorithm. However, there is still ample room for further development since most of the theory is based on strong assumptions. Here, the mathematics (or statistics) of Ensemble Optimization is studied, and it is shown that the algorithm is a special case of an already well-defined natural evolution strategy known as Gaussian Mutation. A natural description of uncertainty in reservoir management arises from the use of an ensemble of history-matched geological realizations. A logical step is therefore to incorporate this uncertainty description in robust life-cycle production optimization through the expected objective function value. The expected value is approximated with the mean over all geological realizations. It is shown that the frequently advocated strategy of applying a different control sample to each reservoir realization delivers an unbiased estimate of the gradient of the expected objective function. However, this procedure is more variance prone than the deterministic strategy of applying the entire ensemble of perturbed control samples to each reservoir model realization. In order to reduce the variance of the gradient estimate, an importance sampling algorithm is proposed and tested on a toy problem with increasing dimensionality.},
  file = {/home/peyman/Zotero/storage/PVALI5V2/Stordal et al. - 2016 - A Theoretical look at Ensemble-Based Optimization .pdf},
  journal = {Mathematical Geosciences},
  language = {en},
  number = {4}
}

@article{sun2020ae,
  title = {Optimal Carbon Storage Reservoir Management through Deep Reinforcement Learning},
  author = {Sun, Alexander Y.},
  year = {2020},
  month = nov,
  volume = {278},
  pages = {115660},
  issn = {0306-2619},
  doi = {10.1016/j.apenergy.2020.115660},
  abstract = {Model-based optimization plays a central role in energy system design and management. The complexity and high-dimensionality of many process-level models, especially those used for geosystem energy exploration and utilization, often lead to formidable computational costs when the dimension of decision space is also large. This work adopts elements of recently advanced deep learning techniques to solve a sequential decision-making problem in applied geosystem management. Specifically, a deep reinforcement learning framework was formed for optimal multiperiod planning, in which a deep Q-learning network (DQN) agent was trained to maximize rewards by learning from high-dimensional inputs and from exploitation of its past experiences. To expedite computation, deep multitask learning was used to approximate high-dimensional, multistate transition functions. Both DQN and deep multitask learning are pattern based. As a demonstration, the framework was applied to optimal carbon sequestration reservoir planning using two different types of management strategies: monitoring only and brine extraction. Both strategies are designed to mitigate potential risks due to pressure buildup. Results show that the DQN agent can identify the optimal policies to maximize the reward for given risk and cost constraints. Experiments also show that knowledge the agent gained from interacting with one environment is largely preserved when deploying the same agent in other similar environments.},
  file = {/home/peyman/Zotero/storage/8SCGYBVS/Sun_2020_Optimal carbon storage reservoir management through deep reinforcement learning.pdf},
  journal = {Applied Energy},
  keywords = {Deep autoregressive model,Deep Q network,Geological carbon sequestration,Markov decision process,Multistage decision-making,Reinforcement learning,Surrogate modeling},
  language = {en}
}

@article{swastanto,
  title = {Gaussian {{Process Regression}} for {{Long}}-{{Term Time Series Forecasting}}},
  author = {Swastanto, Bagas Abisena},
  pages = {84},
  file = {/home/peyman/Zotero/storage/4WZKX395/Swastanto - Gaussian Process Regression for Long-Term Time Ser.pdf},
  language = {en}
}

@misc{t-lse,
  title = {Biblatex - {{Delete}} Month and Day from References with Biber and {{APA}}},
  howpublished = {https://tex.stackexchange.com/questions/438232/delete-month-and-day-from-references-with-biber-and-apa},
  journal = {TeX - LaTeX Stack Exchange}
}

@misc{theaieducationfoundation2021,
  title = {3.3 {{Data}} Efficient {{Optimization}} with {{Bayesian Optimization}} - {{Roberto Calandra}}},
  author = {{The AI Education Foundation}},
  year = {2021},
  month = jan,
  abstract = {57 views \textbullet{} Jan 27, 2021                       Show less                       Show more}
}

@article{thiele2010,
  title = {Streamline {{Simulation}} for {{Modern Reservoir}}-{{Engineering Workflows}}},
  author = {Thiele, M R and Technologies, Streamsim and University, Stanford and Batycky, R P and Fenwick, D H and Technologies, Streamsim},
  year = {2010},
  pages = {7},
  abstract = {In this article, we present a high-level description of streamlinebased flow simulation and focus on four areas in which the technology has proved valuable: reservoir-flow surveillance, flow simulation, history matching, and flood management. We highlight the advantages and disadvantages of streamline simulation (SLS) throughout the article and conclude with a look at possible SLS evolution. SLS re-emerged in the early 1990s to alleviate some computational problems faced by finite-difference (FD) simulation when confronted with highresolution geological models characterized by heterogeneous spatial distributions of static properties. Since then, development and application of SLS has advanced the technology significantly, such that SLS complements conventional-modeling approaches in many reservoir-engineering (RE) workflows.},
  file = {/home/peyman/Zotero/storage/CP2USHEE/Thiele et al_2010_Streamline Simulation for Modern Reservoir-Engineering Workflows.pdf;/home/peyman/Zotero/storage/LSCEZNWY/Thiele et al. - 2010 - Streamline Simulation for Modern Reservoir-Enginee.pdf},
  language = {en}
}

@misc{tychobra2020a,
  title = {Using {{XGBoost}} with {{Tidymodels}} | {{R}}-Bloggers},
  author = {on Tychobra, Posts},
  year = {2020},
  month = may,
  abstract = {Background XGBoost is a machine learning library originally written in C++ and ported to R in the xgboost R package. Over the last several years, XGBoost's effectiveness in Kaggle competitions catapulted it in popularity. At Tychobra, XGBoost is our go-to machine learning library. Fran\c{c}ois Chollet and JJ Allaire ...},
  language = {en-US}
}

@book{vasishth,
  title = {16.1 {{Hypothesis}} Testing Using the {{Bayes}} Factor | {{An Introduction}} to {{Bayesian Data Analysis}} for {{Cognitive Science}}},
  author = {Vasishth, Daniel Schad, {and} Shravan, Bruno Nicenboim},
  abstract = {An introduction to Bayesian data analysis for Cognitive Science.}
}

@article{villemonteix2009jgo,
  title = {An Informational Approach to the Global Optimization of Expensive-to-Evaluate Functions},
  author = {Villemonteix, Julien and Vazquez, Emmanuel and Walter, Eric},
  year = {2009},
  month = aug,
  volume = {44},
  pages = {509--534},
  issn = {0925-5001, 1573-2916},
  doi = {10.1007/s10898-008-9354-2},
  file = {/home/peyman/Zotero/storage/2TC6A92Z/Villemonteix et al_2009_An informational approach to the global optimization of expensive-to-evaluate.pdf},
  journal = {Journal of Global Optimization},
  language = {en},
  number = {4}
}

@inproceedings{volstad2020,
  title = {Perfecting {{The}} `{{Perfect Well}}': {{Lessons}}-Learned {{From The Pre}}-Drilling {{Campaign For Johan Sverdrup}}},
  shorttitle = {Perfecting {{The}} `{{Perfect Well}}'},
  booktitle = {Offshore {{Technology Conference}}},
  author = {V{\o}lstad, Janne and B{\ae}rheim, Stian and Henriksen, Knut and Gloppen, Trond},
  year = {2020},
  month = may,
  publisher = {{OnePetro}},
  doi = {10.4043/30850-MS},
  file = {/home/peyman/Zotero/storage/QP23UHEX/Vølstad et al. - 2020 - Perfecting The ‘Perfect Well’ Lessons-learned Fro.pdf},
  language = {en}
}

@inproceedings{whitea,
  title = {Experimental {{Design}} as a {{Framework}} for {{Reservoir Studies}}},
  author = {White, Christopher D and Royer, Steve A},
  pages = {14},
  abstract = {Numerical simulation integrates extensive geoscience and engineering data with complex process models to examine reservoir behavior. Reservoir studies commonly consider many scenarios, cases, and realizations. However, reservoir simulation can be expensive. Complexity, combinatorics, and expense motivate improved reservoir study methods. The experimental design framework selects relevant models, records factor settings for models, creates data files, controls execution, gathers summary data, and creates response models. Response surface models facilitate Monte Carlo simulation, uncertainty analysis, optimization, parameter estimation, upscaling, and performance forecasting. A predevelopment study of a Gulf of Mexico turbidite reservoir uses this framework to examine the sensitivity of oil production predictions to well location, absolute horizontal permeability, pore compressibility, aquifer size, skin, and vertical permeability. Well location is optimized for cases with uncertain parameters.},
  file = {/home/peyman/Zotero/storage/3HJBS84R/White_Royer_Experimental Design as a Framework for Reservoir Studies.pdf;/home/peyman/Zotero/storage/TV4HF83H/White and Royer - Experimental Design as a Framework for Reservoir S.pdf},
  keywords = {1st,2ed,3rd},
  language = {en}
}

@misc{wilson2021,
  title = {{{AnotherSamWilson}}/{{ParBayesianOptimization}}},
  author = {Wilson, Samuel},
  year = {2021},
  month = may,
  abstract = {Parallelizable Bayesian Optimization in R. Contribute to AnotherSamWilson/ParBayesianOptimization development by creating an account on GitHub.},
  keywords = {bayesian-inference,machine-learning,r}
}

@article{wu,
  title = {Practical {{Multi}}-Fidelity {{Bayesian Optimization}} for {{Hyperparameter Tuning}}},
  author = {Wu, Jian and {Toscano-Palmerin}, Saul and Frazier, Peter I and Wilson, Andrew Gordon},
  pages = {11},
  abstract = {Bayesian optimization is popular for optimizing time-consuming black-box objectives. Nonetheless, for hyperparameter tuning in deep neural networks, the time required to evaluate the validation error for even a few hyperparameter settings remains a bottleneck. Multi-fidelity optimization promises relief using cheaper proxies to such objectives \textemdash{} for example, validation error for a network trained using a subset of the training points or fewer iterations than required for convergence. We propose a highly flexible and practical approach to multi-fidelity Bayesian optimization, focused on efficiently optimizing hyperparameters for iteratively trained supervised learning models. We introduce a new acquisition function, the trace-aware knowledge-gradient, which efficiently leverages both multiple continuous fidelity controls and trace observations \textemdash{} values of the objective at a sequence of fidelities, available when varying fidelity using training iterations. We provide a provably convergent method for optimizing our acquisition function and show it outperforms state-of-the-art alternatives for hyperparameter tuning of deep neural networks and large-scale kernel learning.},
  file = {/home/peyman/Zotero/storage/C4WGYFHS/Wu et al. - Practical Multi-ﬁdelity Bayesian Optimization for .pdf},
  language = {en}
}

@article{yaochujin2002iteca,
  ids = {yaochujin2002itec},
  title = {A Framework for Evolutionary Optimization with Approximate Fitness Functions},
  author = {{Yaochu Jin} and Olhofer, M. and Sendhoff, B.},
  year = {2002},
  month = oct,
  volume = {6},
  pages = {481--494},
  issn = {1089-778X},
  doi = {10.1109/TEVC.2002.800884},
  abstract = {It is not unusual that an approximate model is needed for fitness evaluation in evolutionary computation. In this case, the convergence properties of the evolutionary algorithm are unclear due to the approximation error of the model. In this paper, extensive empirical studies are carried out to investigate the convergence properties of an evolution strategy using an approximate fitness function on two benchmark problems. It is found that incorrect convergence will occur if the approximate model has false optima. To address this problem, individual- and generation-based evolution control are introduced and the resulting effects on the convergence properties are presented. A framework for managing approximate models in generation-based evolution control is proposed. This framework is well suited for parallel evolutionary optimization, which is able to guarantee the correct convergence of the evolutionary algorithm, as well as to reduce the computation cost as much as possible. Control of the evolution and updating of the approximate models are based on the estimated fidelity of the approximate model. Numerical results are presented for three test problems and for a aerodynamic design example.},
  file = {/home/peyman/Zotero/storage/2E8NL7UA/Yaochu Jin et al_2002_A framework for evolutionary optimization with approximate fitness functions.pdf;/home/peyman/Zotero/storage/8TKBYG8Q/Yaochu Jin et al. - 2002 - A framework for evolutionary optimization with app.pdf},
  journal = {IEEE Transactions on Evolutionary Computation},
  language = {en},
  number = {5}
}

@misc{yi2021m,
  title = {Understanding {{Gaussian Process}}, the {{Socratic Way}}},
  author = {Yi, Wei},
  year = {2021},
  month = mar,
  abstract = {Gaussian Process makes predictions with uncertainty, unlike neural networks. Learn how it works with simple steps.},
  howpublished = {https://towardsdatascience.com/understanding-gaussian-process-the-socratic-way-ba02369d804},
  journal = {Medium},
  language = {en}
}

@article{yousef2006a,
  ids = {yousef2006},
  title = {A {{Capacitance Model To Infer Interwell Connectivity From Production}}- and {{Injection}}-{{Rate Fluctuations}}},
  author = {Yousef, Ali A},
  year = {2006},
  pages = {17},
  abstract = {This paper presents a new procedure to quantify communication between vertical wells in a reservoir on the basis of fluctuations in production and injection rates. The proposed procedure uses a nonlinear signal-processing model to provide information about preferential-transmissibility trends and the presence of flow barriers.},
  file = {/home/peyman/Zotero/storage/BHLABBEE/Yousef - 2006 - A Capacitance Model To Infer Interwell Connectivit.pdf;/home/peyman/Zotero/storage/TB9GV9E7/Yousef_2006_A Capacitance Model To Infer Interwell Connectivity From Production- and.pdf},
  language = {en}
}

@inproceedings{zhao2015srss,
  title = {{{INSIM}}: {{A Data}}-{{Driven Model}} for {{History Matching}} and {{Prediction}} for {{Waterflooding Monitoring}} and {{Management}} with a {{Field Application}}},
  shorttitle = {{{INSIM}}},
  booktitle = {{{SPE Reservoir Simulation Symposium}}},
  author = {Zhao, Hui and Kang, Zhijiang and Zhang, Xiansong and Sun, Haitao and Cao, Lin and Reynolds, Albert C.},
  year = {2015},
  publisher = {{Society of Petroleum Engineers}},
  address = {{Houston, Texas, USA}},
  doi = {10.2118/173213-MS},
  abstract = {We derive and implement an interwell numerical simulation model (INSIM) which can be used as a calculation tool to approximate the performance of a reservoir under waterflooding. In INSIM, the reservoir is characterized as a coarse model consisting of a number of interwell control units, where each unit has two specific parameters: transmissibility and control pore volume. By solving the mass material balance and front tracking equations for the control units, the interwell fluid rates and saturations are obtained so that phase producing rates can be predicted. INSIM is applied to perform history matching for parameter estimation and to infer the interwell connectivity and geological characteristics. INSIM has the following advantages: (1) the model parameters estimated from history matching provide a relative characterization of interwell formation properties. The model can handle changes in the flow directions caused by changing well rates, including shutting in wells or converting producers to injectors, whereas with the common correlation-based interwell connectivity method, the well interactions are assumed to be fixed; (2) the previous methods that bear computational similarity to INSIM can only provide the total liquid production rate whereas, with our procedure, we can calculate the oil and water flow rates and hence history-match water-cut data; (3) because we can calculate the oil and water flow rates, our method can be used for waterflooding optimization but with far less computational effort than with the traditional method based on the use of a reservoir simulator.},
  eventtitle = {{{SPE Reservoir Simulation Symposium}}},
  file = {/home/peyman/Zotero/storage/9TVMWPRU/Zhao et al. - 2015 - INSIM A Data-Driven Model for History Matching an.pdf;/home/peyman/Zotero/storage/Q5AMKEG8/Zhao et al_2015_INSIM.pdf},
  language = {en}
}

@misc{zotero-1010,
  title = {Computers \& {{Mathematics}} with {{Applications}} | {{Development}} and {{Application}} of {{Open}}-Source {{Software}} for {{Problems}} with {{Numerical PDEs}} | {{ScienceDirect}}.Com by {{Elsevier}}},
  howpublished = {https://www.sciencedirect.com/journal/computers-and-mathematics-with-applications/vol/81/suppl/C}
}

@article{zotero-1029,
  title = {Lecture 13: {{Optimization}}},
  pages = {15},
  file = {/home/peyman/Zotero/storage/M3ECKDNK/Lecture 13 Optimization.pdf},
  language = {en}
}

@misc{zotero-1044,
  title = {A Reduced Random Sampling Strategy for Fast Robust Well Placement Optimization | {{Elsevier Enhanced Reader}}},
  doi = {10.1016/j.petrol.2019.106414},
  howpublished = {https://reader.elsevier.com/reader/sd/pii/S0920410519308356?token=1B7E58715AB7EBF4A25708E3A9AB9F587F5D73B22B47D0EB2E147F18F0C057AE914D197C51F4F4D252ED170F06C61B12\&originRegion=eu-west-1\&originCreation=20210601181706},
  language = {en}
}

@misc{zotero-1068,
  title = {Google {{Colaboratory}}},
  howpublished = {https://colab.research.google.com/drive/1\_601cnzX83OGWM3pyG3Q7DYjGCT4-VQ-?usp=sharing\#scrollTo=7Nj1okCSBozl},
  language = {en}
}

@misc{zotero-1070,
  title = {Google {{Colaboratory}}},
  howpublished = {https://colab.research.google.com/drive/1\_601cnzX83OGWM3pyG3Q7DYjGCT4-VQ-?usp=sharing\#scrollTo=J6Yhm9UVMXq8},
  language = {en}
}

@book{zotero-1075,
  title = {Probabilistic {{Machine Learning}}: {{An Introduction}}},
  file = {/home/peyman/Zotero/storage/497FE53S/book1.pdf}
}

@misc{zotero-1089,
  title = {{{DiceOptim}}},
  howpublished = {https://richetyann.shinyapps.io/DiceOptim/}
}

@misc{zotero-334a,
  title = {Interface to {{Keras Tuner}}},
  abstract = {Keras Tuner {$<$}https://keras-team.github.io/keras-tuner/{$>$} is a hypertuning framework made for humans.               It aims at making the life of AI practitioners, hypertuner               algorithm creators and model designers as simple as possible by               providing them with a clean and easy to use API for hypertuning.               Keras Tuner makes moving from a base model to a hypertuned one quick and               easy by only requiring you to change a few lines of code.},
  howpublished = {https://henry090.github.io/kerastuneR/},
  language = {en}
}

@misc{zotero-405a,
  title = {{{ECLRUN}}. {{User Guide}}. {{Version}} ({{Beta}} Build 2012-{{Mar}}-07 16:35) - {{PDF Free Download}}},
  shorttitle = {{{ECLRUN}}. {{User Guide}}. {{Version}} ({{Beta}} Build 2012-{{Mar}}-07 16},
  abstract = {ECLRUN User Guide Version (Beta build 2012-Mar-07 16:35) Copyright (c) 2012 Schlumberger. All rights reserved. Reproduction or alteration without prior written permission is prohibited, except as},
  howpublished = {https://docplayer.net/102484590-Eclrun-user-guide-version-beta-build-2012-mar-07-16-35.html}
}

@misc{zotero-410,
  title = {{{RPubs}} - {{Optimization}} with {{Genetic Algorithm}}},
  file = {/home/peyman/Zotero/storage/EB9QLN3X/550805.html},
  howpublished = {https://rpubs.com/Argaadya/550805}
}

@phdthesis{zotero-672,
  type = {Phdthesis}
}

@misc{zotero-677a,
  title = {{{BFGS}} in a {{Nutshell}}: {{An Introduction}} to {{Quasi}}-{{Newton Methods}}},
  howpublished = {https://towardsdatascience.com/bfgs-in-a-nutshell-an-introduction-to-quasi-newton-methods-21b0e13ee504}
}

@misc{zotero-784,
  title = {{{FRED}}/{{UF Working}}-Paper Template},
  abstract = {An online LaTeX editor that's easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.},
  howpublished = {https://www.overleaf.com/latex/templates/fred-slash-uf-working-paper-template/mjnnjxzqmydm},
  language = {en}
}

@misc{zotero-934,
  title = {Dr. {{Behnam Jafarpour}} from {{The USC}} - {{Deep Convolutional Neural Networks}} for {{Latent Space Inversion}} - {{YouTube}}},
  howpublished = {https://www.youtube.com/watch?v=c9mEuwWpzF4}
}

@misc{zotero-954,
  title = {Robust {{Integrated Optimization}} of {{Well Placement}} and {{Control}} under {{Field Production Constraints}} - {{ScienceDirect}}},
  howpublished = {https://www.sciencedirect.com/science/article/abs/pii/S0920410521005878}
}

@misc{zotero-984,
  title = {Machine-{{Learning}}-{{Assisted Closed}}-{{Loop Reservoir Management Using Echo State Network}} for {{Mature Fields}} under {{Waterflood}} | {{SPE Reservoir Evaluation}} \& {{Engineering}} | {{OnePetro}}},
  howpublished = {https://onepetro.org/REE/article/23/04/1298/451139/Machine-Learning-Assisted-Closed-Loop-Reservoir}
}

@misc{zotero-994,
  title = {{{BoTorch}} {$\cdot$} {{Bayesian Optimization}} in {{PyTorch}}},
  abstract = {Bayesian Optimization in PyTorch},
  howpublished = {https://botorch.org/}
}


